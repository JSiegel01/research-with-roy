{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyvo as vo\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "from photutils.utils import calc_total_error\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "import json\n",
    "\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from photutils.detection import DAOStarFinder\n",
    "from astropy.stats import mad_std, sigma_clipped_stats\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going to try debugging this one now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n",
    "#empty data frame to append values of flux to\n",
    "rows=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the image catalog in the WISE database\n",
    "#define coordinates\tmake it possible to run a list over this with all of the ra and decs\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "#print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n",
    "\n",
    "M0instr =  12.98 # found the relative instrumental zero point magnitude in this specific band (W4)\n",
    "flx_conv_fact =  8.363 # the Zero Magnitude Flux Density conversion factor in this band\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "#extract a cutout for plotting and KDTree\n",
    "wcs = WCS(image1[0].header)\n",
    "#cuting out the image of the galaxy apart from the rest of the background.\n",
    "cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "wcs = cutout.wcs\n",
    "\n",
    "#####   constants in every image:\n",
    "\n",
    "#plot the sources with circles\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# convert Ra and dec values to pixel coordinates\n",
    "positions = wcs.world_to_pixel_values(ra, dec)\n",
    "positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "#define the distance threshold for the KDTree grouping (in pixels)\n",
    "distance_threshold = 5\n",
    "\n",
    "#build the KDTree for efficient grouping\n",
    "tree = KDTree(positions)\n",
    "\n",
    "#query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "print(groups)\n",
    "# consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "unique_groups = []\n",
    "seen = set()\n",
    "for group in groups:\n",
    "    group = tuple(sorted(group))\n",
    "    if group not in seen:\n",
    "        seen.add(group)\n",
    "        unique_groups.append(group)\n",
    "print(unique_groups)\n",
    "# for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "#represents the consolidated postion of potentially multiple detections of one source.\n",
    "grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "print(grouped_positions)\n",
    "\n",
    "#define the Region(s) Of Interest (center x, center y, radius)\n",
    "ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "#empty data frame to append values of flux to\n",
    "rows=[]\n",
    "\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "#####  End of constants\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(image_data.shape[0], image_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(image_data.shape[0], image_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = image_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(image_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts<= 0: # \n",
    "                    target_flux # avoid taking the log of zero or negative value\n",
    "                else:\n",
    "                        #counts to flux\n",
    "                    Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                    target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                    #calculate area of annulus\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(image_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts <= 0:\n",
    "                    annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "                else:\n",
    "                    #counts to flux\n",
    "                    Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                    annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': image_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "            #filter only valid sources to conduct the overlapping photometry again. \n",
    "        # so that sources with an acceptable amount of overlap have their overlapping counts subtracted from the nonoverlapping counts.\n",
    "        #valid_sources = display_data[display_data['Flag'] == 'Valid']\n",
    "\n",
    "        for i, valid_row in display_data[display_data['Flag'] == 'Valid'].iterrows():\n",
    "            x, y, r = valid_row['X'], valid_row['Y'], valid_row['Radius']\n",
    "            target_aperture = CircularAperture((x, y), r)\n",
    "            target_photo_table = aperture_photometry(image_data, target_aperture)\n",
    "            target_counts = target_photo_table['aperture_sum'][0]\n",
    "            \n",
    "            if target_counts <= 0:\n",
    "                target_flux = 0\n",
    "            else:\n",
    "                Mcal_trgt = M0instr - 2.5 * (np.log10(target_counts))\n",
    "                target_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5)\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "            non_overlapping_counts = target_counts\n",
    "\n",
    "            for j, valid_row2 in display_data[display_data['Flag'] == 'Valid'].iterrows():\n",
    "                if i != j:\n",
    "                    x2, y2, r2 = valid_row2['X'], valid_row2['Y'], valid_row2['Radius']\n",
    "                    distance = dist((x, y), (x2, y2))\n",
    "                    if distance < r + r2:\n",
    "                        overlap_percent = (r + r2 - distance) / (r + r2)\n",
    "                        if overlap_percent > .01: # i think i will have to fiddle around with this\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(image_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0]\n",
    "                            #Subtract overlapping data from non overlapping and assign the data to the variable of non_overlapping_counts\n",
    "                            non_overlapping_counts -= overlap_counts\n",
    "                            \n",
    "\n",
    "            if non_overlapping_counts <= 0: # if counts are 0 or negative, dont do flux conversion cuz it wont work. assigns the flux to be zero\n",
    "                net_flux = 0\n",
    "            else:\n",
    "                Mcal_trgt = M0instr - 2.5 * (np.log10(non_overlapping_counts))\n",
    "                net_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5) - tot_bg\n",
    "\n",
    "            # for each location of the overlapping source in the pandas dataframe table, assign whether it is still valid or not.\n",
    "            display_data.loc[i, 'Net Flux (Jy)'] = net_flux\n",
    "            display_data.loc[i, 'Flag'] = 'Valid' if net_flux > 0 else 'Low Flux'\n",
    "\n",
    "     \n",
    "        \n",
    "     ## Trying to plot the images now\n",
    "     #extract a cutout and plot it\n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (400,400), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "    \n",
    "        #plotting the image\n",
    "        fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in display_data.itertuples():\n",
    "            if row.Flag == 'Valid':\n",
    "                target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "                annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "                target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "                annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "        ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#rows.append({'band_id': {band_labels[band_id]},\n",
    "    \n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "#visualizing the apertures\n",
    "\n",
    "#for row in display_data.itertuples():\n",
    "    #if row.Flag == 'Valid':\n",
    "       # target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "       # annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "       # target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "       # annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "\n",
    "####if you want to see all of them use the code below:\n",
    "#for ((x, y), r, annulus_inner, annulus_outer) in ROI:\n",
    "    #target_apertureplt = CircularAperture((x,y),r)\n",
    "   # annulus_apertureplt = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "   # target_apertureplt.plot(color='red', lw = 1.5)\n",
    "   # annulus_apertureplt.plot(color='red', lw = 1.5)\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('Dec')\n",
    "plt.grid(color='white', ls='dotted')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just one band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "#for i in range(len(im_table)):\n",
    "   # print(im_table[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(im_table)):\n",
    "    if im_table[i]['sia_bp_id']:\n",
    "\n",
    "        print(im_table[i].getdataurl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = im_table[0].getdataurl()\n",
    "#Download the image and open it in Astropy\n",
    "fname = download_file(data_url, cache=True)\n",
    "image1= fits.open(fname)\n",
    "image_data= image1[0].data\n",
    "print(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "sources_7793\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "hdr = image1[0].header\n",
    "hdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract a cutout for plotting and KDTree\n",
    "wcs = WCS(image1[0].header)\n",
    "#cuting out the image of the galaxy apart from the rest of the background.\n",
    "cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "print(image_data.shape)\n",
    "print(cutout.data.shape)\n",
    "# THIS IS WHERE THE DISCREPANCY IS HAPPENING.\n",
    "# When i make the image shape the same, the positions of the sources are almost identical to the \n",
    "# image downloaded code.\n",
    "wcs = cutout.wcs\n",
    "cutout_data = cutout.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the KDTree\n",
    "# convert Ra and dec values to pixel coordinates\n",
    "positions = wcs.world_to_pixel_values(ra, dec)\n",
    "positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "#define the distance threshold for the KDTree grouping (in pixels)\n",
    "distance_threshold = 10\n",
    "\n",
    "#build the KDTree for efficient grouping\n",
    "tree = KDTree(positions)\n",
    "\n",
    "#query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "print(groups)\n",
    "# consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "unique_groups = []\n",
    "seen = set()\n",
    "for group in groups:\n",
    "    group = tuple(sorted(group))\n",
    "    if group not in seen:\n",
    "        seen.add(group)\n",
    "        unique_groups.append(group)\n",
    "print(unique_groups)\n",
    "# for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "#represents the consolidated postion of potentially multiple detections of one source.\n",
    "grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "print(grouped_positions)\n",
    "# a problem could be with grouped postions maybe?\n",
    "# here is where the code between downloading the image and using the URL differs!\n",
    "#  the position of sources is slightly altered for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define the Region(s) Of Interest (center x, center y, radius)\n",
    "ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "#empty data frame to append values of flux to\n",
    "rows=[]\n",
    "\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n",
    "\n",
    "M0instr =  12.98 # found the relative instrumental zero point magnitude in this specific band (W4)\n",
    "flx_conv_fact =  8.363 # the Zero Magnitude Flux Density conversion factor in this band\n",
    "cutout_data.shape\n",
    "grouped_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check for overlap and perform aperture photometry\n",
    "for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "    overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "    non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "    for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "        if i != j: # ensures that a source is not compared to itself! wow\n",
    "            distance = dist((x, y) , (x2, y2)) \n",
    "            if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                if overlap_percent > .5:\n",
    "                    overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                    break\n",
    "                else: \n",
    "                    overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                    non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                    # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                    # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                \n",
    "    if overlap:\n",
    "        #flag the sources that overlap\n",
    "        rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                      'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "    else: #perform all the aperture photometry stuff\n",
    "        # For the Target objects in the little aperture circle define their target apertures\n",
    "        target_aperture = CircularAperture((x,y),r,)\n",
    "    \n",
    "        #perform aperture photometry on target\n",
    "        # also now apply the masked data\n",
    "        masked_data = cutout_data * non_overlapping_mask\n",
    "        target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "        target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "        if target_counts<= 0: # \n",
    "            target_flux # avoid taking the log of zero or negative value\n",
    "        else:\n",
    "                #counts to flux\n",
    "            Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "            target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "            #calculate area of annulus\n",
    "        target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "        # For the Background Annuli of outside of the Target\n",
    "        #define the background annulus for the target\n",
    "        annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "        #perform aperture photometry on annuli\n",
    "        annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "        annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "    \n",
    "        if annulus_counts <= 0:\n",
    "            annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "        else:\n",
    "            #counts to flux\n",
    "            Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "            annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "        #calculate area of annulus\n",
    "        annulus_area = annulus_aperture.area\n",
    "\n",
    "        # do the calculations for including a Background aperture\n",
    "    \n",
    "        #Calculating the net flux:\n",
    "        #calculate the mean background per pixel\n",
    "        bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "        #calculate the total background in the target aperture\n",
    "        tot_bg = bg_perpixel * target_area\n",
    "\n",
    "        #Subtract background from the target flux\n",
    "        net_flx = target_flux - tot_bg\n",
    "    \n",
    "        #   Append the result as a dictionary to the list named 'rows'\n",
    "        rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                 'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                   'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                     'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                       'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "    \n",
    "\n",
    "#append the rows to the empty dataframe    \n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#visualizing the apertures that are postive and dont overlap to a detrimental degree. if you want to see all of them take out the (== 'Valid') part of the viz code\n",
    "fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "for row in display_data.itertuples():\n",
    "    if row.Flag == 'Valid':\n",
    "        target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "        annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "        target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "        annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "ax.set_xlabel('Right Ascension')\n",
    "ax.set_ylabel('Declination')\n",
    "#plt.title(f'Band {band_labels[band_id]}')\n",
    "plt.show()\n",
    "\n",
    "display_data.loc[display_data['Flag']== 'Valid']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dont think i need this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#filter only valid sources to conduct the overlapping photometry again. \n",
    "# so that sources with an acceptable amount of overlap have their overlapping counts subtracted from the nonoverlapping counts.\n",
    "valid_sources = display_data[display_data['Flag'] == 'Valid']\n",
    "\n",
    "for i, valid_row in valid_sources.iterrows():\n",
    "    x, y, r = valid_row['X'], valid_row['Y'], valid_row['Radius']\n",
    "    target_aperture = CircularAperture((x, y), r)\n",
    "    target_photo_table = aperture_photometry(cutout_data, target_aperture)\n",
    "    target_counts = target_photo_table['aperture_sum'][0]\n",
    "    \n",
    "    if target_counts <= 0:\n",
    "        target_flux = 0\n",
    "    else:\n",
    "        Mcal_trgt = M0instr - 2.5 * (np.log10(target_counts))\n",
    "        target_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5)\n",
    "        target_area = target_aperture.area\n",
    "\n",
    "    non_overlapping_counts = target_counts\n",
    "\n",
    "    for j, valid_row2 in valid_sources.iterrows():\n",
    "        if i != j:\n",
    "            x2, y2, r2 = valid_row2['X'], valid_row2['Y'], valid_row2['Radius']\n",
    "            distance = dist((x, y), (x2, y2))\n",
    "            if distance < r + r2:\n",
    "                overlap_percent = (r + r2 - distance) / (r + r2)\n",
    "                if overlap_percent > .01: # i think i will have to fiddle around with this\n",
    "                    overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                    overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                    overlap_counts = overlap_photo_table['aperture_sum'][0]\n",
    "                    #Subtract overlapping data from non overlapping and assign the data to the variable of non_overlapping_counts\n",
    "                    non_overlapping_counts -= overlap_counts\n",
    "                    \n",
    "\n",
    "    if non_overlapping_counts <= 0: # if counts are 0 or negative, dont do flux conversion cuz it wont work. assigns the flux to be zero\n",
    "        net_flux = 0\n",
    "    else:\n",
    "        Mcal_trgt = M0instr - 2.5 * (np.log10(non_overlapping_counts))\n",
    "        net_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5) - tot_bg\n",
    "\n",
    "    # for each location of the overlapping source in the pandas dataframe table, assign whether it is still valid or not.\n",
    "    display_data.loc[i, 'Net Flux (Jy)'] = net_flux\n",
    "    display_data.loc[i, 'Flag'] = 'Valid' if net_flux > 0 else 'Low Flux'\n",
    "\n",
    "\n",
    "#visualizing the apertures that are postive and dont overlap to a detrimental degree. if you want to see all of them take out the (== 'Valid') part of the viz code\n",
    "fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "for row in display_data.itertuples():\n",
    "    if row.Flag == 'Valid':\n",
    "        target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "        annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "        target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "        annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "ax.set_xlabel('Right Ascension')\n",
    "ax.set_ylabel('Declination')\n",
    "#plt.title(f'Band {band_labels[band_id]}')\n",
    "plt.show()\n",
    "\n",
    "display_data.loc[display_data['Flag']== 'Valid']\n",
    "#display_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the new code for when i want to apply it to all wavelengths :\n",
    "\n",
    "remember to include the code for different flux conversions for each band!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE THIS WHEN YOU HAVE PUT IN THE CONVERSION Code\n",
    "M0instr =  12.98 # found the relative instrumental zero point magnitude in this specific band (W4)\n",
    "flx_conv_fact =  8.363 # the Zero Magnitude Flux Density conversion factor in this band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dont use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_alldata = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "       # print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data # maybe this needs to be assigned as a dictionary for each of them.\n",
    "        cutout_alldata.append({ 'Band': {band_labels[band_id]}, 'CutoutData' : cutout_data, 'WCS': wcs})\n",
    "cutout_alldata = pd.DataFrame(cutout_alldata)\n",
    "cutout_alldata['ROI'] = np.nan\n",
    "display(cutout_alldata)\n",
    "\n",
    "#cutout_alldata = pd.DataFrame(columns=['Band', 'CutoutData', 'WCS'])  # Initialize with columns\n",
    "#for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "  #  band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "   # if band_id in band_labels:\n",
    "   #    # print(f'Band {band_labels[band_id]}: ')\n",
    "    #    data_url = im_table[i].getdataurl()\n",
    "   #     #Download the image and open it in Astropy\n",
    "   #     fname = download_file(data_url, cache=True)\n",
    "   #     image1= fits.open(fname)\n",
    "    #    image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "     #   wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "     #   cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "      #  wcs = cutout.wcs\n",
    "      #  cutout_data = cutout.data # maybe this needs to be assigned as a dictionary for each of them.\n",
    "      #  cutout_alldata.loc[len(cutout_alldata)] = [band_id, cutout_data, wcs]\n",
    "        #cutout_alldata._append({ 'Band': {band_labels[band_id]}, 'CutoutData' : cutout_data, 'WCS': wcs}, ignore_index= True)\n",
    "\n",
    "display(cutout_alldata)\n",
    "\n",
    "for idx, row in cutout_alldata.iterrows():\n",
    "    wcs = row.WCS\n",
    "    positions = wcs.world_to_pixel_values(ra, dec)\n",
    "    positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "    #define the distance threshold for the KDTree grouping (in pixels)\n",
    "    distance_threshold = 11\n",
    "\n",
    "    #build the KDTree for efficient grouping\n",
    "    tree = KDTree(positions)\n",
    "\n",
    "    #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "    groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "    print(groups)\n",
    "    # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "    unique_groups = []\n",
    "    seen = set()\n",
    "    for group in groups:\n",
    "        group = tuple(sorted(group))\n",
    "        if group not in seen:\n",
    "            seen.add(group)\n",
    "            unique_groups.append(group)\n",
    "    print(unique_groups)\n",
    "    # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "    #represents the consolidated postion of potentially multiple detections of one source.\n",
    "    grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "    print(grouped_positions)\n",
    "\n",
    "    #define the Region(s) Of Interest (center x, center y, radius)\n",
    "    ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "    #empty data frame to append values of flux to\n",
    "    roi_str = json.dumps(ROI) # to revert back : roi_list = json.loads(cutout_alldata.at[idx, 'ROI'])\n",
    "    cutout_alldata.at[idx, 'ROI'] = roi_str\n",
    "display(cutout_alldata)\n",
    "\n",
    "for idx, row in cutout_alldata.iterrows(): \n",
    "    roi_list = json.loads(row['ROI'])\n",
    "    band_id = row['Band']\n",
    "    cutout_data = row['CutoutData']\n",
    "    #now inputting the aperture photometry part\n",
    "    # check for overlap and perform aperture photometry\n",
    "    for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(roi_list):\n",
    "        overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "        non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "        for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(roi_list): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "            if i != j: # ensures that a source is not compared to itself! wow\n",
    "                distance = dist((x, y) , (x2, y2)) \n",
    "                if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                    overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                    if overlap_percent > .5:\n",
    "                        overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                        break\n",
    "                    else: \n",
    "                        overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                        non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                        # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                        # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                    \n",
    "        if overlap:\n",
    "            #flag the sources that overlap\n",
    "            rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "        else: #perform all the aperture photometry stuff\n",
    "            # For the Target objects in the little aperture circle define their target apertures\n",
    "            target_aperture = CircularAperture((x,y),r,)\n",
    "        \n",
    "            #perform aperture photometry on target\n",
    "            # also now apply the masked data\n",
    "            masked_data = cutout_data * non_overlapping_mask\n",
    "            target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "            target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "            if target_counts<= 0: # \n",
    "                target_flux # avoid taking the log of zero or negative value\n",
    "            else:\n",
    "                    #counts to flux\n",
    "                Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                #calculate area of annulus\n",
    "            target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "            # For the Background Annuli of outside of the Target\n",
    "            #define the background annulus for the target\n",
    "            annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "            #perform aperture photometry on annuli\n",
    "            annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "            annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "        \n",
    "            if annulus_counts <= 0:\n",
    "                annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "            else:\n",
    "                #counts to flux\n",
    "                Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "            #calculate area of annulus\n",
    "            annulus_area = annulus_aperture.area\n",
    "\n",
    "            # do the calculations for including a Background aperture\n",
    "        \n",
    "            #Calculating the net flux:\n",
    "            #calculate the mean background per pixel\n",
    "            bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "            #calculate the total background in the target aperture\n",
    "            tot_bg = bg_perpixel * target_area\n",
    "\n",
    "            #Subtract background from the target flux\n",
    "            net_flx = target_flux - tot_bg\n",
    "        \n",
    "            #   Append the result as a dictionary to the list named 'rows'\n",
    "            rows.append({ 'band_id': band_id,'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                    'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                    'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                        'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                        'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "        #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "    \n",
    "display_data = pd.DataFrame(rows)\n",
    "display(display_data)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "for row in display_data.itertuples():\n",
    "    if row.Flag == 'Valid':\n",
    "        target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "        annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "        target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "        annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "ax.set_xlabel('Right Ascension')\n",
    "ax.set_ylabel('Declination')\n",
    "#plt.title(f'Band {band_labels[band_id]}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        print(data_url)\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cutting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 10\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "        print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "        print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        #empty data frame to append values of flux to\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts<= 0: # \n",
    "                    target_flux # avoid taking the log of zero or negative value\n",
    "                else:\n",
    "                        #counts to flux\n",
    "                    Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                    target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                    #calculate area of annulus\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts <= 0:\n",
    "                    annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "                else:\n",
    "                    #counts to flux\n",
    "                    Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                    annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "     \n",
    "    \n",
    "     ## Trying to plot the images now\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in display_data.itertuples():\n",
    "            if row.Flag == 'Valid':\n",
    "                target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "                annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "                target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "                annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "        ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(display_data)\n",
    "#display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best versions of the code so far\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## good but has too many duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "        print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "        print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts<= 0: # \n",
    "                    target_flux # avoid taking the log of zero or negative value\n",
    "                else:\n",
    "                        #counts to flux\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                    Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                    target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                    #calculate area of annulus\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts <= 0:\n",
    "                    annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "                else:\n",
    "                    #counts to flux\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                    Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                    annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "     \n",
    "    \n",
    "     ## Trying to plot the images now\n",
    "        fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in rows:\n",
    "            if row['Flag'] == 'Valid':\n",
    "                target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "                annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "                target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "                annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "        ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd best version of code\n",
    "fixed duplicates, does not yet have overlap subtraction in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "        print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "        print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        target_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "\n",
    "                    \n",
    "                    #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                })\n",
    "                \n",
    "            # Append valid_rows to rows (if needed for overall storage)\n",
    "            #rows.extend(valid_rows)\n",
    "        print('valid rows', valid_rows)\n",
    "\n",
    "    # Plotting for current image\n",
    "    # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']),\n",
    "                                            row['Annulus_Inner_Radius'],\n",
    "                                            row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm)\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST VERSION OF THE CODE\n",
    "put the overlapping SUBTRACTION code into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0]\n",
    "                            target_counts -= overlap_counts\n",
    "\n",
    "\n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        target_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "\n",
    "                    \n",
    "                    #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                })\n",
    "                \n",
    "            # Append valid_rows to rows (if needed for overall storage)\n",
    "            #rows.extend(valid_rows)\n",
    "        #print('valid rows', valid_rows)\n",
    "\n",
    "    # Plotting for current image\n",
    "    # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']),\n",
    "                                            row['Annulus_Inner_Radius'],\n",
    "                                            row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm)\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including source detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "error was calculated by determining the error from the annuli and overlapping areas,\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6 ,'w4':12.98 }\n",
    "\n",
    "'''REMEMBER TO\n",
    "Convert the sensitivities from jy to dn and then back to jy after running it through aperture photometry\n",
    "'''\n",
    "#noise_level =  {'w1': 0.0000136,'w2': 0.0000196,'w3': 0.000172 ,'w4': 0.00108 } THIS IS IN Jy. convert it to DN:\n",
    "noise_level =  {'w1': 8.6, 'w2': 7.607, 'w3': 59.54229 , 'w4': 20.093 }\n",
    "\n",
    "\n",
    "#flux uncertainty\n",
    "#bkg_error = annulus_error_var\n",
    "#overlap_error = overlap_error_var\n",
    "\n",
    "#error = calculate_total_error(data, bkg_error, overlapping counts? yes easy)\n",
    "#_error_var = _photo_table['aperture_sum_err'][0]\n",
    "tot_err= []\n",
    "def calc_tot_err(target_error_var, annulus_error_var, overlap_error_var):\n",
    "     tot_err = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "     return tot_err\n",
    "     \n",
    "def create_error_array(shape, noise_level):\n",
    "     #creates an error array with a constant noise level, although this makes me wonder about what to do for areas of brightness or if that doesnt matter.\n",
    "     return np.full(shape, noise_level)\n",
    "\n",
    "     \n",
    "# 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initiate dict for the std of each image\n",
    "cutout_std =  {'w1': [], 'w2': [], 'w3': [], 'w4': []}\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "        \n",
    "        #calculate the std of each cutout image to then be used for determining the error in the flux derivations\n",
    "        if band_id in cutout_std:\n",
    "            mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0)\n",
    "            cutout_std[band_id].append(std)\n",
    "            print(cutout_std)\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            if band_id in noise_level and cutout_std:\n",
    "                                 band_noise_level = noise_level[band_id]\n",
    "                                 band_std = cutout_std[band_id] \n",
    "                                 error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                                 error2 = create_error_array(cutout_data.shape, band_std)     ## using error2 seems to give the best estimation of uncertainty for the Flux values.\n",
    "                                 overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture, error=error2)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error_var = overlap_photo_table['aperture_sum_err'][0]\n",
    "                            #print(overlap_error_var)\n",
    "                            if target_counts > 0:\n",
    "                                target_counts -= overlap_counts\n",
    "                            \n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            if band_id in noise_level and cutout_std:\n",
    "                                band_noise_level = noise_level[band_id]\n",
    "                                band_std = cutout_std[band_id]\n",
    "                                error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                                error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                                overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture, error=error2)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error_var = overlap_photo_table['aperture_sum_err'][0]\n",
    "                            #print(overlap_error_var)\n",
    "                            if target_counts > 0:\n",
    "                                target_counts -= overlap_counts\n",
    "                            \n",
    "\n",
    "\n",
    "            if overlap:\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                if band_id in noise_level and cutout_std:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    band_std = cutout_std[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                    target_photo_table = aperture_photometry(cutout_data, target_aperture, error=error2) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_error_var = target_photo_table['aperture_sum_err'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [], 'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [],  'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var})\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                if band_id in noise_level and cutout_std:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    band_std = cutout_std[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                    annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture, error=error2)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                annulus_error_var = annulus_photo_table['aperture_sum_err'][0]\n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [], 'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var })\n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [],'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                    'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [],  'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var })\n",
    "                \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                if band_id in noise_level and cutout_std:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    band_std = cutout_std[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                    target_photo_table = aperture_photometry(cutout_data, target_aperture, error=error2) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_error_var = target_photo_table['aperture_sum_err'][0]\n",
    "                \n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [],'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var})\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                if band_id in noise_level and cutout_std:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    band_std = cutout_std[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                    annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                annulus_error_var = annulus_photo_table['aperture_sum_err'][0]\n",
    "                \n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [],  'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                              'Offset in Arcseconds': [],   'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': []})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [],\n",
    "                    'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', \n",
    "                    'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, 'Exists?': 'No', 'Point Source Position' : [], 'Offset in Arcseconds': [],\n",
    "                     'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': [] })\n",
    "\n",
    "\n",
    "        #Source detection code\n",
    "        mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0)  \n",
    "       #print((mean, median, std))\n",
    "\n",
    "        # subtract the background and find FWHM of sources at a certain threshold\n",
    "        #started at fwhm= 3 and threshold = 5\n",
    "        daofind = DAOStarFinder(fwhm=8, threshold=1*std) # find the stars in the image that have FWHMs of around 3 pixels and have peaks approximately 5-sigma above the background. \n",
    "        sources = daofind(cutout_data - median)  \n",
    "        #print(type(sources))\n",
    "        # will likely run into iissues in the code below\n",
    "        for col in sources.colnames:  \n",
    "            if col not in ('id', 'npix'):\n",
    "                sources[col].info.format = '%.2f'  # for consistent table output\n",
    "       # sources.pprint(max_width=3000)  \n",
    "\n",
    "        #likely the flux labeled in this is not converted!\n",
    "        \n",
    "        # plot the image with marked locations of all the sources it detected.\n",
    "        detected_positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "        apertures = CircularAperture(detected_positions, r=2)\n",
    "\n",
    "\n",
    "        # Plotting for current image\n",
    "        # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        \n",
    "        # Was there a point source there?\n",
    "        pixelsinarc = 0.0003819444391411 * 3600 ## 0.0003819444391411 is the number found in the header of the image for the scale of pixels in degrees for the fits image.\n",
    "        detectedpos_all = []\n",
    "        #rows = [row for row in rows if row['Flag'] == 'Valid']\n",
    "        for row in valid_rows_filtered:\n",
    "            apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "            for detected_position in detected_positions:\n",
    "                detected_x, detected_y = detected_position\n",
    "                distance = dist((row['X'], row['Y']), (detected_x, detected_y) ) #distance from the center of the xray source to the center of the detected source\n",
    "                if distance <= row['Radius']: \n",
    "                    row['Exists?'] = 'Point Source Detected'\n",
    "                    row['Point Source Position'].append((detected_x, detected_y))\n",
    "                    dist_in_arc = distance * pixelsinarc\n",
    "                    row['Offset in Arcseconds'].append((dist_in_arc))\n",
    "                    detectedpos_all.append(detected_position) \n",
    "                    #print(f\"Number of detected positions within forced apertures: {len(detectedpos_all)}\")\n",
    "\n",
    "\n",
    "        Yes = []\n",
    "        YesRadius= 5\n",
    "        for row in valid_rows_filtered:\n",
    "                    apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "                    for detected_position in detected_positions:\n",
    "                        detected_x, detected_y = detected_position\n",
    "                        distance = dist((row['X'], row['Y']), (detected_x, detected_y) )\n",
    "\n",
    "                        if distance <= YesRadius:\n",
    "                            row['Exists?'] = 'Yes!!'\n",
    "                            Yes.append((row['X'], row['Y']))\n",
    "                 \n",
    "        #calculate error, convert it back to flux and append the total error\n",
    "        #total_error = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "        for row in valid_rows_filtered:\n",
    "            #print(row['Overlap Error'])\n",
    "            if row['Overlap Error']:  # Check if the list is not empty\n",
    "                overlap_error_var = row['Overlap Error']  \n",
    "            else:\n",
    "                overlap_error_var = 0  # Use 0 if the list is empty\n",
    "            total_error = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "            if band_id in flux_zmfd and instr_zpmag: \n",
    "                flx_conv_fact = flux_zmfd[band_id]\n",
    "                M0instr = instr_zpmag[band_id]\n",
    "                Mcal_error = M0instr - 2.5*(np.log10(total_error))     #converting counts to magnitude\n",
    "                total_error_flx = flx_conv_fact * 10**(Mcal_error/-2.5)#convert Magnitude to Flux\n",
    "                flux_uncertainty_value = total_error_flx      #may need to index the variable here.\n",
    "                #print(f'Total error in flux for band {band_id}: {flux_uncertainty_value}')\n",
    "                row['Flux Uncertainty'].append(flux_uncertainty_value)\n",
    "            else:\n",
    "                 print(f'Missing data for band {band_id}. Skipping...')\n",
    "                             \n",
    "\n",
    "        # Update rows with valid_rows_filtered information\n",
    "        for valid_row in valid_rows_filtered:\n",
    "            for row in rows:\n",
    "                if row['band_id'] == valid_row['band_id'] and row['Region'] == valid_row['Region']:\n",
    "                    row.update(valid_row)\n",
    "\n",
    "        #print('valid sources', valid_rows_filtered)\n",
    "\n",
    "        #print( len(detectedpos_all))\n",
    "        if len(detectedpos_all) > 0:\n",
    "            apertures_detected = CircularAperture(detectedpos_all, r=2)\n",
    "        if len(Yes) > 0:\n",
    "            apertures_Yes = CircularAperture(Yes, r=YesRadius)\n",
    "\n",
    "\n",
    "\n",
    "         # Plotting for current image\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "            \n",
    "            apertures.plot(color='#98ff98', lw=.5, alpha=0.5) \n",
    "            apertures_detected.plot(color='#FF4500', lw=.5, alpha=0.5)  #  #FF69B4 for hot pink\n",
    "            apertures_Yes.plot(color='green', lw=.5, alpha=0.5) \n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm, interpolation='nearest')\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "print(len(display_data))\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagating uncertainty correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "error was calculated by determining the error from the annuli and overlapping areas,\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6 ,'w4':12.98 }\n",
    "\n",
    "'''REMEMBER TO\n",
    "Convert the sensitivities from jy to dn and then back to jy after running it through aperture photometry\n",
    "'''\n",
    "#noise_level =  {'w1': 0.0000136,'w2': 0.0000196,'w3': 0.000172 ,'w4': 0.00108 } THIS IS IN Jy. convert it to DN:\n",
    "noise_level =  {'w1': 8.6, 'w2': 7.607, 'w3': 59.54229 , 'w4': 20.093 }\n",
    "\n",
    "\n",
    "#flux uncertainty\n",
    "#bkg_error = annulus_error_var\n",
    "#overlap_error = overlap_error_var\n",
    "\n",
    "#error = calculate_total_error(data, bkg_error, overlapping counts? yes easy)\n",
    "#_error_var = _photo_table['aperture_sum_err'][0]\n",
    "tot_err= []\n",
    "def calc_tot_err(target_error_var, annulus_error_var, overlap_error_var):\n",
    "     tot_err = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "     return tot_err\n",
    "     \n",
    "def create_error_array(shape, noise_level):\n",
    "     #creates an error array with a constant noise level, although this makes me wonder about what to do for areas of brightness or if that doesnt matter.\n",
    "     return np.full(shape, noise_level)\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "        \n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error = np.sqrt(overlap_counts)\n",
    "                            \n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask))\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error = np.sqrt(overlap_counts)\n",
    "                            \n",
    "            if overlap:\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_counts -= overlap_counts\n",
    "\n",
    "                # so that i dont take the log or sqrt of a negative number or zero and get an error\n",
    "                if target_counts > 0: # \n",
    "                    target_error= np.sqrt(target_counts)\n",
    "                    #propagated error of overlap error\n",
    "                    target_overlap_counts_err = np.sqrt(target_error**2 + overlap_error**2)\n",
    "                    #print(target_counts)\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                         \n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error = (2.5*target_overlap_counts_err) / (target_counts * np.log(10))\n",
    "                         target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [], 'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [],  'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error })\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                \n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                    overlapannulus_error = np.sqrt(annulus_counts) # the error of the annulus for sources that overlap\n",
    "                     # to avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error_ann = (2.5 * overlapannulus_error) / (annulus_counts * np.log(10))\n",
    "                         annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "\n",
    "\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "                bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "                tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "                net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "            \n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': net_flx_err, 'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error})\n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                    'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [],  'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error})\n",
    "                \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    target_error = np.sqrt(target_counts)\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error = (2.5*target_error) / (target_counts * np.log(10))\n",
    "                         target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [],'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error})\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                # the error of the annulus for sources that overlap\n",
    "                \n",
    "                if annulus_counts > 0:\n",
    "                    annulus_error = np.sqrt(annulus_counts)\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error_ann = (2.5 * annulus_error) / (annulus_counts * np.log(10))\n",
    "                         annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "               #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "                bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "                tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "                net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "\n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,  'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                              'Offset in Arcseconds': [],   'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': []})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,\n",
    "                    'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', \n",
    "                    'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, 'Exists?': 'No', 'Point Source Position' : [], 'Offset in Arcseconds': [],\n",
    "                     'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': []})\n",
    "\n",
    "\n",
    "        #Source detection code\n",
    "        mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0)  \n",
    "       #print((mean, median, std))\n",
    "\n",
    "        # subtract the background and find FWHM of sources at a certain threshold\n",
    "        #started at fwhm= 3 and threshold = 5\n",
    "        daofind = DAOStarFinder(fwhm=8, threshold=1*std) # find the stars in the image that have FWHMs of around 3 pixels and have peaks approximately 5-sigma above the background. \n",
    "        sources = daofind(cutout_data - median)  \n",
    "        #print(type(sources))\n",
    "        # will likely run into iissues in the code below\n",
    "        for col in sources.colnames:  \n",
    "            if col not in ('id', 'npix'):\n",
    "                sources[col].info.format = '%.2f'  # for consistent table output\n",
    "       # sources.pprint(max_width=3000)  \n",
    "\n",
    "        #likely the flux labeled in this is not converted!\n",
    "        \n",
    "        # plot the image with marked locations of all the sources it detected.\n",
    "        detected_positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "        apertures = CircularAperture(detected_positions, r=2)\n",
    "\n",
    "\n",
    "        # Plotting for current image\n",
    "        # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        \n",
    "        # Was there a point source there?\n",
    "        pixelsinarc = 0.0003819444391411 * 3600 ## 0.0003819444391411 is the number found in the header of the image for the scale of pixels in degrees for the fits image.\n",
    "        detectedpos_all = []\n",
    "        #rows = [row for row in rows if row['Flag'] == 'Valid']\n",
    "        for row in valid_rows_filtered:\n",
    "            apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "            for detected_position in detected_positions:\n",
    "                detected_x, detected_y = detected_position\n",
    "                distance = dist((row['X'], row['Y']), (detected_x, detected_y) ) #distance from the center of the xray source to the center of the detected source\n",
    "                if distance <= row['Radius']: \n",
    "                    row['Exists?'] = 'Point Source Detected'\n",
    "                    row['Point Source Position'].append((detected_x, detected_y))\n",
    "                    dist_in_arc = distance * pixelsinarc\n",
    "                    row['Offset in Arcseconds'].append((dist_in_arc))\n",
    "                    detectedpos_all.append(detected_position) \n",
    "                    #print(f\"Number of detected positions within forced apertures: {len(detectedpos_all)}\")\n",
    "\n",
    "\n",
    "        Yes = []\n",
    "        YesRadius= 5\n",
    "        for row in valid_rows_filtered:\n",
    "                    apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "                    for detected_position in detected_positions:\n",
    "                        detected_x, detected_y = detected_position\n",
    "                        distance = dist((row['X'], row['Y']), (detected_x, detected_y) )\n",
    "\n",
    "                        if distance <= YesRadius:\n",
    "                            row['Exists?'] = 'Yes!!'\n",
    "                            Yes.append((row['X'], row['Y']))\n",
    "                 \n",
    "        \n",
    "        # Update rows with valid_rows_filtered information\n",
    "        for valid_row in valid_rows_filtered:\n",
    "            for row in rows:\n",
    "                if row['band_id'] == valid_row['band_id'] and row['Region'] == valid_row['Region']:\n",
    "                    row.update(valid_row)\n",
    "\n",
    "        #print('valid sources', valid_rows_filtered)\n",
    "\n",
    "        #print( len(detectedpos_all))\n",
    "        if len(detectedpos_all) > 0:\n",
    "            apertures_detected = CircularAperture(detectedpos_all, r=2)\n",
    "        if len(Yes) > 0:\n",
    "            apertures_Yes = CircularAperture(Yes, r=YesRadius)\n",
    "        \n",
    "       # xc = 244.422687\t #19.014239\t\n",
    "       # yc=  191.596758# 310.340772\n",
    "    \n",
    "\n",
    "         # Plotting for current image\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "            \n",
    "            apertures.plot(color='#98ff98', lw=.5, alpha=0.5) \n",
    "            apertures_detected.plot(color='#FF4500', lw=.5, alpha=0.5)  #  #FF69B4 for hot pink\n",
    "            apertures_Yes.plot(color='green', lw=.5, alpha=0.5) \n",
    "\n",
    "            # curious ones\n",
    "           # curious = CircularAperture((xc,yc),5)\n",
    "           # curious.plot(color='red', lw=.5, alpha=0.5)\n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm, interpolation='nearest')\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "print(len(display_data))\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want a csv version of this too\n",
    "for column in display_data.columns:\n",
    "    if display_data[column].apply(lambda x: isinstance(x, set)).any():\n",
    "        display_data[column] = display_data[column].apply(lambda x: str(x))\n",
    "for column in display_data.columns:\n",
    "    if display_data[column].apply(lambda x: isinstance(x, list)).any():\n",
    "        display_data[column] = display_data[column].apply(lambda x: str(x))\n",
    "\n",
    "data = display_data.loc[display_data['Flag']== 'Valid']\n",
    "\n",
    "data_out = Table.from_pandas(data)\n",
    "output_path = '../Data/Flux_uncs.csv'\n",
    "\n",
    "# Write the table in csv format\n",
    "data_out.write(output_path, format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:163\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:128\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:69\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     68\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m band_label \u001b[38;5;129;01min\u001b[39;00m band_labels:\n\u001b[1;32m     14\u001b[0m     wavelength \u001b[38;5;241m=\u001b[39m wavelengths[band_label]\n\u001b[0;32m---> 15\u001b[0m     flux_density, flux_density_unc \u001b[38;5;241m=\u001b[39m \u001b[43mflux_dens\u001b[49m\u001b[43m(\u001b[49m\u001b[43myes_sources\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNet Flux (Jy)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myes_sources\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFlux Uncertainty\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# plot flux density vs wavelength\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m band_label \u001b[38;5;129;01min\u001b[39;00m band_labels:\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mflux_dens\u001b[0;34m(net_flx, net_flx_err, wavelength)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflux_dens\u001b[39m(net_flx, net_flx_err, wavelength):\n\u001b[1;32m      8\u001b[0m     flux_density \u001b[38;5;241m=\u001b[39m net_flx \u001b[38;5;241m/\u001b[39m wavelength\n\u001b[0;32m----> 9\u001b[0m     flux_density_unc \u001b[38;5;241m=\u001b[39m \u001b[43mnet_flx_err\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwavelength\u001b[49m\n\u001b[1;32m     10\u001b[0m     flux_density_and_uncertainty \u001b[38;5;241m=\u001b[39m flux_density, flux_density_unc\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flux_density_and_uncertainty\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:124\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruediv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:5639\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   5638\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m-> 5639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/base.py:1295\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1292\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1295\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:222\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m--> 222\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:170\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:127\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    124\u001b[0m         mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, mask)\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m--> 127\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m np\u001b[38;5;241m.\u001b[39mputmask(result, \u001b[38;5;241m~\u001b[39mmask, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m    130\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# 2D compat\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "yes_sources = display_data.loc[display_data['Exists?']== 'Yes!!']\n",
    "#display(yes_sources)\n",
    "#3.4, 4.6, 12, and 22\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "wavelengths = {'w1': 3.4 ,'w2': 4.6,'w3': 12,'w4': 22}\n",
    "#define function to get flux density by dividing it by the wavelength\n",
    "def flux_dens(net_flx, net_flx_err, wavelength):\n",
    "    flux_density = net_flx / wavelength\n",
    "    flux_density_unc = net_flx_err / wavelength\n",
    "    flux_density_and_uncertainty = flux_density, flux_density_unc\n",
    "    return flux_density_and_uncertainty \n",
    "\n",
    "for band_label in band_labels:\n",
    "    wavelength = wavelengths[band_label]\n",
    "    flux_density, flux_density_unc = flux_dens(yes_sources['Net Flux (Jy)'], yes_sources['Flux Uncertainty'], wavelength)\n",
    "    # plot flux density vs wavelength\n",
    "    if band_label in band_labels:\n",
    "        print(f'Band {band_labels[band_label]}: ')\n",
    "        plt.plot(wavelength, flux_density)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
