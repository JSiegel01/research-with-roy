{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyvo as vo\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "from photutils.utils import calc_total_error\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "import json\n",
    "\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from photutils.detection import DAOStarFinder\n",
    "from astropy.stats import mad_std, sigma_clipped_stats\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going to try debugging this one now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n",
    "#empty data frame to append values of flux to\n",
    "rows=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the image catalog in the WISE database\n",
    "#define coordinates\tmake it possible to run a list over this with all of the ra and decs\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "#print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n",
    "\n",
    "M0instr =  12.98 # found the relative instrumental zero point magnitude in this specific band (W4)\n",
    "flx_conv_fact =  8.363 # the Zero Magnitude Flux Density conversion factor in this band\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "#extract a cutout for plotting and KDTree\n",
    "wcs = WCS(image1[0].header)\n",
    "#cuting out the image of the galaxy apart from the rest of the background.\n",
    "cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "wcs = cutout.wcs\n",
    "\n",
    "#####   constants in every image:\n",
    "\n",
    "#plot the sources with circles\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# convert Ra and dec values to pixel coordinates\n",
    "positions = wcs.world_to_pixel_values(ra, dec)\n",
    "positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "#define the distance threshold for the KDTree grouping (in pixels)\n",
    "distance_threshold = 5\n",
    "\n",
    "#build the KDTree for efficient grouping\n",
    "tree = KDTree(positions)\n",
    "\n",
    "#query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "print(groups)\n",
    "# consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "unique_groups = []\n",
    "seen = set()\n",
    "for group in groups:\n",
    "    group = tuple(sorted(group))\n",
    "    if group not in seen:\n",
    "        seen.add(group)\n",
    "        unique_groups.append(group)\n",
    "print(unique_groups)\n",
    "# for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "#represents the consolidated postion of potentially multiple detections of one source.\n",
    "grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "print(grouped_positions)\n",
    "\n",
    "#define the Region(s) Of Interest (center x, center y, radius)\n",
    "ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "#empty data frame to append values of flux to\n",
    "rows=[]\n",
    "\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "#####  End of constants\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(image_data.shape[0], image_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(image_data.shape[0], image_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = image_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(image_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts<= 0: # \n",
    "                    target_flux # avoid taking the log of zero or negative value\n",
    "                else:\n",
    "                        #counts to flux\n",
    "                    Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                    target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                    #calculate area of annulus\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(image_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts <= 0:\n",
    "                    annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "                else:\n",
    "                    #counts to flux\n",
    "                    Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                    annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': image_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "            #filter only valid sources to conduct the overlapping photometry again. \n",
    "        # so that sources with an acceptable amount of overlap have their overlapping counts subtracted from the nonoverlapping counts.\n",
    "        #valid_sources = display_data[display_data['Flag'] == 'Valid']\n",
    "\n",
    "        for i, valid_row in display_data[display_data['Flag'] == 'Valid'].iterrows():\n",
    "            x, y, r = valid_row['X'], valid_row['Y'], valid_row['Radius']\n",
    "            target_aperture = CircularAperture((x, y), r)\n",
    "            target_photo_table = aperture_photometry(image_data, target_aperture)\n",
    "            target_counts = target_photo_table['aperture_sum'][0]\n",
    "            \n",
    "            if target_counts <= 0:\n",
    "                target_flux = 0\n",
    "            else:\n",
    "                Mcal_trgt = M0instr - 2.5 * (np.log10(target_counts))\n",
    "                target_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5)\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "            non_overlapping_counts = target_counts\n",
    "\n",
    "            for j, valid_row2 in display_data[display_data['Flag'] == 'Valid'].iterrows():\n",
    "                if i != j:\n",
    "                    x2, y2, r2 = valid_row2['X'], valid_row2['Y'], valid_row2['Radius']\n",
    "                    distance = dist((x, y), (x2, y2))\n",
    "                    if distance < r + r2:\n",
    "                        overlap_percent = (r + r2 - distance) / (r + r2)\n",
    "                        if overlap_percent > .01: # i think i will have to fiddle around with this\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(image_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0]\n",
    "                            #Subtract overlapping data from non overlapping and assign the data to the variable of non_overlapping_counts\n",
    "                            non_overlapping_counts -= overlap_counts\n",
    "                            \n",
    "\n",
    "            if non_overlapping_counts <= 0: # if counts are 0 or negative, dont do flux conversion cuz it wont work. assigns the flux to be zero\n",
    "                net_flux = 0\n",
    "            else:\n",
    "                Mcal_trgt = M0instr - 2.5 * (np.log10(non_overlapping_counts))\n",
    "                net_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5) - tot_bg\n",
    "\n",
    "            # for each location of the overlapping source in the pandas dataframe table, assign whether it is still valid or not.\n",
    "            display_data.loc[i, 'Net Flux (Jy)'] = net_flux\n",
    "            display_data.loc[i, 'Flag'] = 'Valid' if net_flux > 0 else 'Low Flux'\n",
    "\n",
    "     \n",
    "        \n",
    "     ## Trying to plot the images now\n",
    "     #extract a cutout and plot it\n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (400,400), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "    \n",
    "        #plotting the image\n",
    "        fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in display_data.itertuples():\n",
    "            if row.Flag == 'Valid':\n",
    "                target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "                annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "                target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "                annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "        ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#rows.append({'band_id': {band_labels[band_id]},\n",
    "    \n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "#visualizing the apertures\n",
    "\n",
    "#for row in display_data.itertuples():\n",
    "    #if row.Flag == 'Valid':\n",
    "       # target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "       # annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "       # target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "       # annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "\n",
    "####if you want to see all of them use the code below:\n",
    "#for ((x, y), r, annulus_inner, annulus_outer) in ROI:\n",
    "    #target_apertureplt = CircularAperture((x,y),r)\n",
    "   # annulus_apertureplt = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "   # target_apertureplt.plot(color='red', lw = 1.5)\n",
    "   # annulus_apertureplt.plot(color='red', lw = 1.5)\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('Dec')\n",
    "plt.grid(color='white', ls='dotted')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just one band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "#for i in range(len(im_table)):\n",
    "   # print(im_table[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(im_table)):\n",
    "    if im_table[i]['sia_bp_id']:\n",
    "\n",
    "        print(im_table[i].getdataurl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = im_table[0].getdataurl()\n",
    "#Download the image and open it in Astropy\n",
    "fname = download_file(data_url, cache=True)\n",
    "image1= fits.open(fname)\n",
    "image_data= image1[0].data\n",
    "print(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "sources_7793\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "hdr = image1[0].header\n",
    "hdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract a cutout for plotting and KDTree\n",
    "wcs = WCS(image1[0].header)\n",
    "#cuting out the image of the galaxy apart from the rest of the background.\n",
    "cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "print(image_data.shape)\n",
    "print(cutout.data.shape)\n",
    "# THIS IS WHERE THE DISCREPANCY IS HAPPENING.\n",
    "# When i make the image shape the same, the positions of the sources are almost identical to the \n",
    "# image downloaded code.\n",
    "wcs = cutout.wcs\n",
    "cutout_data = cutout.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the KDTree\n",
    "# convert Ra and dec values to pixel coordinates\n",
    "positions = wcs.world_to_pixel_values(ra, dec)\n",
    "positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "#define the distance threshold for the KDTree grouping (in pixels)\n",
    "distance_threshold = 10\n",
    "\n",
    "#build the KDTree for efficient grouping\n",
    "tree = KDTree(positions)\n",
    "\n",
    "#query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "print(groups)\n",
    "# consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "unique_groups = []\n",
    "seen = set()\n",
    "for group in groups:\n",
    "    group = tuple(sorted(group))\n",
    "    if group not in seen:\n",
    "        seen.add(group)\n",
    "        unique_groups.append(group)\n",
    "print(unique_groups)\n",
    "# for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "#represents the consolidated postion of potentially multiple detections of one source.\n",
    "grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "print(grouped_positions)\n",
    "# a problem could be with grouped postions maybe?\n",
    "# here is where the code between downloading the image and using the URL differs!\n",
    "#  the position of sources is slightly altered for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define the Region(s) Of Interest (center x, center y, radius)\n",
    "ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "#empty data frame to append values of flux to\n",
    "rows=[]\n",
    "\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n",
    "\n",
    "M0instr =  12.98 # found the relative instrumental zero point magnitude in this specific band (W4)\n",
    "flx_conv_fact =  8.363 # the Zero Magnitude Flux Density conversion factor in this band\n",
    "cutout_data.shape\n",
    "grouped_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check for overlap and perform aperture photometry\n",
    "for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "    overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "    non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "    for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "        if i != j: # ensures that a source is not compared to itself! wow\n",
    "            distance = dist((x, y) , (x2, y2)) \n",
    "            if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                if overlap_percent > .5:\n",
    "                    overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                    break\n",
    "                else: \n",
    "                    overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                    non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                    # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                    # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                \n",
    "    if overlap:\n",
    "        #flag the sources that overlap\n",
    "        rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                      'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "    else: #perform all the aperture photometry stuff\n",
    "        # For the Target objects in the little aperture circle define their target apertures\n",
    "        target_aperture = CircularAperture((x,y),r,)\n",
    "    \n",
    "        #perform aperture photometry on target\n",
    "        # also now apply the masked data\n",
    "        masked_data = cutout_data * non_overlapping_mask\n",
    "        target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "        target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "        if target_counts<= 0: # \n",
    "            target_flux # avoid taking the log of zero or negative value\n",
    "        else:\n",
    "                #counts to flux\n",
    "            Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "            target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "            #calculate area of annulus\n",
    "        target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "        # For the Background Annuli of outside of the Target\n",
    "        #define the background annulus for the target\n",
    "        annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "        #perform aperture photometry on annuli\n",
    "        annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "        annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "    \n",
    "        if annulus_counts <= 0:\n",
    "            annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "        else:\n",
    "            #counts to flux\n",
    "            Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "            annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "        #calculate area of annulus\n",
    "        annulus_area = annulus_aperture.area\n",
    "\n",
    "        # do the calculations for including a Background aperture\n",
    "    \n",
    "        #Calculating the net flux:\n",
    "        #calculate the mean background per pixel\n",
    "        bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "        #calculate the total background in the target aperture\n",
    "        tot_bg = bg_perpixel * target_area\n",
    "\n",
    "        #Subtract background from the target flux\n",
    "        net_flx = target_flux - tot_bg\n",
    "    \n",
    "        #   Append the result as a dictionary to the list named 'rows'\n",
    "        rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                 'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                   'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                     'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                       'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "    \n",
    "\n",
    "#append the rows to the empty dataframe    \n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#visualizing the apertures that are postive and dont overlap to a detrimental degree. if you want to see all of them take out the (== 'Valid') part of the viz code\n",
    "fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "for row in display_data.itertuples():\n",
    "    if row.Flag == 'Valid':\n",
    "        target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "        annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "        target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "        annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "ax.set_xlabel('Right Ascension')\n",
    "ax.set_ylabel('Declination')\n",
    "#plt.title(f'Band {band_labels[band_id]}')\n",
    "plt.show()\n",
    "\n",
    "display_data.loc[display_data['Flag']== 'Valid']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dont think i need this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#filter only valid sources to conduct the overlapping photometry again. \n",
    "# so that sources with an acceptable amount of overlap have their overlapping counts subtracted from the nonoverlapping counts.\n",
    "valid_sources = display_data[display_data['Flag'] == 'Valid']\n",
    "\n",
    "for i, valid_row in valid_sources.iterrows():\n",
    "    x, y, r = valid_row['X'], valid_row['Y'], valid_row['Radius']\n",
    "    target_aperture = CircularAperture((x, y), r)\n",
    "    target_photo_table = aperture_photometry(cutout_data, target_aperture)\n",
    "    target_counts = target_photo_table['aperture_sum'][0]\n",
    "    \n",
    "    if target_counts <= 0:\n",
    "        target_flux = 0\n",
    "    else:\n",
    "        Mcal_trgt = M0instr - 2.5 * (np.log10(target_counts))\n",
    "        target_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5)\n",
    "        target_area = target_aperture.area\n",
    "\n",
    "    non_overlapping_counts = target_counts\n",
    "\n",
    "    for j, valid_row2 in valid_sources.iterrows():\n",
    "        if i != j:\n",
    "            x2, y2, r2 = valid_row2['X'], valid_row2['Y'], valid_row2['Radius']\n",
    "            distance = dist((x, y), (x2, y2))\n",
    "            if distance < r + r2:\n",
    "                overlap_percent = (r + r2 - distance) / (r + r2)\n",
    "                if overlap_percent > .01: # i think i will have to fiddle around with this\n",
    "                    overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                    overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                    overlap_counts = overlap_photo_table['aperture_sum'][0]\n",
    "                    #Subtract overlapping data from non overlapping and assign the data to the variable of non_overlapping_counts\n",
    "                    non_overlapping_counts -= overlap_counts\n",
    "                    \n",
    "\n",
    "    if non_overlapping_counts <= 0: # if counts are 0 or negative, dont do flux conversion cuz it wont work. assigns the flux to be zero\n",
    "        net_flux = 0\n",
    "    else:\n",
    "        Mcal_trgt = M0instr - 2.5 * (np.log10(non_overlapping_counts))\n",
    "        net_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5) - tot_bg\n",
    "\n",
    "    # for each location of the overlapping source in the pandas dataframe table, assign whether it is still valid or not.\n",
    "    display_data.loc[i, 'Net Flux (Jy)'] = net_flux\n",
    "    display_data.loc[i, 'Flag'] = 'Valid' if net_flux > 0 else 'Low Flux'\n",
    "\n",
    "\n",
    "#visualizing the apertures that are postive and dont overlap to a detrimental degree. if you want to see all of them take out the (== 'Valid') part of the viz code\n",
    "fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "for row in display_data.itertuples():\n",
    "    if row.Flag == 'Valid':\n",
    "        target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "        annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "        target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "        annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "ax.set_xlabel('Right Ascension')\n",
    "ax.set_ylabel('Declination')\n",
    "#plt.title(f'Band {band_labels[band_id]}')\n",
    "plt.show()\n",
    "\n",
    "display_data.loc[display_data['Flag']== 'Valid']\n",
    "#display_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the new code for when i want to apply it to all wavelengths :\n",
    "\n",
    "remember to include the code for different flux conversions for each band!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE THIS WHEN YOU HAVE PUT IN THE CONVERSION Code\n",
    "M0instr =  12.98 # found the relative instrumental zero point magnitude in this specific band (W4)\n",
    "flx_conv_fact =  8.363 # the Zero Magnitude Flux Density conversion factor in this band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dont use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_alldata = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "       # print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data # maybe this needs to be assigned as a dictionary for each of them.\n",
    "        cutout_alldata.append({ 'Band': {band_labels[band_id]}, 'CutoutData' : cutout_data, 'WCS': wcs})\n",
    "cutout_alldata = pd.DataFrame(cutout_alldata)\n",
    "cutout_alldata['ROI'] = np.nan\n",
    "display(cutout_alldata)\n",
    "\n",
    "#cutout_alldata = pd.DataFrame(columns=['Band', 'CutoutData', 'WCS'])  # Initialize with columns\n",
    "#for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "  #  band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "   # if band_id in band_labels:\n",
    "   #    # print(f'Band {band_labels[band_id]}: ')\n",
    "    #    data_url = im_table[i].getdataurl()\n",
    "   #     #Download the image and open it in Astropy\n",
    "   #     fname = download_file(data_url, cache=True)\n",
    "   #     image1= fits.open(fname)\n",
    "    #    image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "     #   wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "     #   cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "      #  wcs = cutout.wcs\n",
    "      #  cutout_data = cutout.data # maybe this needs to be assigned as a dictionary for each of them.\n",
    "      #  cutout_alldata.loc[len(cutout_alldata)] = [band_id, cutout_data, wcs]\n",
    "        #cutout_alldata._append({ 'Band': {band_labels[band_id]}, 'CutoutData' : cutout_data, 'WCS': wcs}, ignore_index= True)\n",
    "\n",
    "display(cutout_alldata)\n",
    "\n",
    "for idx, row in cutout_alldata.iterrows():\n",
    "    wcs = row.WCS\n",
    "    positions = wcs.world_to_pixel_values(ra, dec)\n",
    "    positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "    #define the distance threshold for the KDTree grouping (in pixels)\n",
    "    distance_threshold = 11\n",
    "\n",
    "    #build the KDTree for efficient grouping\n",
    "    tree = KDTree(positions)\n",
    "\n",
    "    #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "    groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "    print(groups)\n",
    "    # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "    unique_groups = []\n",
    "    seen = set()\n",
    "    for group in groups:\n",
    "        group = tuple(sorted(group))\n",
    "        if group not in seen:\n",
    "            seen.add(group)\n",
    "            unique_groups.append(group)\n",
    "    print(unique_groups)\n",
    "    # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "    #represents the consolidated postion of potentially multiple detections of one source.\n",
    "    grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "    print(grouped_positions)\n",
    "\n",
    "    #define the Region(s) Of Interest (center x, center y, radius)\n",
    "    ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "    #empty data frame to append values of flux to\n",
    "    roi_str = json.dumps(ROI) # to revert back : roi_list = json.loads(cutout_alldata.at[idx, 'ROI'])\n",
    "    cutout_alldata.at[idx, 'ROI'] = roi_str\n",
    "display(cutout_alldata)\n",
    "\n",
    "for idx, row in cutout_alldata.iterrows(): \n",
    "    roi_list = json.loads(row['ROI'])\n",
    "    band_id = row['Band']\n",
    "    cutout_data = row['CutoutData']\n",
    "    #now inputting the aperture photometry part\n",
    "    # check for overlap and perform aperture photometry\n",
    "    for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(roi_list):\n",
    "        overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "        non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "        for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(roi_list): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "            if i != j: # ensures that a source is not compared to itself! wow\n",
    "                distance = dist((x, y) , (x2, y2)) \n",
    "                if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                    overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                    if overlap_percent > .5:\n",
    "                        overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                        break\n",
    "                    else: \n",
    "                        overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                        non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                        # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                        # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                    \n",
    "        if overlap:\n",
    "            #flag the sources that overlap\n",
    "            rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "        else: #perform all the aperture photometry stuff\n",
    "            # For the Target objects in the little aperture circle define their target apertures\n",
    "            target_aperture = CircularAperture((x,y),r,)\n",
    "        \n",
    "            #perform aperture photometry on target\n",
    "            # also now apply the masked data\n",
    "            masked_data = cutout_data * non_overlapping_mask\n",
    "            target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "            target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "            if target_counts<= 0: # \n",
    "                target_flux # avoid taking the log of zero or negative value\n",
    "            else:\n",
    "                    #counts to flux\n",
    "                Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                #calculate area of annulus\n",
    "            target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "            # For the Background Annuli of outside of the Target\n",
    "            #define the background annulus for the target\n",
    "            annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "            #perform aperture photometry on annuli\n",
    "            annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "            annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "        \n",
    "            if annulus_counts <= 0:\n",
    "                annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "            else:\n",
    "                #counts to flux\n",
    "                Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "            #calculate area of annulus\n",
    "            annulus_area = annulus_aperture.area\n",
    "\n",
    "            # do the calculations for including a Background aperture\n",
    "        \n",
    "            #Calculating the net flux:\n",
    "            #calculate the mean background per pixel\n",
    "            bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "            #calculate the total background in the target aperture\n",
    "            tot_bg = bg_perpixel * target_area\n",
    "\n",
    "            #Subtract background from the target flux\n",
    "            net_flx = target_flux - tot_bg\n",
    "        \n",
    "            #   Append the result as a dictionary to the list named 'rows'\n",
    "            rows.append({ 'band_id': band_id,'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                    'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                    'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                        'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                        'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "        #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "    \n",
    "display_data = pd.DataFrame(rows)\n",
    "display(display_data)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "for row in display_data.itertuples():\n",
    "    if row.Flag == 'Valid':\n",
    "        target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "        annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "        target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "        annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "ax.set_xlabel('Right Ascension')\n",
    "ax.set_ylabel('Declination')\n",
    "#plt.title(f'Band {band_labels[band_id]}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        print(data_url)\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cutting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 10\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "        print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "        print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        #empty data frame to append values of flux to\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts<= 0: # \n",
    "                    target_flux # avoid taking the log of zero or negative value\n",
    "                else:\n",
    "                        #counts to flux\n",
    "                    Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                    target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                    #calculate area of annulus\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts <= 0:\n",
    "                    annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "                else:\n",
    "                    #counts to flux\n",
    "                    Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                    annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "     \n",
    "    \n",
    "     ## Trying to plot the images now\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in display_data.itertuples():\n",
    "            if row.Flag == 'Valid':\n",
    "                target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "                annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "                target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "                annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "        ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(display_data)\n",
    "#display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best versions of the code so far\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## good but has too many duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "        print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "        print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts<= 0: # \n",
    "                    target_flux # avoid taking the log of zero or negative value\n",
    "                else:\n",
    "                        #counts to flux\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                    Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                    target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                    #calculate area of annulus\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts <= 0:\n",
    "                    annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "                else:\n",
    "                    #counts to flux\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                    Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                    annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "     \n",
    "    \n",
    "     ## Trying to plot the images now\n",
    "        fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in rows:\n",
    "            if row['Flag'] == 'Valid':\n",
    "                target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "                annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "                target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "                annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "        ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd best version of code\n",
    "fixed duplicates, does not yet have overlap subtraction in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "        print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "        print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        target_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "\n",
    "                    \n",
    "                    #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                })\n",
    "                \n",
    "            # Append valid_rows to rows (if needed for overall storage)\n",
    "            #rows.extend(valid_rows)\n",
    "        print('valid rows', valid_rows)\n",
    "\n",
    "    # Plotting for current image\n",
    "    # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']),\n",
    "                                            row['Annulus_Inner_Radius'],\n",
    "                                            row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm)\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST VERSION OF THE CODE\n",
    "put the overlapping SUBTRACTION code into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0]\n",
    "                            target_counts -= overlap_counts\n",
    "\n",
    "\n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        target_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "\n",
    "                    \n",
    "                    #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                })\n",
    "                \n",
    "            # Append valid_rows to rows (if needed for overall storage)\n",
    "            #rows.extend(valid_rows)\n",
    "        #print('valid rows', valid_rows)\n",
    "\n",
    "    # Plotting for current image\n",
    "    # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']),\n",
    "                                            row['Annulus_Inner_Radius'],\n",
    "                                            row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm)\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including source detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "error was calculated by determining the error from the annuli and overlapping areas,\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6 ,'w4':12.98 }\n",
    "\n",
    "'''REMEMBER TO\n",
    "Convert the sensitivities from jy to dn and then back to jy after running it through aperture photometry\n",
    "'''\n",
    "#noise_level =  {'w1': 0.0000136,'w2': 0.0000196,'w3': 0.000172 ,'w4': 0.00108 } THIS IS IN Jy. convert it to DN:\n",
    "noise_level =  {'w1': 8.6, 'w2': 7.607, 'w3': 59.54229 , 'w4': 20.093 }\n",
    "\n",
    "\n",
    "#flux uncertainty\n",
    "#bkg_error = annulus_error_var\n",
    "#overlap_error = overlap_error_var\n",
    "\n",
    "#error = calculate_total_error(data, bkg_error, overlapping counts? yes easy)\n",
    "#_error_var = _photo_table['aperture_sum_err'][0]\n",
    "tot_err= []\n",
    "def calc_tot_err(target_error_var, annulus_error_var, overlap_error_var):\n",
    "     tot_err = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "     return tot_err\n",
    "     \n",
    "def create_error_array(shape, noise_level):\n",
    "     #creates an error array with a constant noise level, although this makes me wonder about what to do for areas of brightness or if that doesnt matter.\n",
    "     return np.full(shape, noise_level)\n",
    "\n",
    "     \n",
    "# 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initiate dict for the std of each image\n",
    "cutout_std =  {'w1': [], 'w2': [], 'w3': [], 'w4': []}\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "        \n",
    "        #calculate the std of each cutout image to then be used for determining the error in the flux derivations\n",
    "        if band_id in cutout_std:\n",
    "            mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0)\n",
    "            cutout_std[band_id].append(std)\n",
    "            print(cutout_std)\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            if band_id in noise_level and cutout_std:\n",
    "                                 band_noise_level = noise_level[band_id]\n",
    "                                 band_std = cutout_std[band_id] \n",
    "                                 error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                                 error2 = create_error_array(cutout_data.shape, band_std)     ## using error2 seems to give the best estimation of uncertainty for the Flux values.\n",
    "                                 overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture, error=error2)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error_var = overlap_photo_table['aperture_sum_err'][0]\n",
    "                            #print(overlap_error_var)\n",
    "                            if target_counts > 0:\n",
    "                                target_counts -= overlap_counts\n",
    "                            \n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            if band_id in noise_level and cutout_std:\n",
    "                                band_noise_level = noise_level[band_id]\n",
    "                                band_std = cutout_std[band_id]\n",
    "                                error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                                error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                                overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture, error=error2)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error_var = overlap_photo_table['aperture_sum_err'][0]\n",
    "                            #print(overlap_error_var)\n",
    "                            if target_counts > 0:\n",
    "                                target_counts -= overlap_counts\n",
    "                            \n",
    "\n",
    "\n",
    "            if overlap:\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                if band_id in noise_level and cutout_std:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    band_std = cutout_std[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                    target_photo_table = aperture_photometry(cutout_data, target_aperture, error=error2) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_error_var = target_photo_table['aperture_sum_err'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [], 'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [],  'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var})\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                if band_id in noise_level and cutout_std:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    band_std = cutout_std[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                    annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture, error=error2)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                annulus_error_var = annulus_photo_table['aperture_sum_err'][0]\n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [], 'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var })\n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [],'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                    'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [],  'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var })\n",
    "                \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                if band_id in noise_level and cutout_std:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    band_std = cutout_std[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                    target_photo_table = aperture_photometry(cutout_data, target_aperture, error=error2) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_error_var = target_photo_table['aperture_sum_err'][0]\n",
    "                \n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [],'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var})\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                if band_id in noise_level and cutout_std:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    band_std = cutout_std[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    error2 = create_error_array(cutout_data.shape, band_std)\n",
    "                    annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                annulus_error_var = annulus_photo_table['aperture_sum_err'][0]\n",
    "                \n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [],  'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                              'Offset in Arcseconds': [],   'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': []})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [],\n",
    "                    'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', \n",
    "                    'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, 'Exists?': 'No', 'Point Source Position' : [], 'Offset in Arcseconds': [],\n",
    "                     'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': [] })\n",
    "\n",
    "\n",
    "        #Source detection code\n",
    "        mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0)  \n",
    "       #print((mean, median, std))\n",
    "\n",
    "        # subtract the background and find FWHM of sources at a certain threshold\n",
    "        #started at fwhm= 3 and threshold = 5\n",
    "        daofind = DAOStarFinder(fwhm=8, threshold=1*std) # find the stars in the image that have FWHMs of around 3 pixels and have peaks approximately 5-sigma above the background. \n",
    "        sources = daofind(cutout_data - median)  \n",
    "        #print(type(sources))\n",
    "        # will likely run into iissues in the code below\n",
    "        for col in sources.colnames:  \n",
    "            if col not in ('id', 'npix'):\n",
    "                sources[col].info.format = '%.2f'  # for consistent table output\n",
    "       # sources.pprint(max_width=3000)  \n",
    "\n",
    "        #likely the flux labeled in this is not converted!\n",
    "        \n",
    "        # plot the image with marked locations of all the sources it detected.\n",
    "        detected_positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "        apertures = CircularAperture(detected_positions, r=2)\n",
    "\n",
    "\n",
    "        # Plotting for current image\n",
    "        # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        \n",
    "        # Was there a point source there?\n",
    "        pixelsinarc = 0.0003819444391411 * 3600 ## 0.0003819444391411 is the number found in the header of the image for the scale of pixels in degrees for the fits image.\n",
    "        detectedpos_all = []\n",
    "        #rows = [row for row in rows if row['Flag'] == 'Valid']\n",
    "        for row in valid_rows_filtered:\n",
    "            apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "            for detected_position in detected_positions:\n",
    "                detected_x, detected_y = detected_position\n",
    "                distance = dist((row['X'], row['Y']), (detected_x, detected_y) ) #distance from the center of the xray source to the center of the detected source\n",
    "                if distance <= row['Radius']: \n",
    "                    row['Exists?'] = 'Point Source Detected'\n",
    "                    row['Point Source Position'].append((detected_x, detected_y))\n",
    "                    dist_in_arc = distance * pixelsinarc\n",
    "                    row['Offset in Arcseconds'].append((dist_in_arc))\n",
    "                    detectedpos_all.append(detected_position) \n",
    "                    #print(f\"Number of detected positions within forced apertures: {len(detectedpos_all)}\")\n",
    "\n",
    "\n",
    "        Yes = []\n",
    "        YesRadius= 5\n",
    "        for row in valid_rows_filtered:\n",
    "                    apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "                    for detected_position in detected_positions:\n",
    "                        detected_x, detected_y = detected_position\n",
    "                        distance = dist((row['X'], row['Y']), (detected_x, detected_y) )\n",
    "\n",
    "                        if distance <= YesRadius:\n",
    "                            row['Exists?'] = 'Yes!!'\n",
    "                            Yes.append((row['X'], row['Y']))\n",
    "                 \n",
    "        #calculate error, convert it back to flux and append the total error\n",
    "        #total_error = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "        for row in valid_rows_filtered:\n",
    "            #print(row['Overlap Error'])\n",
    "            if row['Overlap Error']:  # Check if the list is not empty\n",
    "                overlap_error_var = row['Overlap Error']  \n",
    "            else:\n",
    "                overlap_error_var = 0  # Use 0 if the list is empty\n",
    "            total_error = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "            if band_id in flux_zmfd and instr_zpmag: \n",
    "                flx_conv_fact = flux_zmfd[band_id]\n",
    "                M0instr = instr_zpmag[band_id]\n",
    "                Mcal_error = M0instr - 2.5*(np.log10(total_error))     #converting counts to magnitude\n",
    "                total_error_flx = flx_conv_fact * 10**(Mcal_error/-2.5)#convert Magnitude to Flux\n",
    "                flux_uncertainty_value = total_error_flx      #may need to index the variable here.\n",
    "                #print(f'Total error in flux for band {band_id}: {flux_uncertainty_value}')\n",
    "                row['Flux Uncertainty'].append(flux_uncertainty_value)\n",
    "            else:\n",
    "                 print(f'Missing data for band {band_id}. Skipping...')\n",
    "                             \n",
    "\n",
    "        # Update rows with valid_rows_filtered information\n",
    "        for valid_row in valid_rows_filtered:\n",
    "            for row in rows:\n",
    "                if row['band_id'] == valid_row['band_id'] and row['Region'] == valid_row['Region']:\n",
    "                    row.update(valid_row)\n",
    "\n",
    "        #print('valid sources', valid_rows_filtered)\n",
    "\n",
    "        #print( len(detectedpos_all))\n",
    "        if len(detectedpos_all) > 0:\n",
    "            apertures_detected = CircularAperture(detectedpos_all, r=2)\n",
    "        if len(Yes) > 0:\n",
    "            apertures_Yes = CircularAperture(Yes, r=YesRadius)\n",
    "\n",
    "\n",
    "\n",
    "         # Plotting for current image\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "            \n",
    "            apertures.plot(color='#98ff98', lw=.5, alpha=0.5) \n",
    "            apertures_detected.plot(color='#FF4500', lw=.5, alpha=0.5)  #  #FF69B4 for hot pink\n",
    "            apertures_Yes.plot(color='green', lw=.5, alpha=0.5) \n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm, interpolation='nearest')\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "print(len(display_data))\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagating uncertainty correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "error was calculated by determining the error from the annuli and overlapping areas,\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6 ,'w4':12.98 }\n",
    "wavelengths = {'w1': 3.4 ,'w2': 4.6,'w3': 12,'w4': 22}\n",
    "\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "        \n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error = np.sqrt(overlap_counts)\n",
    "                            \n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask))\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error = np.sqrt(overlap_counts)\n",
    "                            \n",
    "            if overlap:\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_counts -= overlap_counts\n",
    "\n",
    "                # so that i dont take the log or sqrt of a negative number or zero and get an error\n",
    "                if target_counts > 0: # \n",
    "                    target_error= np.sqrt(target_counts)\n",
    "                    #propagated error of overlap error\n",
    "                    target_overlap_counts_err = np.sqrt(target_error**2 + overlap_error**2)\n",
    "                    #print(target_counts)\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                         \n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error = (2.5*target_overlap_counts_err) / (target_counts * np.log(10))\n",
    "                         target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [], 'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [],  'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error })\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                \n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                    overlapannulus_error = np.sqrt(annulus_counts) # the error of the annulus for sources that overlap\n",
    "                     # to avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error_ann = (2.5 * overlapannulus_error) / (annulus_counts * np.log(10))\n",
    "                         annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "\n",
    "\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "                bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "                tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "                net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "            \n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': net_flx_err, 'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error})\n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                    'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [],  'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error})\n",
    "                \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    target_error = np.sqrt(target_counts)\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error = (2.5*target_error) / (target_counts * np.log(10))\n",
    "                         target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [],'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error})\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                # the error of the annulus for sources that overlap\n",
    "                \n",
    "                if annulus_counts > 0:\n",
    "                    annulus_error = np.sqrt(annulus_counts)\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error_ann = (2.5 * annulus_error) / (annulus_counts * np.log(10))\n",
    "                         annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "               #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "                bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "                tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "                net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "\n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,  'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                              'Offset in Arcseconds': [],   'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': []})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,\n",
    "                    'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', \n",
    "                    'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, 'Exists?': 'No', 'Point Source Position' : [], 'Offset in Arcseconds': [],\n",
    "                     'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': []})\n",
    "\n",
    "\n",
    "        #Source detection code\n",
    "        mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0)  \n",
    "       #print((mean, median, std))\n",
    "\n",
    "        # subtract the background and find FWHM of sources at a certain threshold\n",
    "        #started at fwhm= 3 and threshold = 5\n",
    "        daofind = DAOStarFinder(fwhm=8, threshold=1*std) # find the stars in the image that have FWHMs of around 3 pixels and have peaks approximately 5-sigma above the background. \n",
    "        sources = daofind(cutout_data - median)  \n",
    "        #print(type(sources))\n",
    "        # will likely run into iissues in the code below\n",
    "        for col in sources.colnames:  \n",
    "            if col not in ('id', 'npix'):\n",
    "                sources[col].info.format = '%.2f'  # for consistent table output\n",
    "       # sources.pprint(max_width=3000)  \n",
    "\n",
    "        #likely the flux labeled in this is not converted!\n",
    "        \n",
    "        # plot the image with marked locations of all the sources it detected.\n",
    "        detected_positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "        apertures = CircularAperture(detected_positions, r=2)\n",
    "\n",
    "\n",
    "        # Plotting for current image\n",
    "        # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        \n",
    "        # Was there a point source there?\n",
    "        pixelsinarc = 0.0003819444391411 * 3600 ## 0.0003819444391411 is the number found in the header of the image for the scale of pixels in degrees for the fits image.\n",
    "        detectedpos_all = []\n",
    "        #rows = [row for row in rows if row['Flag'] == 'Valid']\n",
    "        for row in valid_rows_filtered:\n",
    "            apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "            for detected_position in detected_positions:\n",
    "                detected_x, detected_y = detected_position\n",
    "                distance = dist((row['X'], row['Y']), (detected_x, detected_y) ) #distance from the center of the xray source to the center of the detected source\n",
    "                if distance <= row['Radius']: \n",
    "                    row['Exists?'] = 'Point Source Detected'\n",
    "                    row['Point Source Position'].append((detected_x, detected_y))\n",
    "                    dist_in_arc = distance * pixelsinarc\n",
    "                    row['Offset in Arcseconds'].append((dist_in_arc))\n",
    "                    detectedpos_all.append(detected_position) \n",
    "                    #print(f\"Number of detected positions within forced apertures: {len(detectedpos_all)}\")\n",
    "\n",
    "\n",
    "        Yes = []\n",
    "        YesRadius= 5\n",
    "        for row in valid_rows_filtered:\n",
    "                    apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "                    for detected_position in detected_positions:\n",
    "                        detected_x, detected_y = detected_position\n",
    "                        distance = dist((row['X'], row['Y']), (detected_x, detected_y) )\n",
    "\n",
    "                        if distance <= YesRadius:\n",
    "                            row['Exists?'] = 'Yes!!'\n",
    "                            Yes.append((row['X'], row['Y']))\n",
    "                 \n",
    "        \n",
    "        # Update rows with valid_rows_filtered information\n",
    "        for valid_row in valid_rows_filtered:\n",
    "            for row in rows:\n",
    "                if row['band_id'] == valid_row['band_id'] and row['Region'] == valid_row['Region']:\n",
    "                    row.update(valid_row)\n",
    "\n",
    "        #print('valid sources', valid_rows_filtered)\n",
    "\n",
    "        #print( len(detectedpos_all))\n",
    "        if len(detectedpos_all) > 0:\n",
    "            apertures_detected = CircularAperture(detectedpos_all, r=2)\n",
    "        if len(Yes) > 0:\n",
    "            apertures_Yes = CircularAperture(Yes, r=YesRadius)\n",
    "        \n",
    "       # xc = 244.422687\t #19.014239\t\n",
    "       # yc=  191.596758# 310.340772\n",
    "    \n",
    "\n",
    "         # Plotting for current image\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "            \n",
    "            apertures.plot(color='#98ff98', lw=.5, alpha=0.5) \n",
    "            apertures_detected.plot(color='#FF4500', lw=.5, alpha=0.5)  #  #FF69B4 for hot pink\n",
    "            apertures_Yes.plot(color='green', lw=.5, alpha=0.5) \n",
    "\n",
    "            # curious ones\n",
    "           # curious = CircularAperture((xc,yc),5)\n",
    "           # curious.plot(color='red', lw=.5, alpha=0.5)\n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm, interpolation='nearest')\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "print(len(display_data))\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want a csv version of this too\n",
    "for column in display_data.columns:\n",
    "    if display_data[column].apply(lambda x: isinstance(x, set)).any():\n",
    "        display_data[column] = display_data[column].apply(lambda x: str(x))\n",
    "for column in display_data.columns:\n",
    "    if display_data[column].apply(lambda x: isinstance(x, list)).any():\n",
    "        display_data[column] = display_data[column].apply(lambda x: str(x))\n",
    "\n",
    "data = display_data.loc[display_data['Flag']== 'Valid']\n",
    "\n",
    "data_out = Table.from_pandas(data)\n",
    "output_path = '../Data/Flux_uncs.csv'\n",
    "\n",
    "# Write the table in csv format\n",
    "data_out.write(output_path, format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_sources = display_data.loc[display_data['Exists?']== 'Yes!!']\n",
    "#display(yes_sources)\n",
    "#3.4, 4.6, 12, and 22\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "wavelengths = {'w1': 3.4 ,'w2': 4.6,'w3': 12,'w4': 22}\n",
    "#define function to get flux density by dividing it by the wavelength\n",
    "def flux_dens(net_flx, net_flx_err, wavelength):\n",
    "    flux_density = net_flx / wavelength\n",
    "    flux_density_unc = net_flx_err / wavelength\n",
    "    flux_density_and_uncertainty = flux_density, flux_density_unc\n",
    "    return flux_density_and_uncertainty \n",
    "\n",
    "for band_label in band_labels:\n",
    "    wavelength = wavelengths[band_label]\n",
    "    flux_density, flux_density_unc = flux_dens(yes_sources['Net Flux (Jy)'], yes_sources['Flux Uncertainty'], wavelength)\n",
    "    # plot flux density vs wavelength\n",
    "    if band_label in band_labels:\n",
    "        print(f'Band {band_labels[band_label]}: ')\n",
    "        plt.plot(wavelength, flux_density)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporating SED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6 ,'w4':12.98 }\n",
    "wavelengths = {'w1': 3.4 ,'w2': 4.6,'w3': 12,'w4': 22}\n",
    "\n",
    "#define function to get flux density per unit frequency (energy units)\n",
    "def flux_dens(net_flx, net_flx_err, wavelength):\n",
    "    flux_density = (net_flx * 1e-23) * (3e10 / (wavelength*1e-4)**2)\n",
    "    flux_density_unc = (net_flx_err * 1e-23) * (3e10 / (wavelength*1e-4)**2)\n",
    "    return flux_density, flux_density_unc\n",
    "\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "        \n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error = np.sqrt(overlap_counts)\n",
    "                            \n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask))\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error = np.sqrt(overlap_counts)\n",
    "                            \n",
    "            if overlap:\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_counts -= overlap_counts\n",
    "\n",
    "                # so that i dont take the log or sqrt of a negative number or zero and get an error\n",
    "                if target_counts > 0: # \n",
    "                    target_error= np.sqrt(target_counts)\n",
    "                    #propagated error of overlap error\n",
    "                    target_overlap_counts_err = np.sqrt(target_error**2 + overlap_error**2)\n",
    "                    #print(target_counts)\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                         \n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error = (2.5*target_overlap_counts_err) / (target_counts * np.log(10))\n",
    "                         target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [], 'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [],  'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : []  })\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                \n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                    overlapannulus_error = np.sqrt(annulus_counts) # the error of the annulus for sources that overlap\n",
    "                     # to avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error_ann = (2.5 * overlapannulus_error) / (annulus_counts * np.log(10))\n",
    "                         annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "\n",
    "\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "                bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "                tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "                net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "            \n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': net_flx_err, 'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                    'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [],  'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "                \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    target_error = np.sqrt(target_counts)\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error = (2.5*target_error) / (target_counts * np.log(10))\n",
    "                         target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [],'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                # the error of the annulus for sources that overlap\n",
    "                \n",
    "                if annulus_counts > 0:\n",
    "                    annulus_error = np.sqrt(annulus_counts)\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error_ann = (2.5 * annulus_error) / (annulus_counts * np.log(10))\n",
    "                         annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "               #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "                bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "                tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "                net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "\n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,  'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                              'Offset in Arcseconds': [],   'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': [], 'Wavelength': wavelengths[band_id],'Flux Density': [], 'Flux Density Uncertainty' : [] })  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,\n",
    "                    'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', \n",
    "                    'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, 'Exists?': 'No', 'Point Source Position' : [], 'Offset in Arcseconds': [],\n",
    "                     'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': [], 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "\n",
    "\n",
    "        #Source detection code\n",
    "        mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0)  \n",
    "       #print((mean, median, std))\n",
    "\n",
    "        # subtract the background and find FWHM of sources at a certain threshold\n",
    "        #started at fwhm= 3 and threshold = 5\n",
    "        daofind = DAOStarFinder(fwhm=8, threshold=1*std) # find the stars in the image that have FWHMs of around 3 pixels and have peaks approximately 5-sigma above the background. \n",
    "        sources = daofind(cutout_data - median)  \n",
    "        #print(type(sources))\n",
    "        # will likely run into iissues in the code below\n",
    "        for col in sources.colnames:  \n",
    "            if col not in ('id', 'npix'):\n",
    "                sources[col].info.format = '%.2f'  # for consistent table output\n",
    "       # sources.pprint(max_width=3000)  \n",
    "\n",
    "        #likely the flux labeled in this is not converted!\n",
    "        \n",
    "        # plot the image with marked locations of all the sources it detected.\n",
    "        detected_positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "        apertures = CircularAperture(detected_positions, r=2)\n",
    "\n",
    "\n",
    "        # Plotting for current image\n",
    "        # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        \n",
    "        # Was there a point source there?\n",
    "        pixelsinarc = 0.0003819444391411 * 3600 ## 0.0003819444391411 is the number found in the header of the image for the scale of pixels in degrees for the fits image.\n",
    "        detectedpos_all = []\n",
    "        #rows = [row for row in rows if row['Flag'] == 'Valid']\n",
    "        for row in valid_rows_filtered:\n",
    "            apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "            for detected_position in detected_positions:\n",
    "                detected_x, detected_y = detected_position\n",
    "                distance = dist((row['X'], row['Y']), (detected_x, detected_y) ) #distance from the center of the xray source to the center of the detected source\n",
    "                if distance <= row['Radius']: \n",
    "                    row['Exists?'] = 'Point Source Detected'\n",
    "                    row['Point Source Position'].append((detected_x, detected_y))\n",
    "                    dist_in_arc = distance * pixelsinarc\n",
    "                    row['Offset in Arcseconds'].append((dist_in_arc))\n",
    "                    detectedpos_all.append(detected_position) \n",
    "                    #print(f\"Number of detected positions within forced apertures: {len(detectedpos_all)}\")\n",
    "\n",
    "\n",
    "        Yes = []\n",
    "        YesRadius= 5\n",
    "        for row in valid_rows_filtered:\n",
    "                    apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "                    for detected_position in detected_positions:\n",
    "                        detected_x, detected_y = detected_position\n",
    "                        distance = dist((row['X'], row['Y']), (detected_x, detected_y) )\n",
    "\n",
    "                        if distance <= YesRadius:\n",
    "                            row['Exists?'] = 'Yes!!'\n",
    "                            Yes.append((row['X'], row['Y']))\n",
    "        #doing flux density\n",
    "        for row in valid_rows_filtered:\n",
    "             net_flx = row['Net Flux (Jy)']\n",
    "             net_flx_err = row['Flux Uncertainty']\n",
    "             print(net_flx)\n",
    "             flux_density, flux_density_unc = flux_dens(net_flx, net_flx_err, wavelength)\n",
    "             row['Flux Density'].append(flux_density)\n",
    "             row['Flux Density Uncertainty'].append(flux_density_unc)\n",
    "                 \n",
    "        \n",
    "        # Update rows with valid_rows_filtered information\n",
    "        for valid_row in valid_rows_filtered:\n",
    "            for row in rows:\n",
    "                if row['band_id'] == valid_row['band_id'] and row['Region'] == valid_row['Region']:\n",
    "                    row.update(valid_row)\n",
    "\n",
    "        #print('valid sources', valid_rows_filtered)\n",
    "\n",
    "        #print( len(detectedpos_all))\n",
    "        if len(detectedpos_all) > 0:\n",
    "            apertures_detected = CircularAperture(detectedpos_all, r=2)\n",
    "        if len(Yes) > 0:\n",
    "            apertures_Yes = CircularAperture(Yes, r=YesRadius)\n",
    "        \n",
    "       # xc = 244.422687\t #19.014239\t\n",
    "       # yc=  191.596758# 310.340772\n",
    "    \n",
    "\n",
    "         # Plotting for current image\n",
    "        #fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        #norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        #for row in valid_rows_filtered:\n",
    "         #  target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "          #  annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "           # target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "          #  annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "            \n",
    "           # apertures.plot(color='#98ff98', lw=.5, alpha=0.5) \n",
    "           # apertures_detected.plot(color='#FF4500', lw=.5, alpha=0.5)  #  #FF69B4 for hot pink\n",
    "           # apertures_Yes.plot(color='green', lw=.5, alpha=0.5) \n",
    "\n",
    "            # curious ones\n",
    "           # curious = CircularAperture((xc,yc),5)\n",
    "           # curious.plot(color='red', lw=.5, alpha=0.5)\n",
    "       # ax.imshow(cutout.data, cmap='gray', norm=norm, interpolation='nearest')\n",
    "       # ax.set_xlabel('Right Ascension')\n",
    "       # ax.set_ylabel('Declination')\n",
    "       # plt.title(f'Band {band_labels[band_id]}')\n",
    "       # plt.show()\n",
    "        yesses =[row for row in valid_rows_filtered if row['Exists?'] == 'Yes!!']\n",
    "       \n",
    "\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "#pd.set_option(\"display.max_columns\", None)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "print(len(display_data))\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing SED here instead, outside of the code\n",
    "#filter for just the yes sources\n",
    "yesses = display_data[display_data['Exists?'] == 'Yes!!']\n",
    "#display(yesses)\n",
    "\n",
    "#group the sources by RA and filter for its appearance in greater than 3 wavelengths\n",
    "sources_by_ra = yesses.groupby('X').filter(lambda x: len(x) >= 4)\n",
    "\n",
    "#Define a list of unique RA values with at least 3 wavelength appearances\n",
    "unique_ra_vals = sources_by_ra['X'].unique()\n",
    "\n",
    "def blackbody(wavelength, temperature):\n",
    "     \n",
    "    k = 1.380649e-16 #boltzman const in erg/kelvin\n",
    "    h = 6.6260755e-27 # planks const in erg*s\n",
    "    c = 3e10 #speed of light in cm/s\n",
    "    wavelength = wavelength * 1e-4 #put wavelength in cm for consistency of units\n",
    "    exponent = np.exp( (h*c) / (wavelength * k * temperature) )\n",
    "    return ( (2 * h * c**2) / wavelength**5) * (1/ (exponent - 1))  \n",
    "\n",
    "temp = 5000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialize subplots\n",
    "num_sources = len(unique_ra_vals)\n",
    "fig, axs = plt.subplots(num_sources, 1, figsize = (10,6*num_sources), sharex= True) # made it so that there are two columns\n",
    "\n",
    "#plot each source individually\n",
    "for idx, ra in enumerate(unique_ra_vals): \n",
    "    sources = sources_by_ra[sources_by_ra['X'] == ra]\n",
    "    wavelengths1 = []\n",
    "    flux_densities1 = []\n",
    "    #plotting in each subplot\n",
    "    for index, source in sources.iterrows():\n",
    "        net_flx = source['Net Flux (Jy)']\n",
    "        net_flx_err = source['Flux Uncertainty']\n",
    "        wavelength = source['Wavelength']\n",
    "        flux_density = source['Flux Density']\n",
    "        flux_density_unc = source['Flux Density Uncertainty']\n",
    "        band_id = source['band_id']\n",
    "        axs[idx].errorbar(wavelength, flux_density, yerr=flux_density_unc, fmt='o', label=f\"RA: {ra}\")\n",
    "\n",
    "        wavelengths1.append(wavelength)\n",
    "        flux_densities1.append(flux_density)\n",
    "    \n",
    "    # Fit the blackbody curve\n",
    "    wavelengths2 = np.array(wavelengths1)\n",
    "    flux_densities2 = np.array(flux_densities1)    \n",
    "    '''\n",
    "    try:\n",
    "        optimal_parameters, covariance_parameters = curve_fit(blackbody, wavelengths2, flux_densities2, p0=temp)\n",
    "        axs[idx].plot(wavelengths2, blackbody(wavelengths2, *optimal_parameters), label = 'Blackbody Fit' )\n",
    "    except RuntimeError:\n",
    "        print(f\"Could not fit a blackbody curve for RA: {ra}\")\n",
    "    except TypeError as e:\n",
    "        print(f\"TypeError for RA: {ra} - {e}\")\n",
    "    '''\n",
    "    axs[idx].set_ylabel('Flux Density (erg/s/cm²/Hz)')\n",
    "    #create titles and legends for each subplot\n",
    "    axs[idx].set_title(f'Source {idx + 1} SED (RA: {ra})')\n",
    "    axs[idx].legend()\n",
    "\n",
    "#common x axis label and title\n",
    "axs[-1].set_xlabel('Wavelength (µm)')\n",
    "plt.suptitle('Spectral Energy Distribution (SED) for Sources with RA in at least 3 Wavelengths')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running over all of the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ra_x   dec_x               source_id  cntr_01    dist_x      pang_x  \\\n",
      "0   201.365 -43.019                NGC 5128      1.0  0.830776  162.673944   \n",
      "1   184.741  47.303             MESSIER 106      3.0  5.022737  -43.454463   \n",
      "2   202.468  47.198             MESSIER 051      4.0  6.295556  -65.412743   \n",
      "3   148.963  69.679             MESSIER 082      5.0  4.934001   60.594118   \n",
      "4    67.704  64.848                NGC 1569      6.0  8.361842  -51.691199   \n",
      "5    11.888 -25.288                NGC 0253      8.0  0.993958  158.563643   \n",
      "6    35.639  42.349                NGC 0891     10.0  3.895011 -134.133495   \n",
      "7    49.328 -41.106  NGC 1291:[LFF2012] 084     11.0  7.368795 -164.984930   \n",
      "8   190.530  32.542                NGC 4631     12.0  9.053783   69.702218   \n",
      "9   192.721  41.120             MESSIER 094     13.0  1.409980   58.249431   \n",
      "10  196.365 -49.468                NGC 4945     14.0  1.444546  -95.506067   \n",
      "11  172.005  78.993               UGC 06456     16.0  3.261849 -157.154801   \n",
      "12  267.365  70.145                NGC 6503     17.0  5.957336 -101.168740   \n",
      "13  186.454  33.547                NGC 4395     18.0  1.088464 -108.113185   \n",
      "14  184.375  37.809                NGC 4244     20.0  8.423295 -132.064124   \n",
      "15  181.763  43.065                NGC 4111     21.0  2.534106    1.427312   \n",
      "16  187.630  41.650                NGC 4485     22.0  4.796021   37.282045   \n",
      "17  161.958  12.582             MESSIER 105     24.0  4.829860 -107.390842   \n",
      "18  114.216  65.600                NGC 2403     25.0  5.837017  145.062619   \n",
      "19  167.880  55.674             MESSIER 108     26.0  1.511374  -39.873393   \n",
      "\n",
      "      ra_01  dec_01          designation        ra_y  ...  moon_lev   w1nm  \\\n",
      "0   201.365 -43.019  J132527.62-430109.1  201.365094  ...       0.0   46.0   \n",
      "1   184.741  47.303  J121857.50+471814.4  184.739585  ...       0.0   34.0   \n",
      "2   202.468  47.198  J132951.75+471155.4  202.465660  ...       0.0   32.0   \n",
      "3   148.963  69.679  J095551.94+694046.8  148.966438  ...       0.0   39.0   \n",
      "4    67.704  64.848  J043047.93+645057.9   67.699712  ...       0.0   33.0   \n",
      "5    11.888 -25.288  J004733.14-251717.7   11.888112  ...       0.0   27.0   \n",
      "6    35.639  42.349  J022233.10+422053.6   35.637949  ...       0.0   27.0   \n",
      "7    49.328 -41.106  J031718.55-410628.7   49.327296  ...       0.0   65.0   \n",
      "8   190.530  32.542  J124207.87+323234.3  190.532798  ...      11.0   27.0   \n",
      "9   192.721  41.120  J125053.14+410712.7  192.721442  ...       0.0   33.0   \n",
      "10  196.365 -49.468  J130527.45-492804.9  196.364385  ...       0.0   50.0   \n",
      "11  172.005  78.993  J112800.75+785931.7  172.003158  ...       0.0   51.0   \n",
      "12  267.365  70.145  J174926.45+700840.8  267.360220  ...       0.0  151.0   \n",
      "13  186.454  33.547  J122548.87+333248.8  186.453655  ...       0.0   28.0   \n",
      "14  184.375  37.809  J121729.47+374826.7  184.372801  ...       0.0   28.0   \n",
      "15  181.763  43.065  J120703.12+430356.5  181.763024  ...       0.0   29.0   \n",
      "16  187.630  41.650  J123031.45+413903.8  187.631080  ...       0.0   27.0   \n",
      "17  161.958  12.582  J104749.60+123453.7  161.956688  ...    1100.0   24.0   \n",
      "18  114.216  65.600  J073652.37+653555.2  114.218248  ...       0.0   32.0   \n",
      "19  167.880  55.674  J111131.08+554027.5  167.879523  ...       0.0   33.0   \n",
      "\n",
      "      w1m   w2nm    w2m  w3nm   w3m  w4nm   w4m  _merge  \n",
      "0    46.0   46.0   46.0  24.0  24.0  24.0  24.0    both  \n",
      "1    34.0   34.0   34.0  19.0  19.0  19.0  19.0    both  \n",
      "2    32.0   32.0   32.0  18.0  18.0  18.0  18.0    both  \n",
      "3    39.0   39.0   39.0  19.0  19.0  19.0  19.0    both  \n",
      "4    33.0   33.0   33.0  17.0  17.0  17.0  17.0    both  \n",
      "5    27.0   27.0   27.0  14.0  14.0  14.0  14.0    both  \n",
      "6    27.0   27.0   27.0  12.0  12.0  12.0  12.0    both  \n",
      "7    65.0   65.0   65.0  33.0  33.0  33.0  33.0    both  \n",
      "8    27.0   27.0   27.0  14.0  14.0  14.0  14.0    both  \n",
      "9    33.0   33.0   33.0  18.0  18.0  18.0  18.0    both  \n",
      "10   50.0   50.0   50.0  27.0  27.0  27.0  27.0    both  \n",
      "11   51.0   50.0   51.0  16.0  25.0  24.0  25.0    both  \n",
      "12  151.0  151.0  151.0  77.0  77.0  77.0  77.0    both  \n",
      "13   28.0   28.0   28.0  15.0  15.0  15.0  15.0    both  \n",
      "14   28.0   27.0   27.0  14.0  14.0  13.0  14.0    both  \n",
      "15   29.0   29.0   29.0  16.0  16.0  16.0  16.0    both  \n",
      "16   27.0   27.0   27.0  15.0  15.0  15.0  15.0    both  \n",
      "17   24.0   24.0   24.0  13.0  13.0  13.0  13.0    both  \n",
      "18   32.0   32.0   32.0  17.0  17.0  11.0  17.0    both  \n",
      "19   33.0   33.0   33.0  20.0  20.0  20.0  20.0    both  \n",
      "\n",
      "[20 rows x 54 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/77pj43rx7wbcbp0wx2qjq2140000gp/T/ipykernel_97832/2852043174.py:25: DtypeWarning: Columns (533,534) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band W4: \n",
      "Band W3: \n",
      "Band W2: \n",
      "Band W1: \n",
      "Number of valid sources:  109\n",
      "Number of sources:  780\n",
      "Number of sources coincidental with WISE bright points within 5 arcsec:  50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_id</th>\n",
       "      <th>Region</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Annulus_Inner_Radius</th>\n",
       "      <th>Annulus_Outer_Radius</th>\n",
       "      <th>Net Flux (Jy)</th>\n",
       "      <th>Flux Uncertainty</th>\n",
       "      <th>Flag</th>\n",
       "      <th>...</th>\n",
       "      <th>Offset in Arcseconds</th>\n",
       "      <th>Exists?</th>\n",
       "      <th>Point Source Position</th>\n",
       "      <th>Target Error</th>\n",
       "      <th>Annulus Error</th>\n",
       "      <th>Overlap Error (in counts)</th>\n",
       "      <th>Wavelength</th>\n",
       "      <th>Flux Density</th>\n",
       "      <th>Flux Density Uncertainty</th>\n",
       "      <th>Overlap Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>11</td>\n",
       "      <td>244.422687</td>\n",
       "      <td>191.596758</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.6338919810711983]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(243.3789797697625, 192.1648220806889)]</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.019270</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[3.19273867620897e-08]</td>\n",
       "      <td>[3.10906427663272e-08]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>44</td>\n",
       "      <td>27.106572</td>\n",
       "      <td>287.112057</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.011897</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[4.995840817328477]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(24.618842802905956, 289.7601421914975)]</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.019181</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[2.1183233725838155e-10]</td>\n",
       "      <td>[3.0875832142614227e-08]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>45</td>\n",
       "      <td>19.014239</td>\n",
       "      <td>310.340772</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.136794</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[4.64558351780892, 4.914657389017605]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(16.829309271611887, 307.76374627351134), (19...</td>\n",
       "      <td>0.010449</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[3.5500136480137275e-07]</td>\n",
       "      <td>[3.063953479399767e-08]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>85</td>\n",
       "      <td>217.177779</td>\n",
       "      <td>220.539778</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.019106</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[2.946439664849703]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(219.27090874204174, 220.99877614197925)]</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[4.958267235129992e-08]</td>\n",
       "      <td>[3.1218246798249594e-08]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>107</td>\n",
       "      <td>203.923577</td>\n",
       "      <td>174.000270</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.01197</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.7973691467121211]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(205.0780258155945, 173.38711269541773)]</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[2.174278089708009e-08]</td>\n",
       "      <td>[3.106359083803017e-08]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>6</td>\n",
       "      <td>281.147755</td>\n",
       "      <td>141.030790</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[3.993322999826168]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(283.46881246673087, 139.2851459031614)]</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[4.78952461225838e-09]</td>\n",
       "      <td>[3.0214271892610635e-09]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>8</td>\n",
       "      <td>271.085639</td>\n",
       "      <td>171.908120</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[4.087011969382882]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(268.80396961634534, 173.81310834210194)]</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[2.0470410193695366e-09]</td>\n",
       "      <td>[3.0376346718766105e-09]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>11</td>\n",
       "      <td>244.422687</td>\n",
       "      <td>191.596758</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.6372828878546131]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(244.13097064596934, 191.95691596580338)]</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[2.77927976861057e-08]</td>\n",
       "      <td>[3.117536013556034e-09]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>22</td>\n",
       "      <td>168.969907</td>\n",
       "      <td>25.773980</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[5.915797833842992, 0.35389129096326516]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(164.75538072324719, 24.908877144643192), (16...</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[1.528665905364602e-09]</td>\n",
       "      <td>[3.003961154366345e-09]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>25</td>\n",
       "      <td>156.897152</td>\n",
       "      <td>251.971371</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[3.527868378692109]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(154.6464211744247, 253.20309403008687)]</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[1.1266390152011784e-09]</td>\n",
       "      <td>[3.055856398974445e-09]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>38</td>\n",
       "      <td>60.883682</td>\n",
       "      <td>112.861582</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.4170819923031746]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(60.09736163076986, 113.52780044931512)]</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[4.687372834596383e-10]</td>\n",
       "      <td>[3.0032672300434013e-09]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>44</td>\n",
       "      <td>27.106572</td>\n",
       "      <td>287.112057</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[2.57793760495788]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(25.524403391228326, 288.1179679114064)]</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[5.934025897291922e-10]</td>\n",
       "      <td>[3.002722818240092e-09]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>85</td>\n",
       "      <td>217.177779</td>\n",
       "      <td>220.539778</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.029103</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[2.1547111298820085]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(218.72188467686087, 220.2725269218816)]</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[7.552675580291517e-08]</td>\n",
       "      <td>[3.2282083121225253e-09]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>107</td>\n",
       "      <td>203.923577</td>\n",
       "      <td>174.000270</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.3918050335023846, 10.88555864632431]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(204.19898290004437, 173.02623485201292), (19...</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[1.559668694671138e-08]</td>\n",
       "      <td>[3.0996785479298177e-09]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>5</td>\n",
       "      <td>337.953952</td>\n",
       "      <td>77.232043</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[3.344228698621333]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(338.96716715757196, 75.02097388741595)]</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[8.960152692552383e-11]</td>\n",
       "      <td>[3.429411087308093e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>6</td>\n",
       "      <td>281.147755</td>\n",
       "      <td>141.030790</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[3.076099940488436]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(282.7078359166899, 139.42734088626844)]</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[4.0923632418140267e-10]</td>\n",
       "      <td>[3.6542949346395737e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>7</td>\n",
       "      <td>277.237138</td>\n",
       "      <td>287.356364</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[7.89068574953197, 5.396014991466557]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(275.8340850537986, 281.79184243243986), (280...</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[2.625151232751326e-10]</td>\n",
       "      <td>[3.8403683860019765e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>8</td>\n",
       "      <td>271.085639</td>\n",
       "      <td>171.908120</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.825459030088275]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(270.1092992888553, 172.80773058870955)]</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[7.51726998501996e-10]</td>\n",
       "      <td>[4.0159691733323823e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>11</td>\n",
       "      <td>244.422687</td>\n",
       "      <td>191.596758</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[2.3228946132256816]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(244.12063156533156, 193.25891302343618)]</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[1.6067943141794437e-10]</td>\n",
       "      <td>[4.4661213223925484e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>13</td>\n",
       "      <td>230.855881</td>\n",
       "      <td>154.742167</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[6.830833746071463]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(226.04043168688173, 153.52099224013972)]</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[1.951008123262403e-09]</td>\n",
       "      <td>[4.0889050380491147e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>14</td>\n",
       "      <td>227.715640</td>\n",
       "      <td>346.900800</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.7240747441902733]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(227.25771276404325, 346.6407794755969)]</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[4.165915919208028e-10]</td>\n",
       "      <td>[3.5319388204422325e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>22</td>\n",
       "      <td>168.969907</td>\n",
       "      <td>25.773980</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0206632652943224]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(169.4730444780039, 25.228212221018516)]</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[3.2747010649913893e-10]</td>\n",
       "      <td>[3.4349743954882196e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>25</td>\n",
       "      <td>156.897152</td>\n",
       "      <td>251.971371</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.865350154043277]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(157.020510216117, 253.3223690608367)]</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[4.3281540135761353e-10]</td>\n",
       "      <td>[4.1544648109247277e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>34</td>\n",
       "      <td>96.262803</td>\n",
       "      <td>187.515057</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[6.73712336437424]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(93.28171869132426, 183.6265546237317)]</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[3.7455455747931154e-10]</td>\n",
       "      <td>[3.701883944692322e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>35</td>\n",
       "      <td>90.434545</td>\n",
       "      <td>166.022290</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[2.809642051900591]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(88.7577205887646, 164.85453788556248)]</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[6.753573012624916e-12]</td>\n",
       "      <td>[3.61507210757474e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>38</td>\n",
       "      <td>60.883682</td>\n",
       "      <td>112.861582</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9568068449233852]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(60.67698087976386, 113.52603289443866)]</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[1.8229798605268535e-10]</td>\n",
       "      <td>[3.4422031949384266e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>42</td>\n",
       "      <td>34.039466</td>\n",
       "      <td>185.534541</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[4.202638303327356]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(34.82033221783704, 188.48957403300582)]</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[2.6815826214989865e-10]</td>\n",
       "      <td>[3.509644977048344e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>44</td>\n",
       "      <td>27.106572</td>\n",
       "      <td>287.112057</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.6460661117881591, 6.957804777950241]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(26.75899943840708, 286.79588062468633), (32....</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[4.836844101878687e-10]</td>\n",
       "      <td>[3.469809913450438e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>45</td>\n",
       "      <td>19.014239</td>\n",
       "      <td>310.340772</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.1260266805068824]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(19.518998553028062, 309.69589861527953)]</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[1.0443620538760883e-09]</td>\n",
       "      <td>[3.3981463924049566e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>83</td>\n",
       "      <td>231.487784</td>\n",
       "      <td>269.894339</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[6.055958879179225]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(232.21181580819353, 274.2387533415802)]</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[5.765120806177205e-10]</td>\n",
       "      <td>[4.2050375822855363e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>85</td>\n",
       "      <td>217.177779</td>\n",
       "      <td>220.539778</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.6444691761605599]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(217.63552462551527, 220.64054100775823)]</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[1.6424837598904433e-08]</td>\n",
       "      <td>[6.092999204845941e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>98</td>\n",
       "      <td>45.106758</td>\n",
       "      <td>76.526072</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.3133257330479177]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(44.88740036089273, 76.46435905059778)]</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[1.897270644640328e-10]</td>\n",
       "      <td>[3.4153434041893106e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>101</td>\n",
       "      <td>280.450699</td>\n",
       "      <td>154.977536</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[10.838675552102037, 1.319107746197877]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(288.30347675726074, 154.2916623846832), (279...</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[6.977349863586175e-10]</td>\n",
       "      <td>[3.8398567110741124e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>107</td>\n",
       "      <td>203.923577</td>\n",
       "      <td>174.000270</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[3.4066564353286446, 9.001546796734347]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(205.4505471764895, 175.9513489939941), (197....</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[5.786144998686642e-10]</td>\n",
       "      <td>[4.2984868457278707e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>{W2}</td>\n",
       "      <td>120</td>\n",
       "      <td>176.811625</td>\n",
       "      <td>251.197414</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[5.092353250628895, 7.827501237142721]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(179.60281249253336, 248.7631980045809), (177...</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[7.977919208068935e-10]</td>\n",
       "      <td>[4.2803858325068325e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>6</td>\n",
       "      <td>281.147755</td>\n",
       "      <td>141.030790</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[8.168447372161333, 3.660578213391915]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(278.62008634076614, 135.65466872089107), (28...</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[2.82367822117744e-10]</td>\n",
       "      <td>[1.7263493350934003e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>8</td>\n",
       "      <td>271.085639</td>\n",
       "      <td>171.908120</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.5930292990238084]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(270.2425015752207, 172.7027240304418)]</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[8.236569205955794e-10]</td>\n",
       "      <td>[2.3201511737017856e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>9</td>\n",
       "      <td>270.537574</td>\n",
       "      <td>254.125605</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[6.117157273541634]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(266.3939116190876, 255.7449432208837)]</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[1.8442172024025682e-09]</td>\n",
       "      <td>[2.7019201673423906e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>13</td>\n",
       "      <td>230.855881</td>\n",
       "      <td>154.742167</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[5.902548045834064, 12.231365010155992]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(226.7276917494284, 153.56494204110064), (233...</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[2.354663308498713e-09]</td>\n",
       "      <td>[2.410700808104352e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>14</td>\n",
       "      <td>227.715640</td>\n",
       "      <td>346.900800</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.5090651327687477]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(227.38653642911314, 346.73120945986784)]</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[4.767904328420143e-10]</td>\n",
       "      <td>[1.6033138638351403e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>22</td>\n",
       "      <td>168.969907</td>\n",
       "      <td>25.773980</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.39460044225887086]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(169.14192055199408, 25.544262858547373)]</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[1.382920976659625e-10]</td>\n",
       "      <td>[1.2839894122591724e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>25</td>\n",
       "      <td>156.897152</td>\n",
       "      <td>251.971371</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.8511196911304246]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(157.5095647557755, 253.17028321216011)]</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[4.659569063846909e-10]</td>\n",
       "      <td>[2.548406263690561e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>38</td>\n",
       "      <td>60.883682</td>\n",
       "      <td>112.861582</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.4812083476281173]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(60.85985815622834, 113.9385608635844)]</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[1.7736202436740403e-10]</td>\n",
       "      <td>[1.368421742615447e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>42</td>\n",
       "      <td>34.039466</td>\n",
       "      <td>185.534541</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[4.934454145390541]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(35.118822328290946, 188.95707112530735)]</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[4.7549106823356e-10]</td>\n",
       "      <td>[1.5229527654991933e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>44</td>\n",
       "      <td>27.106572</td>\n",
       "      <td>287.112057</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9587006703440272, 7.546408711591116]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(26.704567471152394, 286.54238043650787), (32...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[6.30652996172757e-10]</td>\n",
       "      <td>[1.4005488432087592e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>83</td>\n",
       "      <td>231.487784</td>\n",
       "      <td>269.894339</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[6.583874602353049]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(232.03974977387307, 274.65069155172574)]</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[7.750244374532824e-10]</td>\n",
       "      <td>[2.6032591534475944e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>85</td>\n",
       "      <td>217.177779</td>\n",
       "      <td>220.539778</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.29782167792510633]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(217.3943757277362, 220.5391628086986)]</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[2.438207199991237e-08]</td>\n",
       "      <td>[4.940096618038785e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>98</td>\n",
       "      <td>45.106758</td>\n",
       "      <td>76.526072</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.13314894931077426]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(45.09266689385177, 76.43026714395607)]</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[2.4616279591900247e-10]</td>\n",
       "      <td>[1.318131863484321e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>101</td>\n",
       "      <td>280.450699</td>\n",
       "      <td>154.977536</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.4941432504076897]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(279.4221204071491, 155.32801135543508)]</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[9.840361300053884e-10]</td>\n",
       "      <td>[2.0556469237342423e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>{W1}</td>\n",
       "      <td>120</td>\n",
       "      <td>176.811625</td>\n",
       "      <td>251.197414</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>Valid</td>\n",
       "      <td>...</td>\n",
       "      <td>[5.487422037655745, 5.060352597498933]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(179.5406297516763, 248.28546625414114), (176...</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>[]</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[9.877227136178846e-10]</td>\n",
       "      <td>[2.7198390090318427e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    band_id  Region           X           Y  Radius  Annulus_Inner_Radius  \\\n",
       "10     {W4}      11  244.422687  191.596758       9                    16   \n",
       "51     {W4}      44   27.106572  287.112057       9                    16   \n",
       "52     {W4}      45   19.014239  310.340772       9                    16   \n",
       "129    {W4}      85  217.177779  220.539778       9                    16   \n",
       "165    {W4}     107  203.923577  174.000270       9                    16   \n",
       "200    {W3}       6  281.147755  141.030790       9                    16   \n",
       "202    {W3}       8  271.085639  171.908120       9                    16   \n",
       "205    {W3}      11  244.422687  191.596758       9                    16   \n",
       "219    {W3}      22  168.969907   25.773980       9                    16   \n",
       "223    {W3}      25  156.897152  251.971371       9                    16   \n",
       "239    {W3}      38   60.883682  112.861582       9                    16   \n",
       "246    {W3}      44   27.106572  287.112057       9                    16   \n",
       "324    {W3}      85  217.177779  220.539778       9                    16   \n",
       "360    {W3}     107  203.923577  174.000270       9                    16   \n",
       "394    {W2}       5  337.953952   77.232043       9                    16   \n",
       "395    {W2}       6  281.147755  141.030790       9                    16   \n",
       "396    {W2}       7  277.237138  287.356364       9                    16   \n",
       "397    {W2}       8  271.085639  171.908120       9                    16   \n",
       "400    {W2}      11  244.422687  191.596758       9                    16   \n",
       "402    {W2}      13  230.855881  154.742167       9                    16   \n",
       "403    {W2}      14  227.715640  346.900800       9                    16   \n",
       "414    {W2}      22  168.969907   25.773980       9                    16   \n",
       "418    {W2}      25  156.897152  251.971371       9                    16   \n",
       "430    {W2}      34   96.262803  187.515057       9                    16   \n",
       "431    {W2}      35   90.434545  166.022290       9                    16   \n",
       "434    {W2}      38   60.883682  112.861582       9                    16   \n",
       "438    {W2}      42   34.039466  185.534541       9                    16   \n",
       "441    {W2}      44   27.106572  287.112057       9                    16   \n",
       "442    {W2}      45   19.014239  310.340772       9                    16   \n",
       "516    {W2}      83  231.487784  269.894339       9                    16   \n",
       "519    {W2}      85  217.177779  220.539778       9                    16   \n",
       "541    {W2}      98   45.106758   76.526072       9                    16   \n",
       "546    {W2}     101  280.450699  154.977536       9                    16   \n",
       "555    {W2}     107  203.923577  174.000270       9                    16   \n",
       "579    {W2}     120  176.811625  251.197414       9                    16   \n",
       "590    {W1}       6  281.147755  141.030790       9                    16   \n",
       "592    {W1}       8  271.085639  171.908120       9                    16   \n",
       "593    {W1}       9  270.537574  254.125605       9                    16   \n",
       "597    {W1}      13  230.855881  154.742167       9                    16   \n",
       "598    {W1}      14  227.715640  346.900800       9                    16   \n",
       "609    {W1}      22  168.969907   25.773980       9                    16   \n",
       "613    {W1}      25  156.897152  251.971371       9                    16   \n",
       "629    {W1}      38   60.883682  112.861582       9                    16   \n",
       "633    {W1}      42   34.039466  185.534541       9                    16   \n",
       "636    {W1}      44   27.106572  287.112057       9                    16   \n",
       "711    {W1}      83  231.487784  269.894339       9                    16   \n",
       "714    {W1}      85  217.177779  220.539778       9                    16   \n",
       "736    {W1}      98   45.106758   76.526072       9                    16   \n",
       "741    {W1}     101  280.450699  154.977536       9                    16   \n",
       "774    {W1}     120  176.811625  251.197414       9                    16   \n",
       "\n",
       "     Annulus_Outer_Radius  Net Flux (Jy) Flux Uncertainty   Flag  ...  \\\n",
       "10                     23       0.012303          0.01198  Valid  ...   \n",
       "51                     23       0.000082         0.011897  Valid  ...   \n",
       "52                     23       0.136794         0.011806  Valid  ...   \n",
       "129                    23       0.019106         0.012029  Valid  ...   \n",
       "165                    23       0.008378          0.01197  Valid  ...   \n",
       "200                    23       0.001846         0.001164  Valid  ...   \n",
       "202                    23       0.000789         0.001171  Valid  ...   \n",
       "205                    23       0.010709         0.001201  Valid  ...   \n",
       "219                    23       0.000589         0.001158  Valid  ...   \n",
       "223                    23       0.000434         0.001178  Valid  ...   \n",
       "239                    23       0.000181         0.001157  Valid  ...   \n",
       "246                    23       0.000229         0.001157  Valid  ...   \n",
       "324                    23       0.029103         0.001244  Valid  ...   \n",
       "360                    23       0.006010         0.001194  Valid  ...   \n",
       "394                    23       0.000035         0.000132  Valid  ...   \n",
       "395                    23       0.000158         0.000141  Valid  ...   \n",
       "396                    23       0.000101         0.000148  Valid  ...   \n",
       "397                    23       0.000290         0.000155  Valid  ...   \n",
       "400                    23       0.000062         0.000172  Valid  ...   \n",
       "402                    23       0.000752         0.000158  Valid  ...   \n",
       "403                    23       0.000161         0.000136  Valid  ...   \n",
       "414                    23       0.000126         0.000132  Valid  ...   \n",
       "418                    23       0.000167          0.00016  Valid  ...   \n",
       "430                    23       0.000144         0.000143  Valid  ...   \n",
       "431                    23       0.000003         0.000139  Valid  ...   \n",
       "434                    23       0.000070         0.000133  Valid  ...   \n",
       "438                    23       0.000103         0.000135  Valid  ...   \n",
       "441                    23       0.000186         0.000134  Valid  ...   \n",
       "442                    23       0.000402         0.000131  Valid  ...   \n",
       "516                    23       0.000222         0.000162  Valid  ...   \n",
       "519                    23       0.006329         0.000235  Valid  ...   \n",
       "541                    23       0.000073         0.000132  Valid  ...   \n",
       "546                    23       0.000269         0.000148  Valid  ...   \n",
       "555                    23       0.000223         0.000166  Valid  ...   \n",
       "579                    23       0.000307         0.000165  Valid  ...   \n",
       "590                    23       0.000109         0.000067  Valid  ...   \n",
       "592                    23       0.000317         0.000089  Valid  ...   \n",
       "593                    23       0.000711         0.000104  Valid  ...   \n",
       "597                    23       0.000907         0.000093  Valid  ...   \n",
       "598                    23       0.000184         0.000062  Valid  ...   \n",
       "609                    23       0.000053         0.000049  Valid  ...   \n",
       "613                    23       0.000180         0.000098  Valid  ...   \n",
       "629                    23       0.000068         0.000053  Valid  ...   \n",
       "633                    23       0.000183         0.000059  Valid  ...   \n",
       "636                    23       0.000243         0.000054  Valid  ...   \n",
       "711                    23       0.000299           0.0001  Valid  ...   \n",
       "714                    23       0.009395          0.00019  Valid  ...   \n",
       "736                    23       0.000095         0.000051  Valid  ...   \n",
       "741                    23       0.000379         0.000079  Valid  ...   \n",
       "774                    23       0.000381         0.000105  Valid  ...   \n",
       "\n",
       "                         Offset in Arcseconds  Exists?  \\\n",
       "10                       [1.6338919810711983]    Yes!!   \n",
       "51                        [4.995840817328477]    Yes!!   \n",
       "52      [4.64558351780892, 4.914657389017605]    Yes!!   \n",
       "129                       [2.946439664849703]    Yes!!   \n",
       "165                      [1.7973691467121211]    Yes!!   \n",
       "200                       [3.993322999826168]    Yes!!   \n",
       "202                       [4.087011969382882]    Yes!!   \n",
       "205                      [0.6372828878546131]    Yes!!   \n",
       "219  [5.915797833842992, 0.35389129096326516]    Yes!!   \n",
       "223                       [3.527868378692109]    Yes!!   \n",
       "239                      [1.4170819923031746]    Yes!!   \n",
       "246                        [2.57793760495788]    Yes!!   \n",
       "324                      [2.1547111298820085]    Yes!!   \n",
       "360   [1.3918050335023846, 10.88555864632431]    Yes!!   \n",
       "394                       [3.344228698621333]    Yes!!   \n",
       "395                       [3.076099940488436]    Yes!!   \n",
       "396     [7.89068574953197, 5.396014991466557]    Yes!!   \n",
       "397                       [1.825459030088275]    Yes!!   \n",
       "400                      [2.3228946132256816]    Yes!!   \n",
       "402                       [6.830833746071463]    Yes!!   \n",
       "403                      [0.7240747441902733]    Yes!!   \n",
       "414                      [1.0206632652943224]    Yes!!   \n",
       "418                       [1.865350154043277]    Yes!!   \n",
       "430                        [6.73712336437424]    Yes!!   \n",
       "431                       [2.809642051900591]    Yes!!   \n",
       "434                      [0.9568068449233852]    Yes!!   \n",
       "438                       [4.202638303327356]    Yes!!   \n",
       "441   [0.6460661117881591, 6.957804777950241]    Yes!!   \n",
       "442                      [1.1260266805068824]    Yes!!   \n",
       "516                       [6.055958879179225]    Yes!!   \n",
       "519                      [0.6444691761605599]    Yes!!   \n",
       "541                      [0.3133257330479177]    Yes!!   \n",
       "546   [10.838675552102037, 1.319107746197877]    Yes!!   \n",
       "555   [3.4066564353286446, 9.001546796734347]    Yes!!   \n",
       "579    [5.092353250628895, 7.827501237142721]    Yes!!   \n",
       "590    [8.168447372161333, 3.660578213391915]    Yes!!   \n",
       "592                      [1.5930292990238084]    Yes!!   \n",
       "593                       [6.117157273541634]    Yes!!   \n",
       "597   [5.902548045834064, 12.231365010155992]    Yes!!   \n",
       "598                      [0.5090651327687477]    Yes!!   \n",
       "609                     [0.39460044225887086]    Yes!!   \n",
       "613                      [1.8511196911304246]    Yes!!   \n",
       "629                      [1.4812083476281173]    Yes!!   \n",
       "633                       [4.934454145390541]    Yes!!   \n",
       "636   [0.9587006703440272, 7.546408711591116]    Yes!!   \n",
       "711                       [6.583874602353049]    Yes!!   \n",
       "714                     [0.29782167792510633]    Yes!!   \n",
       "736                     [0.13314894931077426]    Yes!!   \n",
       "741                      [1.4941432504076897]    Yes!!   \n",
       "774    [5.487422037655745, 5.060352597498933]    Yes!!   \n",
       "\n",
       "                                 Point Source Position  Target Error  \\\n",
       "10            [(243.3789797697625, 192.1648220806889)]      0.010528   \n",
       "51           [(24.618842802905956, 289.7601421914975)]      0.010448   \n",
       "52   [(16.829309271611887, 307.76374627351134), (19...      0.010449   \n",
       "129         [(219.27090874204174, 220.99877614197925)]      0.010575   \n",
       "165          [(205.0780258155945, 173.38711269541773)]      0.010516   \n",
       "200          [(283.46881246673087, 139.2851459031614)]      0.001023   \n",
       "202         [(268.80396961634534, 173.81310834210194)]      0.001028   \n",
       "205         [(244.13097064596934, 191.95691596580338)]      0.001058   \n",
       "219  [(164.75538072324719, 24.908877144643192), (16...      0.001017   \n",
       "223          [(154.6464211744247, 253.20309403008687)]      0.001034   \n",
       "239          [(60.09736163076986, 113.52780044931512)]      0.001016   \n",
       "246          [(25.524403391228326, 288.1179679114064)]      0.001016   \n",
       "324          [(218.72188467686087, 220.2725269218816)]      0.001101   \n",
       "360  [(204.19898290004437, 173.02623485201292), (19...      0.001051   \n",
       "394          [(338.96716715757196, 75.02097388741595)]      0.000116   \n",
       "395          [(282.7078359166899, 139.42734088626844)]      0.000124   \n",
       "396  [(275.8340850537986, 281.79184243243986), (280...      0.000130   \n",
       "397          [(270.1092992888553, 172.80773058870955)]      0.000137   \n",
       "400         [(244.12063156533156, 193.25891302343618)]      0.000151   \n",
       "402         [(226.04043168688173, 153.52099224013972)]      0.000140   \n",
       "403          [(227.25771276404325, 346.6407794755969)]      0.000120   \n",
       "414          [(169.4730444780039, 25.228212221018516)]      0.000117   \n",
       "418            [(157.020510216117, 253.3223690608367)]      0.000141   \n",
       "430           [(93.28171869132426, 183.6265546237317)]      0.000126   \n",
       "431           [(88.7577205887646, 164.85453788556248)]      0.000122   \n",
       "434          [(60.67698087976386, 113.52603289443866)]      0.000117   \n",
       "438          [(34.82033221783704, 188.48957403300582)]      0.000119   \n",
       "441  [(26.75899943840708, 286.79588062468633), (32....      0.000118   \n",
       "442         [(19.518998553028062, 309.69589861527953)]      0.000116   \n",
       "516          [(232.21181580819353, 274.2387533415802)]      0.000143   \n",
       "519         [(217.63552462551527, 220.64054100775823)]      0.000215   \n",
       "541           [(44.88740036089273, 76.46435905059778)]      0.000116   \n",
       "546  [(288.30347675726074, 154.2916623846832), (279...      0.000131   \n",
       "555  [(205.4505471764895, 175.9513489939941), (197....      0.000146   \n",
       "579  [(179.60281249253336, 248.7631980045809), (177...      0.000145   \n",
       "590  [(278.62008634076614, 135.65466872089107), (28...      0.000059   \n",
       "592           [(270.2425015752207, 172.7027240304418)]      0.000079   \n",
       "593           [(266.3939116190876, 255.7449432208837)]      0.000093   \n",
       "597  [(226.7276917494284, 153.56494204110064), (233...      0.000084   \n",
       "598         [(227.38653642911314, 346.73120945986784)]      0.000055   \n",
       "609         [(169.14192055199408, 25.544262858547373)]      0.000044   \n",
       "613          [(157.5095647557755, 253.17028321216011)]      0.000087   \n",
       "629           [(60.85985815622834, 113.9385608635844)]      0.000047   \n",
       "633         [(35.118822328290946, 188.95707112530735)]      0.000052   \n",
       "636  [(26.704567471152394, 286.54238043650787), (32...      0.000048   \n",
       "711         [(232.03974977387307, 274.65069155172574)]      0.000089   \n",
       "714           [(217.3943757277362, 220.5391628086986)]      0.000177   \n",
       "736           [(45.09266689385177, 76.43026714395607)]      0.000045   \n",
       "741          [(279.4221204071491, 155.32801135543508)]      0.000071   \n",
       "774  [(179.5406297516763, 248.28546625414114), (176...      0.000093   \n",
       "\n",
       "     Annulus Error  Overlap Error (in counts) Wavelength  \\\n",
       "10        0.019270                         []       22.0   \n",
       "51        0.019181                         []       22.0   \n",
       "52        0.018526                         []       22.0   \n",
       "129       0.019325                         []       22.0   \n",
       "165       0.019267                         []       22.0   \n",
       "200       0.001873                         []       12.0   \n",
       "202       0.001886                         []       12.0   \n",
       "205       0.001916                         []       12.0   \n",
       "219       0.001865                         []       12.0   \n",
       "223       0.001898                         []       12.0   \n",
       "239       0.001865                         []       12.0   \n",
       "246       0.001865                         []       12.0   \n",
       "324       0.001950                         []       12.0   \n",
       "360       0.001914                         []       12.0   \n",
       "394       0.000213                         []        4.6   \n",
       "395       0.000225                         []        4.6   \n",
       "396       0.000237                         []        4.6   \n",
       "397       0.000246                         []        4.6   \n",
       "400       0.000277                         []        4.6   \n",
       "402       0.000244                         []        4.6   \n",
       "403       0.000217                         []        4.6   \n",
       "414       0.000211                         []        4.6   \n",
       "418       0.000256                         []        4.6   \n",
       "430       0.000228                         []        4.6   \n",
       "431       0.000225                         []        4.6   \n",
       "434       0.000213                         []        4.6   \n",
       "438       0.000216                         []        4.6   \n",
       "441       0.000213                         []        4.6   \n",
       "442       0.000205                         []        4.6   \n",
       "516       0.000258                         []        4.6   \n",
       "519       0.000318                         []        4.6   \n",
       "541       0.000211                         []        4.6   \n",
       "546       0.000235                         []        4.6   \n",
       "555       0.000264                         []        4.6   \n",
       "579       0.000262                         []        4.6   \n",
       "590       0.000105                         []        3.4   \n",
       "592       0.000140                         []        3.4   \n",
       "593       0.000159                         []        3.4   \n",
       "597       0.000137                         []        3.4   \n",
       "598       0.000096                         []        3.4   \n",
       "609       0.000078                         []        3.4   \n",
       "613       0.000156                         []        3.4   \n",
       "629       0.000083                         []        3.4   \n",
       "633       0.000091                         []        3.4   \n",
       "636       0.000081                         []        3.4   \n",
       "711       0.000158                         []        3.4   \n",
       "714       0.000236                         []        3.4   \n",
       "736       0.000079                         []        3.4   \n",
       "741       0.000121                         []        3.4   \n",
       "774       0.000164                         []        3.4   \n",
       "\n",
       "                 Flux Density  Flux Density Uncertainty  Overlap Counts  \n",
       "10     [3.19273867620897e-08]    [3.10906427663272e-08]             NaN  \n",
       "51   [2.1183233725838155e-10]  [3.0875832142614227e-08]             NaN  \n",
       "52   [3.5500136480137275e-07]   [3.063953479399767e-08]             NaN  \n",
       "129   [4.958267235129992e-08]  [3.1218246798249594e-08]             NaN  \n",
       "165   [2.174278089708009e-08]   [3.106359083803017e-08]             NaN  \n",
       "200    [4.78952461225838e-09]  [3.0214271892610635e-09]             NaN  \n",
       "202  [2.0470410193695366e-09]  [3.0376346718766105e-09]             NaN  \n",
       "205    [2.77927976861057e-08]   [3.117536013556034e-09]             NaN  \n",
       "219   [1.528665905364602e-09]   [3.003961154366345e-09]             NaN  \n",
       "223  [1.1266390152011784e-09]   [3.055856398974445e-09]             NaN  \n",
       "239   [4.687372834596383e-10]  [3.0032672300434013e-09]             NaN  \n",
       "246   [5.934025897291922e-10]   [3.002722818240092e-09]             NaN  \n",
       "324   [7.552675580291517e-08]  [3.2282083121225253e-09]             NaN  \n",
       "360   [1.559668694671138e-08]  [3.0996785479298177e-09]             NaN  \n",
       "394   [8.960152692552383e-11]   [3.429411087308093e-10]             NaN  \n",
       "395  [4.0923632418140267e-10]  [3.6542949346395737e-10]             NaN  \n",
       "396   [2.625151232751326e-10]  [3.8403683860019765e-10]             NaN  \n",
       "397    [7.51726998501996e-10]  [4.0159691733323823e-10]             NaN  \n",
       "400  [1.6067943141794437e-10]  [4.4661213223925484e-10]             NaN  \n",
       "402   [1.951008123262403e-09]  [4.0889050380491147e-10]             NaN  \n",
       "403   [4.165915919208028e-10]  [3.5319388204422325e-10]             NaN  \n",
       "414  [3.2747010649913893e-10]  [3.4349743954882196e-10]             NaN  \n",
       "418  [4.3281540135761353e-10]  [4.1544648109247277e-10]             NaN  \n",
       "430  [3.7455455747931154e-10]   [3.701883944692322e-10]             NaN  \n",
       "431   [6.753573012624916e-12]    [3.61507210757474e-10]             NaN  \n",
       "434  [1.8229798605268535e-10]  [3.4422031949384266e-10]             NaN  \n",
       "438  [2.6815826214989865e-10]   [3.509644977048344e-10]             NaN  \n",
       "441   [4.836844101878687e-10]   [3.469809913450438e-10]             NaN  \n",
       "442  [1.0443620538760883e-09]  [3.3981463924049566e-10]             NaN  \n",
       "516   [5.765120806177205e-10]  [4.2050375822855363e-10]             NaN  \n",
       "519  [1.6424837598904433e-08]   [6.092999204845941e-10]             NaN  \n",
       "541   [1.897270644640328e-10]  [3.4153434041893106e-10]             NaN  \n",
       "546   [6.977349863586175e-10]  [3.8398567110741124e-10]             NaN  \n",
       "555   [5.786144998686642e-10]  [4.2984868457278707e-10]             NaN  \n",
       "579   [7.977919208068935e-10]  [4.2803858325068325e-10]             NaN  \n",
       "590    [2.82367822117744e-10]  [1.7263493350934003e-10]             NaN  \n",
       "592   [8.236569205955794e-10]  [2.3201511737017856e-10]             NaN  \n",
       "593  [1.8442172024025682e-09]  [2.7019201673423906e-10]             NaN  \n",
       "597   [2.354663308498713e-09]   [2.410700808104352e-10]             NaN  \n",
       "598   [4.767904328420143e-10]  [1.6033138638351403e-10]             NaN  \n",
       "609   [1.382920976659625e-10]  [1.2839894122591724e-10]             NaN  \n",
       "613   [4.659569063846909e-10]   [2.548406263690561e-10]             NaN  \n",
       "629  [1.7736202436740403e-10]   [1.368421742615447e-10]             NaN  \n",
       "633     [4.7549106823356e-10]  [1.5229527654991933e-10]             NaN  \n",
       "636    [6.30652996172757e-10]  [1.4005488432087592e-10]             NaN  \n",
       "711   [7.750244374532824e-10]  [2.6032591534475944e-10]             NaN  \n",
       "714   [2.438207199991237e-08]   [4.940096618038785e-10]             NaN  \n",
       "736  [2.4616279591900247e-10]   [1.318131863484321e-10]             NaN  \n",
       "741   [9.840361300053884e-10]  [2.0556469237342423e-10]             NaN  \n",
       "774   [9.877227136178846e-10]  [2.7198390090318427e-10]             NaN  \n",
       "\n",
       "[50 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "#print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "#for i in range(len(im_table)):\n",
    "    #print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "#g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Galaxies = Xray_sources.groupby(['Gname_Homogenized'])\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6 ,'w4':12.98 }\n",
    "wavelengths = {'w1': 3.4 ,'w2': 4.6,'w3': 12,'w4': 22}\n",
    "\n",
    "#define function to get flux density per unit frequency (energy units)\n",
    "def flux_dens(net_flx, net_flx_err, wavelength):\n",
    "    flux_density = (net_flx * 1e-23) * (3e10 / (wavelength*1e-4)**2)\n",
    "    flux_density_unc = (net_flx_err * 1e-23) * (3e10 / (wavelength*1e-4)**2)\n",
    "    return flux_density, flux_density_unc\n",
    "\n",
    "rows = []\n",
    "#for galaxy in Galaxies:\n",
    "   #  ra = galaxy['RA'].values\n",
    "   #  dec = galaxy['Dec'].values\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "        \n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error = np.sqrt(overlap_counts)\n",
    "                            \n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask))\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error = np.sqrt(overlap_counts)\n",
    "                            \n",
    "            if overlap:\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_counts -= overlap_counts\n",
    "\n",
    "                # so that i dont take the log or sqrt of a negative number or zero and get an error\n",
    "                if target_counts > 0: # \n",
    "                    target_error= np.sqrt(target_counts)\n",
    "                    #propagated error of overlap error\n",
    "                    target_overlap_counts_err = np.sqrt(target_error**2 + overlap_error**2)\n",
    "                    #print(target_counts)\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                         \n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error = (2.5*target_overlap_counts_err) / (target_counts * np.log(10))\n",
    "                         target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [], 'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [],  'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : []  })\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                \n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                    overlapannulus_error = np.sqrt(annulus_counts) # the error of the annulus for sources that overlap\n",
    "                     # to avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error_ann = (2.5 * overlapannulus_error) / (annulus_counts * np.log(10))\n",
    "                         annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "\n",
    "\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "                bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "                tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "                net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "            \n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': net_flx_err, 'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                    'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [],  'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "                \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    target_error = np.sqrt(target_counts)\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error = (2.5*target_error) / (target_counts * np.log(10))\n",
    "                         target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [],'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                # the error of the annulus for sources that overlap\n",
    "                \n",
    "                if annulus_counts > 0:\n",
    "                    annulus_error = np.sqrt(annulus_counts)\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                         #propagation of uncertainty of flux conversion\n",
    "                         Mcal_error_ann = (2.5 * annulus_error) / (annulus_counts * np.log(10))\n",
    "                         annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "               #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "                bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "                tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "                net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "\n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,  'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                              'Offset in Arcseconds': [],   'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': [], 'Wavelength': wavelengths[band_id],'Flux Density': [], 'Flux Density Uncertainty' : [] })  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,\n",
    "                    'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', \n",
    "                    'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, 'Exists?': 'No', 'Point Source Position' : [], 'Offset in Arcseconds': [],\n",
    "                     'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': [], 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "\n",
    "\n",
    "        #Source detection code\n",
    "        mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0)  \n",
    "       #print((mean, median, std))\n",
    "\n",
    "        # subtract the background and find FWHM of sources at a certain threshold\n",
    "        #started at fwhm= 3 and threshold = 5\n",
    "        daofind = DAOStarFinder(fwhm=8, threshold=1*std) # find the stars in the image that have FWHMs of around 3 pixels and have peaks approximately 5-sigma above the background. \n",
    "        sources = daofind(cutout_data - median)  \n",
    "        #print(type(sources))\n",
    "        # will likely run into iissues in the code below\n",
    "        for col in sources.colnames:  \n",
    "            if col not in ('id', 'npix'):\n",
    "                sources[col].info.format = '%.2f'  # for consistent table output\n",
    "       # sources.pprint(max_width=3000)  \n",
    "\n",
    "        #likely the flux labeled in this is not converted!\n",
    "        \n",
    "        # plot the image with marked locations of all the sources it detected.\n",
    "        detected_positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "        apertures = CircularAperture(detected_positions, r=2)\n",
    "\n",
    "\n",
    "        # Plotting for current image\n",
    "        # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        \n",
    "        # Was there a point source there?\n",
    "        pixelsinarc = 0.0003819444391411 * 3600 ## 0.0003819444391411 is the number found in the header of the image for the scale of pixels in degrees for the fits image.\n",
    "        detectedpos_all = []\n",
    "        #rows = [row for row in rows if row['Flag'] == 'Valid']\n",
    "        for row in valid_rows_filtered:\n",
    "            apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "            for detected_position in detected_positions:\n",
    "                detected_x, detected_y = detected_position\n",
    "                distance = dist((row['X'], row['Y']), (detected_x, detected_y) ) #distance from the center of the xray source to the center of the detected source\n",
    "                if distance <= row['Radius']: \n",
    "                    row['Exists?'] = 'Point Source Detected'\n",
    "                    row['Point Source Position'].append((detected_x, detected_y))\n",
    "                    dist_in_arc = distance * pixelsinarc\n",
    "                    row['Offset in Arcseconds'].append((dist_in_arc))\n",
    "                    detectedpos_all.append(detected_position) \n",
    "                    #print(f\"Number of detected positions within forced apertures: {len(detectedpos_all)}\")\n",
    "\n",
    "\n",
    "        Yes = []\n",
    "        YesRadius= 5\n",
    "        for row in valid_rows_filtered:\n",
    "                    apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "                    for detected_position in detected_positions:\n",
    "                        detected_x, detected_y = detected_position\n",
    "                        distance = dist((row['X'], row['Y']), (detected_x, detected_y) )\n",
    "\n",
    "                        if distance <= YesRadius:\n",
    "                            row['Exists?'] = 'Yes!!'\n",
    "                            Yes.append((row['X'], row['Y']))\n",
    "        #doing flux density\n",
    "        for row in valid_rows_filtered:\n",
    "             net_flx = row['Net Flux (Jy)']\n",
    "             net_flx_err = row['Flux Uncertainty']\n",
    "             #print(net_flx)\n",
    "             flux_density, flux_density_unc = flux_dens(net_flx, net_flx_err, wavelength)\n",
    "             row['Flux Density'].append(flux_density)\n",
    "             row['Flux Density Uncertainty'].append(flux_density_unc)\n",
    "                 \n",
    "        \n",
    "        # Update rows with valid_rows_filtered information\n",
    "        for valid_row in valid_rows_filtered:\n",
    "            for row in rows:\n",
    "                if row['band_id'] == valid_row['band_id'] and row['Region'] == valid_row['Region']:\n",
    "                    row.update(valid_row)\n",
    "\n",
    "        #print('valid sources', valid_rows_filtered)\n",
    "\n",
    "        #print( len(detectedpos_all))\n",
    "        if len(detectedpos_all) > 0:\n",
    "            apertures_detected = CircularAperture(detectedpos_all, r=2)\n",
    "        if len(Yes) > 0:\n",
    "            apertures_Yes = CircularAperture(Yes, r=YesRadius)\n",
    "        \n",
    "       # xc = 244.422687\t #19.014239\t\n",
    "       # yc=  191.596758# 310.340772\n",
    "    \n",
    "\n",
    "         # Plotting for current image\n",
    "        #fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        #norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        #for row in valid_rows_filtered:\n",
    "         #  target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "          #  annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "           # target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "          #  annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "            \n",
    "           # apertures.plot(color='#98ff98', lw=.5, alpha=0.5) \n",
    "           # apertures_detected.plot(color='#FF4500', lw=.5, alpha=0.5)  #  #FF69B4 for hot pink\n",
    "           # apertures_Yes.plot(color='green', lw=.5, alpha=0.5) \n",
    "\n",
    "            # curious ones\n",
    "           # curious = CircularAperture((xc,yc),5)\n",
    "           # curious.plot(color='red', lw=.5, alpha=0.5)\n",
    "       # ax.imshow(cutout.data, cmap='gray', norm=norm, interpolation='nearest')\n",
    "       # ax.set_xlabel('Right Ascension')\n",
    "       # ax.set_ylabel('Declination')\n",
    "       # plt.title(f'Band {band_labels[band_id]}')\n",
    "       # plt.show()\n",
    "        yesses =[row for row in valid_rows_filtered if row['Exists?'] == 'Yes!!']\n",
    "       \n",
    "\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "#pd.set_option(\"display.max_columns\", None)\n",
    "print('Number of valid sources: ',len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "print('Number of sources: ',len(display_data))\n",
    "print('Number of sources coincidental with WISE bright points within 5 arcsec: ',len(display_data.loc[display_data['Exists?']== 'Yes!!']))\n",
    "#display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data.loc[display_data['Exists?']== 'Yes!!'])\n",
    "#display(display_data)\n",
    "#print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
