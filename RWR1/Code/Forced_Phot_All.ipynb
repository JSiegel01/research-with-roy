{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyvo as vo\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "from photutils.utils import calc_total_error\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "import json\n",
    "\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from photutils.detection import DAOStarFinder\n",
    "from astropy.stats import mad_std, sigma_clipped_stats\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running over all galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/77pj43rx7wbcbp0wx2qjq2140000gp/T/ipykernel_75616/263547423.py:50: DtypeWarning: Columns (533,534) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy: NGC 5128\n",
      "Galaxy: MESSIER 106\n",
      "Galaxy: MESSIER 051\n",
      "Galaxy: MESSIER 082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n",
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy: NGC 1569\n",
      "Galaxy: NGC 0253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy: NGC 0891\n",
      "Galaxy: NGC 1291:[LFF2012] 084\n",
      "Galaxy: NGC 4631\n",
      "Galaxy: MESSIER 094\n",
      "Galaxy: NGC 4945\n",
      "No sources found for galaxy: UGC 06456\n",
      "Galaxy: NGC 6503\n",
      "No sources found for galaxy: NGC 4395\n",
      "Galaxy: NGC 4244\n",
      "No sources found for galaxy: NGC 4111\n",
      "Galaxy: NGC 4485\n",
      "Galaxy: MESSIER 105\n",
      "Galaxy: NGC 2403\n",
      "Galaxy: MESSIER 108\n",
      "Galaxy: NGC 5253\n",
      "Galaxy: MESSIER 074\n",
      "Galaxy: ESO 495- G 021\n",
      "Galaxy: MESSIER 063\n",
      "No sources found for galaxy: NGC 7331\n",
      "Galaxy: NGC 5102\n",
      "Galaxy: NGC 4725\n",
      "Galaxy: NGC 4526\n",
      "Galaxy: NGC 1705\n",
      "Galaxy: NGC 7793\n",
      "Galaxy: NGC 4473\n",
      "Galaxy: NGC 2787\n",
      "Galaxy: NGC 0045\n",
      "Galaxy: NGC 1023\n",
      "Galaxy: NGC 0625\n",
      "Galaxy: Maffei 1\n",
      "Galaxy: MESSIER 090\n",
      "Galaxy: MESSIER 081\n",
      "Galaxy: MESSIER 100\n",
      "No sources found for galaxy: NGC 4026\n",
      "Galaxy: NGC 7090\n",
      "Galaxy: Maffei 2\n",
      "Galaxy: NGC 2915\n",
      "Galaxy: UGC 04459\n",
      "Galaxy: NGC 5474\n",
      "Galaxy: NGC 0024\n",
      "Galaxy: MESSIER 066\n",
      "Galaxy: NGC 4625\n",
      "Galaxy: NGC 0855\n",
      "Galaxy: NGC 3521\n",
      "No sources found for galaxy: NGC 5408\n",
      "Galaxy: NGC 2903\n",
      "Galaxy: NGC 3384\n",
      "Galaxy: NGC 7457\n",
      "No sources found for galaxy: NGC 4178\n",
      "Galaxy: MESSIER 083\n",
      "Galaxy: NGC 4088\n",
      "Galaxy: NGC 4417\n",
      "Galaxy: MRK 0750\n",
      "Galaxy: NGC 0660\n",
      "Galaxy: NGC 2835\n",
      "Galaxy: NGC 6744\n",
      "Galaxy: NGC 5248\n",
      "Galaxy: NGC 3344\n",
      "Galaxy: NGC 4550\n",
      "Galaxy: NGC 4551\n",
      "Galaxy: NGC 5866\n",
      "Galaxy: MESSIER 099\n",
      "Galaxy: NGC 4460\n",
      "Galaxy: NGC 4536\n",
      "Galaxy: NGC 4302\n",
      "Galaxy: NGC 1792\n",
      "Galaxy: IC342\n",
      "Galaxy: MESSIER 096\n",
      "Number of valid sources:  18465\n",
      "Number of sources that dont 100 percent overlap x4 (because it is iterating over all 4 bands and appending each one once):  21424\n",
      "Number of sources coincidental with WISE bright points within 5 arcsec:  9414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\n all of the valid sources\")\\ndisplay(display_data.loc[display_data[\\'Flag\\']== \\'Valid\\'])\\nprint(\"\\n all of the Yes!! sources\")\\ndisplay(display_data.loc[display_data[\\'Exists?\\']== \\'Yes!!\\'])\\n\\ndisplay(display_data)\\nprint(len(display_data.loc[display_data[\\'Flag\\']== \\'Valid\\']))\\n\\n\\n\\n\\n\\n\\n  \\n#'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Defining the constants\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "   return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "   Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "   dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "   mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "   return mask\n",
    "\n",
    "def overlap_area(radius, distance):\n",
    "    Area = ((2 * radius**2) * np.arccos((distance / (2 * radius)))) - ( .5 * distance * np.sqrt( (4 * radius**2) - distance**2))\n",
    "    return Area\n",
    "\n",
    "\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6 ,'w4':12.98 }\n",
    "wavelengths = {'w1': 3.4 ,'w2': 4.6,'w3': 12,'w4': 22}\n",
    "\n",
    "\n",
    "#define function to get flux density per unit frequency (energy units)\n",
    "def flux_dens(net_flx, net_flx_err, wavelength):\n",
    "   flux_density = (net_flx * 1e-23) * (3e10 / (wavelength*1e-4)**2)\n",
    "   flux_density_unc = (net_flx_err * 1e-23) * (3e10 / (wavelength*1e-4)**2)\n",
    "   return flux_density, flux_density_unc\n",
    "\n",
    "\n",
    "'''\n",
    "make a conditional code where:\n",
    "choose one obs id and eerything associated with it bwith the longest exposuretime exptime?\n",
    "tell me all of the obsids associated with this galaxy_name\n",
    "    unique list of each galaxy Name\n",
    "    what are the obs ids associated with it\n",
    "    if more than one which one is the longest exposure\n",
    "    aggregate all of the associated sources with it and none from any of the others\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#import huge csv and grab the name and ra and dec needed for each galaxy.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "#print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec','Gname_Modified','Gname_Homogenized', 'ObsID', 'EXPOSURE']\n",
    "g_huge = huge[columns]\n",
    "#display(g_huge.head())\n",
    "\n",
    "\n",
    "#group the x-ray sources for this galaxy. locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns1 = ['RA','Dec','Gname_Homogenized', 'ObsID', 'EXPOSURE']\n",
    "Xray_sources = merged_data[columns1]\n",
    "\n",
    "\n",
    "#group by galaxy name and the longest exposure time.\n",
    "longest_exposure_obs = Xray_sources.loc[Xray_sources.groupby('Gname_Homogenized')['EXPOSURE'].idxmax()]\n",
    "\n",
    "\n",
    "# aggregate all the sources associated with the obsid with the longest exposure time\n",
    "aggregated_sources = Xray_sources[Xray_sources['ObsID'].isin(longest_exposure_obs['ObsID'])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#align them based on source Id since they all got jumbled.\n",
    "#aligned_targetgals = targetgals[targetgals.isin(aggregated_sources['Gname_Homogenized'])]\n",
    "\n",
    "\n",
    "#reset index and group them by name\n",
    "#aligned_targetgals = aligned_targetgals.reset_index(drop=True)\n",
    "#print(aligned_targetgals)\n",
    "#aligned_aggregatedsources = aggregated_sources.groupby('Gname_Homogenized')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "print(\"Unique list of each galaxy name:\")\n",
    "print(targetgals['source_id'])\n",
    "\n",
    "\n",
    "print(\"\\nObservations with the longest exposure time for each galaxy:\")\n",
    "print(longest_exposure_obs)\n",
    "\n",
    "\n",
    "print(\"\\nAggregated sources:\")\n",
    "print(aggregated_sources)\n",
    "#'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ensure the uniqueness for NGC 5128\n",
    "#ngc_5128_sources = Xray_sources[Xray_sources['Gname_Homogenized'] == 'NGC 5128']\n",
    "#print(f\"Number of unique X-ray sources for NGC 5128: {len(ngc_5128_sources)}\")\n",
    "#print(ngc_5128_sources)\n",
    "\n",
    "\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "#pd.set_option(\"display.max_columns\", None)\n",
    "#display(g_huge)\n",
    "#display(Xray_sources)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create a list of all the names needed\n",
    "galaxy_names = targetgals['source_id'].unique()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "galaxy_sources = {}\n",
    "grouped_sources = aggregated_sources.groupby('Gname_Homogenized')\n",
    "'''print(\"\\nGrouped sources:\")\n",
    "for group_name, group in grouped_sources:\n",
    "   print(f\"\\nGroup: {group_name}\")\n",
    "   print(group)'''\n",
    "#get all of the ra and dec sources for the galaxy in question\n",
    "for group_name, group in grouped_sources:\n",
    "   galaxy_sources[group_name] = {'ra' : group['RA'].values, 'dec' : group['Dec'].values, 'ObsID': group['ObsID'].values}\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "rows = []\n",
    "#create subsets for testing:\n",
    "#grouped_sources_subset = grouped_sources.head(2)\n",
    "#targetgals_subset = targetgals.head(2)\n",
    "\n",
    "\n",
    "#targetgals_subset = targetgals.iloc[0:73]\n",
    "\n",
    "\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "#loop through the galaxies\n",
    "#print(\"\\nAligned target galaxies and grouped sources:\")\n",
    "\n",
    "\n",
    "for galaxy in targetgals.itertuples():\n",
    "    galaxy_name = galaxy.source_id\n",
    "    #print(galaxy_name)\n",
    "    #group = aligned_aggregatedsources.get_group(galaxy_name)\n",
    "  \n",
    "    # Print galaxy information\n",
    "    #print(f\"\\nGalaxy: {galaxy_name}\")\n",
    "    #print(group)\n",
    "\n",
    "\n",
    "    #define coordinates\n",
    "    ra1 = galaxy.ra_x\n",
    "    #print (ra1)\n",
    "    dec1 = galaxy.dec_x\n",
    "    pos = SkyCoord(ra=ra1, dec=dec1, unit= 'deg')\n",
    "    #search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "    im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "    #im_table\n",
    "    im_table.to_table().colnames\n",
    "    #print(im_table)\n",
    "    # get the Ra and dec values necessary for the kdtree and rest of the code\n",
    "    if galaxy_name in galaxy_sources:\n",
    "       ra = galaxy_sources[galaxy_name]['ra']\n",
    "       dec = galaxy_sources[galaxy_name]['dec']\n",
    "       obsid = galaxy_sources[galaxy_name]['ObsID']\n",
    "       print(f\"Galaxy: {galaxy_name}\")\n",
    "       #print(\"RA values:\", ra)\n",
    "       #print(\"Number of RA values:\", len(ra))\n",
    "    else:\n",
    "       print(f\"No sources found for galaxy: {galaxy_name}\")\n",
    "       continue # skip to the next galaxy if no sources were found\n",
    "          \n",
    "   ##running the for loop over every image and doing aperture photometry on each one\n",
    "   #currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "\n",
    "    for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "        band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "        if band_id in band_labels:\n",
    "            #print(f'Band {band_labels[band_id]}: ')\n",
    "            data_url = im_table[i].getdataurl()\n",
    "            #Download the image and open it in Astropy\n",
    "            fname = download_file(data_url, cache=True)\n",
    "            image1= fits.open(fname)\n",
    "            image_data= image1[0].data\n",
    "            #print(data)\n",
    "            #print(data_url)\n",
    "            wcs = WCS(image1[0].header)\n",
    "            #cuting out the image of the galaxy apart from the rest of the background.\n",
    "            cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "            wcs = cutout.wcs\n",
    "            cutout_data = cutout.data\n",
    "            #print(cutout_data)\n",
    "            positions = wcs.world_to_pixel_values(ra, dec)\n",
    "            positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "\n",
    "            #define the distance threshold for the KDTree grouping (in pixels)\n",
    "            distance_threshold = 5\n",
    "\n",
    "\n",
    "            #build the KDTree for efficient grouping\n",
    "            tree = KDTree(positions)\n",
    "\n",
    "\n",
    "            #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "            groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "            # print(groups)\n",
    "            # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "            unique_groups = []\n",
    "            seen = set()\n",
    "            for group in groups:\n",
    "                group = tuple(sorted(group))\n",
    "                if group not in seen:\n",
    "                    seen.add(group)\n",
    "                    unique_groups.append(group)\n",
    "                 # print(unique_groups)\n",
    "            # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "             #represents the consolidated postion of potentially multiple detections of one source.\n",
    "            grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "            #print(grouped_positions)\n",
    "\n",
    "            #print(\"Grouped positions for galaxy\", galaxy_name, \":\", grouped_positions)\n",
    "            #define the Region(s) Of Interest (center x, center y, radius)\n",
    "            ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping?\n",
    "          \n",
    "\n",
    "\n",
    "                # initialize valid rows plotting for the current image iteration\n",
    "            valid_rows = []\n",
    "           \n",
    "           #now inputting the aperture photometry part\n",
    "           # check for overlap and perform aperture photometry\n",
    "            for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "                overlap_dict = []\n",
    "                overlap = False # initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source. becomes true if they do overlap \n",
    "                acc_overlap = False # initialize the acceptable overlap flag.  false if there is no overlap, true if there is overlap and it is acceptable \n",
    "               \n",
    "\n",
    "                for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                    if i != j: # ensures that a source is not compared to itself! wow\n",
    "                        #print(f'{x}, {y} / {x2}, {y2}')\n",
    "                        #print(f\"Checking positions: ({x}, {y}) and ({x2, {y2}})\")\n",
    "                        distance = dist((x, y) , (x2, y2))\n",
    "                        #print(f\"Distance: {distance}, Radii Sum: {r + r2}\")\n",
    "                        #print('dsitance', distance)\n",
    "                        #print('Distance', distance)\n",
    "                        #print('r1', r)\n",
    "                        if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                            #print(distance)\n",
    "                            #print('yesif')\n",
    "                            overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                            #print('overlap perc', overlap_percent)\n",
    "                            if overlap_percent > .5:\n",
    "                                overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                                #print('overlap is unacceptable: ', overlap)\n",
    "                                overlap_aperture = np.nan\n",
    "                                overlap_photo_table = np.nan\n",
    "                                overlap_counts = np.nan\n",
    "                                overlap_error = np.nan\n",
    "                              \n",
    "                            elif overlap_percent <= .5:\n",
    "                                acc_overlap = True\n",
    "                                #print('acceptable or no overlap: ', acc_overlap)\n",
    "                                #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                                overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                                overlapping_area = overlap_area(r,distance) # using the function to define the overlapping area for the location of overlap\n",
    "                                overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                                total_area = math.pi * r**2\n",
    "                                overlap_counts = overlap_photo_table['aperture_sum'][0] * ( overlapping_area/total_area ) # scaling the counts by the overlapping area\n",
    "                                overlap_error = np.sqrt(overlap_counts)\n",
    "                                overlap_dict.append({'Position': ({x}, {y}),  'overlapping counts': overlap_counts, 'overlap_error': overlap_error})\n",
    "                                #print('were here')\n",
    "                                #print('Overlap counts', overlap_counts)\n",
    "                                #print('overlapdict', overlap_dict)\n",
    "\n",
    "\n",
    "\n",
    "                        else:\n",
    "                            #print(' Prob skips distance if statement')\n",
    "                            #print('not overlapping at all')\n",
    "                            overlap_percent = np.nan\n",
    "                            overlap_aperture = np.nan\n",
    "                            overlap_photo_table = np.nan\n",
    "                            overlap_counts = np.nan\n",
    "                            overlap_error = np.nan\n",
    "\n",
    "                       \n",
    "                #print(acc_overlap)  \n",
    "                if acc_overlap:\n",
    "                    overlap_counts = 0\n",
    "                    overlap_error = 0\n",
    "                    # for a source, if it overlaps with more than one other source, add all of the counts for those overlapping regions\n",
    "                    for row in overlap_dict:\n",
    "                        if not np.isnan(row['overlapping counts']) and not np.isnan(row['overlap_error']):\n",
    "                            overlap_counts += row['overlapping counts'] # now add in quadriture for the propagation of error for sources like this\n",
    "                            overlap_error += row['overlap_error']**2\n",
    "                    overlap_error= np.sqrt(overlap_error)\n",
    "                    #print('Overlapping COUNTS HERE', overlap_counts)\n",
    "                    # For the Target objects in the little aperture circle define their target apertures\n",
    "                    target_aperture = CircularAperture((x,y),r,)\n",
    "                   \n",
    "                    #perform aperture photometry on target\n",
    "                    target_photo_table = aperture_photometry(cutout_data, target_aperture)\n",
    "                    target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                    target_counts -= overlap_counts\n",
    "                    # so that i dont take the log or sqrt of a negative number or zero and get an error\n",
    "                    if target_counts > 0: #\n",
    "                        target_error= np.sqrt(target_counts)\n",
    "                        #propagated error of overlap error\n",
    "                        target_overlap_counts_err = np.sqrt(target_error**2 + overlap_error**2)\n",
    "                        #print(target_counts)\n",
    "                        if band_id in flux_zmfd and instr_zpmag:\n",
    "                            #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                            flx_conv_fact = flux_zmfd[band_id]\n",
    "                            M0instr = instr_zpmag[band_id]\n",
    "                            Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                            target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                          \n",
    "                            #propagation of uncertainty of flux conversion\n",
    "                            Mcal_error = (2.5*target_overlap_counts_err) / (target_counts * np.log(10))\n",
    "                            target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "\n",
    "                    else:# to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        target_error = np.nan\n",
    "                        target_overlap_counts_err = np.nan\n",
    "                        target_flux = np.nan\n",
    "                        target_flux_error = np.nan\n",
    "                        flx_conv_fact = np.nan\n",
    "                        M0instr = np.nan\n",
    "                        target_counts = np.nan\n",
    "\n",
    "                    # continuing on with the photometry under the \"if acc_overlap\"\n",
    "\n",
    "\n",
    "                    #calculate area of target aperutue\n",
    "                    target_area = target_aperture.area\n",
    "\n",
    "                    # For the Background Annuli of outside of the Target\n",
    "                    #define the background annulus for the target\n",
    "                    annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "\n",
    "                    #perform aperture photometry on annuli\n",
    "                    annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                    annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                  \n",
    "              \n",
    "                    if annulus_counts > 0:\n",
    "                        overlapannulus_error = np.sqrt(annulus_counts) # the error of the annulus for sources that overlap\n",
    "                        # to avoid taking the log of zero or negative value\n",
    "                        if band_id in flux_zmfd and instr_zpmag:\n",
    "                            #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                            flx_conv_fact = flux_zmfd[band_id]\n",
    "                            M0instr = instr_zpmag[band_id]\n",
    "                            Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                            annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "\n",
    "                            #propagation of uncertainty of flux conversion\n",
    "                            Mcal_error_ann = (2.5 * overlapannulus_error) / (annulus_counts * np.log(10))\n",
    "                            annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    else: \n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        overlapannulus_error = np.nan\n",
    "                        flx_conv_fact = np.nan\n",
    "                        M0instr = np.nan\n",
    "                        annulus_counts = np.nan\n",
    "                          \n",
    "                    #calculate area of annulus\n",
    "                    annulus_area = annulus_aperture.area\n",
    "\n",
    "\n",
    "                    # do the calculations for including a Background aperture\n",
    "              \n",
    "                    #Calculating the net flux:\n",
    "                    #calculate the mean background per pixel\n",
    "                    bg_perpixel = annulus_flux/annulus_area\n",
    "                    bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "\n",
    "                    #calculate the total background in the target aperture\n",
    "                    tot_bg = bg_perpixel * target_area\n",
    "                    tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "\n",
    "                    #Subtract background from the target flux\n",
    "                    net_flx = target_flux - tot_bg\n",
    "                    net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "              \n",
    "                    #flag the sources that overlap\n",
    "                    rows.append({ 'band_id': {band_labels[band_id]}, 'Galaxy Name' : galaxy_name, 'ObsID' : obsid[0], 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                           'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': net_flx_err, 'Flag':'Valid' if not np.isnan(np.array(target_counts)) and target_counts > 0 and net_flx > 0 else 'Nan values or Low Flux',\n",
    "                           'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux, 'Acceptable overlapping?': 'Yes' if acc_overlap == True else 'Not acceptable or no overlap at all', 'Unacceptable overlapping?': 'Yes' if overlap == True else 'Acceptable or no overlap at all',\n",
    "                               'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                               'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "                    # Append valid results to valid_rows\n",
    "                    valid_rows.append({\n",
    "                       'band_id': {band_labels[band_id]},  'Galaxy Name' : galaxy_name, 'ObsID' : obsid[0],\n",
    "                       'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                       'Annulus_Inner_Radius': annulus_inner,\n",
    "                       'Annulus_Outer_Radius': annulus_outer,\n",
    "                       'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,'Flag':'Valid' if not np.isnan(np.array(target_counts)) and target_counts > 0 and net_flx > 0 else 'Nan values or Low Flux', 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                       'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [],  'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': overlap_error, 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "                  \n",
    "                else: #perform all the normal aperture photometry stuff for those that do not overlap in any way.\n",
    "            \n",
    "                   # For the Target objects in the little aperture circle define their target apertures\n",
    "                    target_aperture = CircularAperture((x,y),r,)\n",
    "              \n",
    "                    #perform aperture photometry on target\n",
    "                    target_photo_table = aperture_photometry(cutout_data, target_aperture)\n",
    "                    target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "\n",
    "                    if target_counts > 0:   # avoid taking the log of zero or negative value\n",
    "                        target_error = np.sqrt(target_counts)\n",
    "                        if band_id in flux_zmfd and instr_zpmag:\n",
    "                            #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                            flx_conv_fact = flux_zmfd[band_id]\n",
    "                            M0instr = instr_zpmag[band_id]\n",
    "                            Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                            target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "\n",
    "                            #propagation of uncertainty of flux conversion\n",
    "                            Mcal_error = (2.5*target_error) / (target_counts * np.log(10))\n",
    "                            target_flux_error = target_flux * np.log(10) * (Mcal_error/2.5)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        target_error = np.nan\n",
    "                        target_flux = np.nan\n",
    "                        target_flux_error = np.nan\n",
    "                        flx_conv_fact = np.nan\n",
    "                        M0instr = np.nan\n",
    "                        target_counts = np.nan\n",
    "\n",
    "                      \n",
    "                    #calculate area of target aperutue\n",
    "                    target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    # For the Background Annuli of outside of the Target\n",
    "                    #define the background annulus for the target\n",
    "                    annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "\n",
    "                    #perform aperture photometry on annuli\n",
    "                    annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                    annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                    # the error of the annulus for sources that overlap\n",
    "                  \n",
    "                    if annulus_counts > 0:\n",
    "                        annulus_error = np.sqrt(annulus_counts)\n",
    "                        # avoid taking the log of zero or negative value\n",
    "                        if band_id in flux_zmfd and instr_zpmag:\n",
    "                            #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                            flx_conv_fact = flux_zmfd[band_id]\n",
    "                            M0instr = instr_zpmag[band_id]\n",
    "                            Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                            annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "\n",
    "                            #propagation of uncertainty of flux conversion\n",
    "                            Mcal_error_ann = (2.5 * annulus_error) / (annulus_counts * np.log(10))\n",
    "                            annulus_flux_error = annulus_flux * np.log(10) * (Mcal_error_ann/2.5)\n",
    "                    else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        annulus_error = np.nan\n",
    "                        annulus_flux_error = np.nan\n",
    "                        flx_conv_fact = np.nan\n",
    "                        M0instr = np.nan\n",
    "                        annulus_counts = np.nan\n",
    "                          \n",
    "                    #calculate area of annulus\n",
    "                    annulus_area = annulus_aperture.area\n",
    "\n",
    "\n",
    "                    # do the calculations for including a Background aperture\n",
    "              \n",
    "                    #Calculating the net flux:\n",
    "                    #calculate the mean background per pixel\n",
    "                    bg_perpixel = annulus_flux/annulus_area\n",
    "                    bg_perpixel_err = annulus_flux_error/annulus_area #propagation of error!\n",
    "\n",
    "\n",
    "                    #calculate the total background in the target aperture\n",
    "                    tot_bg = bg_perpixel * target_area\n",
    "                    tot_bg_err = bg_perpixel_err * target_area ##propagation of error!\n",
    "\n",
    "\n",
    "                    #Subtract background from the target flux\n",
    "                    net_flx = target_flux - tot_bg\n",
    "                    net_flx_err = np.sqrt(target_flux_error**2 + tot_bg_err**2) ##propagation of error!\n",
    "\n",
    "                    if overlap:\n",
    "                        overlap_counts = np.nan\n",
    "                        overlap_error = np.nan\n",
    "                        target_counts = np.nan\n",
    "\n",
    "                    #   Append the result as a dictionary to the list named 'rows'\n",
    "                    rows.append({ 'band_id': {band_labels[band_id]}, 'Galaxy Name' : galaxy_name, 'ObsID' : obsid[0], 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                           'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,  'Flag':'Valid' if not np.isnan(np.array(target_counts)) and target_counts > 0 and net_flx > 0 else 'Nan values or Low Flux',\n",
    "                           'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux, 'Acceptable overlapping?': 'Yes' if acc_overlap == True else 'Not acceptable or no overlap at all','Unacceptable overlapping?': 'Yes' if overlap == True else 'Acceptable or no overlap at all',\n",
    "                               'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                               'Offset in Arcseconds': [],   'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': [], 'Wavelength': wavelengths[band_id],'Flux Density': [], 'Flux Density Uncertainty' : [] })  #will prolly have to change the name of the Flux here!!!\n",
    "                        #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "              \n",
    "                    # Append valid results to valid_rows\n",
    "                    valid_rows.append({\n",
    "                       'band_id': {band_labels[band_id]}, 'Galaxy Name' : galaxy_name, 'ObsID' : obsid[0],\n",
    "                       'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                       'Annulus_Inner_Radius': annulus_inner,\n",
    "                       'Annulus_Outer_Radius': annulus_outer,\n",
    "                       'Net Flux (Jy)': net_flx, 'Flux Uncertainty': net_flx_err,\n",
    "                       'Flag':'Valid' if not np.isnan(np.array(target_counts)) and target_counts > 0 and net_flx > 0 else 'Nan values or Low Flux',\n",
    "                       'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, 'Exists?': 'No', 'Point Source Position' : [], 'Offset in Arcseconds': [],\n",
    "                       'Target Error': target_flux_error, 'Annulus Error': annulus_flux_error, 'Overlap Error (in counts)': [], 'Wavelength': wavelengths[band_id], 'Flux Density': [], 'Flux Density Uncertainty' : [] })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #Source detection code\n",
    "            mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0) \n",
    "            #print((mean, median, std))\n",
    "\n",
    "\n",
    "            # subtract the background and find FWHM of sources at a certain threshold\n",
    "            #started at fwhm= 3 and threshold = 5\n",
    "            daofind = DAOStarFinder(fwhm=8, threshold=1*std) # find the stars in the image that have FWHMs of around 3 pixels and have peaks approximately 5-sigma above the background.\n",
    "            sources = daofind(cutout_data - median) \n",
    "            #print(type(sources))\n",
    "            # will likely run into iissues in the code below\n",
    "            for col in sources.colnames: \n",
    "                if col not in ('id', 'npix'):\n",
    "                    sources[col].info.format = '%.2f'  # for consistent table output\n",
    "                        # sources.pprint(max_width=3000) \n",
    "\n",
    "\n",
    "                        #likely the flux labeled in this is not converted!\n",
    "          \n",
    "            # plot the image with marked locations of all the sources it detected.\n",
    "            detected_positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "            apertures = CircularAperture(detected_positions, r=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Plotting for current image\n",
    "            # Filter valid rows\n",
    "            valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "          \n",
    "            # Was there a point source there?\n",
    "            pixelsinarc = 0.0003819444391411 * 3600 ## 0.0003819444391411 is the number found in the header of the image for the scale of pixels in degrees for the fits image.\n",
    "            detectedpos_all = []\n",
    "            #rows = [row for row in rows if row['Flag'] == 'Valid']\n",
    "            for row in valid_rows_filtered:\n",
    "                apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "                for detected_position in detected_positions:\n",
    "                    detected_x, detected_y = detected_position\n",
    "                    distance = dist((row['X'], row['Y']), (detected_x, detected_y) ) #distance from the center of the xray source to the center of the detected source\n",
    "                    if distance <= row['Radius']:\n",
    "                        row['Exists?'] = 'Point Source Detected'\n",
    "                        row['Point Source Position'].append((detected_x, detected_y))\n",
    "                        dist_in_arc = distance * pixelsinarc\n",
    "                        row['Offset in Arcseconds'].append((dist_in_arc))\n",
    "                        detectedpos_all.append(detected_position)\n",
    "\n",
    "\n",
    "\n",
    "            Yes = []\n",
    "            YesRadius= 5\n",
    "            for row in valid_rows_filtered:\n",
    "                        apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "                        for detected_position in detected_positions:\n",
    "                            detected_x, detected_y = detected_position\n",
    "                            distance = dist((row['X'], row['Y']), (detected_x, detected_y) )\n",
    "                            if distance <= YesRadius:\n",
    "                                row['Exists?'] = 'Yes!!'\n",
    "                                Yes.append((row['X'], row['Y']))\n",
    "                                #else: # this does not seem to do what i want it to do\n",
    "                               #row['Exists?'] = 'Detected but does not exist'\n",
    "                               \n",
    "            #doing flux density\n",
    "            for row in valid_rows_filtered:\n",
    "                net_flx = row['Net Flux (Jy)']\n",
    "                net_flx_err = row['Flux Uncertainty']\n",
    "                wavelength = row['Wavelength']\n",
    "                #print(net_flx)\n",
    "                flux_density, flux_density_unc = flux_dens(net_flx, net_flx_err, wavelength)\n",
    "                row['Flux Density'].append(flux_density)\n",
    "                row['Flux Density Uncertainty'].append(flux_density_unc)\n",
    "                  \n",
    "          \n",
    "            # Update rows with valid_rows_filtered information\n",
    "            for valid_row in valid_rows_filtered:\n",
    "                for row in rows:\n",
    "                    if row['band_id'] == valid_row['band_id'] and row['Region'] == valid_row['Region']:\n",
    "                        row.update(valid_row)\n",
    "\n",
    "\n",
    "            #print('valid sources', valid_rows_filtered)\n",
    "\n",
    "\n",
    "            #print( len(detectedpos_all))\n",
    "            if len(detectedpos_all) > 0:\n",
    "                apertures_detected = CircularAperture(detectedpos_all, r=2)\n",
    "            if len(Yes) > 0:\n",
    "                apertures_Yes = CircularAperture(Yes, r=YesRadius)\n",
    "          \n",
    "         # xc = 244.422687    #19.014239\n",
    "        # yc=  191.596758# 310.340772\n",
    "      \n",
    "                \n",
    "\n",
    "           # Plotting for current image\n",
    "            '''\n",
    "            fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "            norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "            for row in valid_rows_filtered: # use 'valid_rows_filtered' to change it back to only the valid sources. use 'rows' to plot all sources\n",
    "                target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "                annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "                target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "                annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "              \n",
    "                apertures.plot(color='#98ff98', lw=.5, alpha=0.5)\n",
    "                apertures_detected.plot(color='#FF4500', lw=.5, alpha=0.5)  #  #FF69B4 for hot pink\n",
    "                apertures_Yes.plot(color='green', lw=.5, alpha=0.5)\n",
    "\n",
    "\n",
    "                # curious ones\n",
    "            # curious = CircularAperture((xc,yc),5)\n",
    "            # curious.plot(color='red', lw=.5, alpha=0.5)\n",
    "            ax.imshow(cutout.data, cmap='gray', norm=norm, interpolation='nearest')\n",
    "            ax.set_xlabel('Right Ascension')\n",
    "            ax.set_ylabel('Declination')\n",
    "            plt.title(f'Band {band_labels[band_id]}')\n",
    "            plt.show()\n",
    "            yesses =[row for row in valid_rows_filtered if row['Exists?'] == 'Yes!!']\n",
    "            #'''\n",
    "   \n",
    "           \n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "           \n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "#by_name = display_data.groupby('Galaxy Name')\n",
    "#byname = by_name.apply(lambda x: x).reset_index(drop=True)\n",
    "#print(\"\\n FINAL Sources Grouped by Galaxy:\")\n",
    "#display(byname)\n",
    "#byname_byband = by_name.groupby('band_id')\n",
    "#display(byname_byband)\n",
    "\n",
    "\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "#pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print('Number of valid sources: ',len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "print('Number of sources that dont 100 percent overlap x4 (because it is iterating over all 4 bands and appending each one once): ',len(display_data))\n",
    "print('Number of sources coincidental with WISE bright points within 5 arcsec: ',len(display_data.loc[display_data['Exists?']== 'Yes!!']))\n",
    "'''\n",
    "print(\"\\n all of the valid sources\")\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "print(\"\\n all of the Yes!! sources\")\n",
    "display(display_data.loc[display_data['Exists?']== 'Yes!!'])\n",
    "\n",
    "display(display_data)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "#'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Data/Hugefiles/forced_phot_YES1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Write the table in csv format\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m data_out\u001b[38;5;241m.\u001b[39mwrite(output_path, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/astropy/table/connect.py:130\u001b[0m, in \u001b[0;36mTableWrite.__call__\u001b[0;34m(self, serialize_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instance\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m serialize_method_as(instance, serialize_method):\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mwrite(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/astropy/io/registry/core.py:383\u001b[0m, in \u001b[0;36mUnifiedOutputRegistry.write\u001b[0;34m(self, data, format, *args, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_valid_format(\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, path, fileobj, args, kwargs\n\u001b[1;32m    380\u001b[0m     )\n\u001b[1;32m    382\u001b[0m writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_writer(\u001b[38;5;28mformat\u001b[39m, data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m writer(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/astropy/io/ascii/connect.py:28\u001b[0m, in \u001b[0;36mio_write\u001b[0;34m(format, table, filename, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^ascii\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m     27\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m write(table, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/astropy/io/ascii/ui.py:978\u001b[0m, in \u001b[0;36mwrite\u001b[0;34m(table, output, format, Writer, fast_writer, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m writer \u001b[38;5;241m=\u001b[39m get_writer(Writer\u001b[38;5;241m=\u001b[39mWriter, fast_writer\u001b[38;5;241m=\u001b[39mfast_writer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer\u001b[38;5;241m.\u001b[39m_format_name \u001b[38;5;129;01min\u001b[39;00m core\u001b[38;5;241m.\u001b[39mFAST_CLASSES:\n\u001b[0;32m--> 978\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwrite(table, output)\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    981\u001b[0m lines \u001b[38;5;241m=\u001b[39m writer\u001b[38;5;241m.\u001b[39mwrite(table)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/astropy/io/ascii/fastbasic.py:238\u001b[0m, in \u001b[0;36mFastCsv.write\u001b[0;34m(self, table, output)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, table, output):\n\u001b[1;32m    234\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    Override the default write method of `FastBasic` to\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    output masked values as empty fields.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write(table, output, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfill_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(core\u001b[38;5;241m.\u001b[39mmasked, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/astropy/io/ascii/fastbasic.py:214\u001b[0m, in \u001b[0;36mFastBasic._write\u001b[0;34m(self, table, output, default_kwargs, header_output, output_types)\u001b[0m\n\u001b[1;32m    212\u001b[0m write_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m    213\u001b[0m writer \u001b[38;5;241m=\u001b[39m cparser\u001b[38;5;241m.\u001b[39mFastWriter(table, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mwrite_kwargs)\n\u001b[0;32m--> 214\u001b[0m writer\u001b[38;5;241m.\u001b[39mwrite(output, header_output, output_types)\n",
      "File \u001b[0;32mastropy/io/ascii/cparser.pyx:1131\u001b[0m, in \u001b[0;36mastropy.io.ascii.cparser.FastWriter.write\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'set'"
     ]
    }
   ],
   "source": [
    "#FOR SOURCES COINCIDENT WITH XRAY\n",
    "exists =  display_data.loc[display_data['Exists?']== 'Yes!!']\n",
    "data_out = Table.from_pandas(exists)\n",
    "output_path = '../Data/Hugefiles/forced_phot_YES1.csv'\n",
    "\n",
    "# Write the table in csv format\n",
    "data_out.write(output_path, format='csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ALL SOURCES\n",
    "data_out = Table.from_pandas(display_data)\n",
    "output_path = '../Data/Hugefiles/forced_phot_ALL1.csv'\n",
    "\n",
    "# Write the table in csv format\n",
    "data_out.write(output_path, format='csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color-Color Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_id</th>\n",
       "      <th>Galaxy Name</th>\n",
       "      <th>ObsID</th>\n",
       "      <th>Region</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Annulus_Inner_Radius</th>\n",
       "      <th>Annulus_Outer_Radius</th>\n",
       "      <th>Net Flux (Jy)</th>\n",
       "      <th>...</th>\n",
       "      <th>Offset in Arcseconds</th>\n",
       "      <th>Exists?</th>\n",
       "      <th>Point Source Position</th>\n",
       "      <th>Target Error</th>\n",
       "      <th>Annulus Error</th>\n",
       "      <th>Overlap Error (in counts)</th>\n",
       "      <th>Wavelength</th>\n",
       "      <th>Flux Density</th>\n",
       "      <th>Flux Density Uncertainty</th>\n",
       "      <th>Overlap Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>NGC 4417</td>\n",
       "      <td>14902</td>\n",
       "      <td>1</td>\n",
       "      <td>399.211027</td>\n",
       "      <td>142.185253</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>...</td>\n",
       "      <td>[6.669909074600799]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(403.8203804675527, 143.69672141155763)]</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.024163</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[4.602750906555958e-12]</td>\n",
       "      <td>[9.289829223049668e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>NGC 4536</td>\n",
       "      <td>19387</td>\n",
       "      <td>2</td>\n",
       "      <td>377.933601</td>\n",
       "      <td>22.318875</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>...</td>\n",
       "      <td>[5.914647816374392]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(381.2870034012018, 25.012967011813853)]</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>0.024806</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[1.7799624099739449e-10]</td>\n",
       "      <td>[9.540295245460287e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>NGC 1792</td>\n",
       "      <td>19524</td>\n",
       "      <td>4</td>\n",
       "      <td>431.947871</td>\n",
       "      <td>47.526962</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.254757</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0431493707960338]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(432.296387958713, 48.20082533515143)]</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.010653</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[1.5790704150388123e-08]</td>\n",
       "      <td>[4.694169658872262e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>NGC 1792</td>\n",
       "      <td>19524</td>\n",
       "      <td>7</td>\n",
       "      <td>344.462348</td>\n",
       "      <td>312.508632</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.2616300941124432]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(345.0216890950249, 313.23597936091664)]</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.014052</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[5.972730460620459e-11]</td>\n",
       "      <td>[5.404537126044525e-10]</td>\n",
       "      <td>5502.641878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{W4}</td>\n",
       "      <td>NGC 1792</td>\n",
       "      <td>19524</td>\n",
       "      <td>9</td>\n",
       "      <td>338.764515</td>\n",
       "      <td>46.865411</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.2527023688413876]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(338.70743900678855, 45.956144481847126)]</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>[]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[3.776306168997739e-11]</td>\n",
       "      <td>[5.402535111305191e-10]</td>\n",
       "      <td>7123.742023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21373</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>MESSIER 096</td>\n",
       "      <td>23599</td>\n",
       "      <td>22</td>\n",
       "      <td>259.283826</td>\n",
       "      <td>427.139424</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.192847</td>\n",
       "      <td>...</td>\n",
       "      <td>[5.966407769597616]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(263.4689866040141, 428.2853461744851)]</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[4.01764186659453e-08]</td>\n",
       "      <td>[2.912667022632127e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21409</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>MESSIER 096</td>\n",
       "      <td>23599</td>\n",
       "      <td>58</td>\n",
       "      <td>93.474434</td>\n",
       "      <td>116.876602</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>...</td>\n",
       "      <td>[11.219025052362074, 5.618820515334173]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(101.19187245255404, 114.22798401196933), (95...</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[9.394281499923438e-11]</td>\n",
       "      <td>[3.0329534136724316e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>MESSIER 096</td>\n",
       "      <td>23599</td>\n",
       "      <td>61</td>\n",
       "      <td>66.622607</td>\n",
       "      <td>8.753096</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.194528</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.6155077650535793, 7.207263984672402, 11.518...</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(67.01760196936023, 8.542472679562124), (61.5...</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[4.052669180348156e-08]</td>\n",
       "      <td>[2.91322339024501e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>MESSIER 096</td>\n",
       "      <td>23599</td>\n",
       "      <td>65</td>\n",
       "      <td>17.149295</td>\n",
       "      <td>1.474268</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.102984</td>\n",
       "      <td>...</td>\n",
       "      <td>[4.794856747635324, 9.570579403090477]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(20.56065048127327, 2.197453616296342), (10.4...</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[2.1455016461625562e-08]</td>\n",
       "      <td>[2.3435204839489227e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21418</th>\n",
       "      <td>{W3}</td>\n",
       "      <td>MESSIER 096</td>\n",
       "      <td>23599</td>\n",
       "      <td>67</td>\n",
       "      <td>9.814150</td>\n",
       "      <td>297.233578</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0.183058</td>\n",
       "      <td>...</td>\n",
       "      <td>[8.82727976208917, 1.0141068446473493]</td>\n",
       "      <td>Yes!!</td>\n",
       "      <td>[(16.184181567006082, 296.4354274508852), (10....</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>[]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[3.813712960231857e-08]</td>\n",
       "      <td>[2.920694595569872e-10]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9414 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      band_id  Galaxy Name  ObsID  Region           X           Y  Radius  \\\n",
       "0        {W4}     NGC 4417  14902       1  399.211027  142.185253       9   \n",
       "1        {W4}     NGC 4536  19387       2  377.933601   22.318875       9   \n",
       "3        {W4}     NGC 1792  19524       4  431.947871   47.526962       9   \n",
       "6        {W4}     NGC 1792  19524       7  344.462348  312.508632       9   \n",
       "8        {W4}     NGC 1792  19524       9  338.764515   46.865411       9   \n",
       "...       ...          ...    ...     ...         ...         ...     ...   \n",
       "21373    {W3}  MESSIER 096  23599      22  259.283826  427.139424       9   \n",
       "21409    {W3}  MESSIER 096  23599      58   93.474434  116.876602       9   \n",
       "21412    {W3}  MESSIER 096  23599      61   66.622607    8.753096       9   \n",
       "21416    {W3}  MESSIER 096  23599      65   17.149295    1.474268       9   \n",
       "21418    {W3}  MESSIER 096  23599      67    9.814150  297.233578       9   \n",
       "\n",
       "       Annulus_Inner_Radius  Annulus_Outer_Radius  Net Flux (Jy)  ...  \\\n",
       "0                        16                    23       0.000074  ...   \n",
       "1                        16                    23       0.002872  ...   \n",
       "3                        16                    23       0.254757  ...   \n",
       "6                        16                    23       0.000964  ...   \n",
       "8                        16                    23       0.000609  ...   \n",
       "...                     ...                   ...            ...  ...   \n",
       "21373                    16                    23       0.192847  ...   \n",
       "21409                    16                    23       0.000451  ...   \n",
       "21412                    16                    23       0.194528  ...   \n",
       "21416                    16                    23       0.102984  ...   \n",
       "21418                    16                    23       0.183058  ...   \n",
       "\n",
       "                                    Offset in Arcseconds Exists?  \\\n",
       "0                                    [6.669909074600799]   Yes!!   \n",
       "1                                    [5.914647816374392]   Yes!!   \n",
       "3                                   [1.0431493707960338]   Yes!!   \n",
       "6                                   [1.2616300941124432]   Yes!!   \n",
       "8                                   [1.2527023688413876]   Yes!!   \n",
       "...                                                  ...     ...   \n",
       "21373                                [5.966407769597616]   Yes!!   \n",
       "21409            [11.219025052362074, 5.618820515334173]   Yes!!   \n",
       "21412  [0.6155077650535793, 7.207263984672402, 11.518...   Yes!!   \n",
       "21416             [4.794856747635324, 9.570579403090477]   Yes!!   \n",
       "21418             [8.82727976208917, 1.0141068446473493]   Yes!!   \n",
       "\n",
       "                                   Point Source Position  Target Error  \\\n",
       "0              [(403.8203804675527, 143.69672141155763)]      0.013162   \n",
       "1              [(381.2870034012018, 25.012967011813853)]      0.013518   \n",
       "3                [(432.296387958713, 48.20082533515143)]      0.006882   \n",
       "6              [(345.0216890950249, 313.23597936091664)]      0.007658   \n",
       "8             [(338.70743900678855, 45.956144481847126)]      0.007655   \n",
       "...                                                  ...           ...   \n",
       "21373           [(263.4689866040141, 428.2853461744851)]      0.001279   \n",
       "21409  [(101.19187245255404, 114.22798401196933), (95...      0.001279   \n",
       "21412  [(67.01760196936023, 8.542472679562124), (61.5...      0.001279   \n",
       "21416  [(20.56065048127327, 2.197453616296342), (10.4...      0.001022   \n",
       "21418  [(16.184181567006082, 296.4354274508852), (10....      0.001279   \n",
       "\n",
       "       Annulus Error  Overlap Error (in counts) Wavelength  \\\n",
       "0           0.024163                         []       22.0   \n",
       "1           0.024806                         []       22.0   \n",
       "3           0.010653                         []       22.0   \n",
       "6           0.014052                         []       22.0   \n",
       "8           0.014049                         []       22.0   \n",
       "...              ...                        ...        ...   \n",
       "21373       0.001906                         []       12.0   \n",
       "21409       0.002346                         []       12.0   \n",
       "21412       0.001903                         []       12.0   \n",
       "21416       0.001586                         []       12.0   \n",
       "21418       0.001932                         []       12.0   \n",
       "\n",
       "                   Flux Density  Flux Density Uncertainty  Overlap Counts  \n",
       "0       [4.602750906555958e-12]   [9.289829223049668e-10]             NaN  \n",
       "1      [1.7799624099739449e-10]   [9.540295245460287e-10]             NaN  \n",
       "3      [1.5790704150388123e-08]   [4.694169658872262e-10]             NaN  \n",
       "6       [5.972730460620459e-11]   [5.404537126044525e-10]     5502.641878  \n",
       "8       [3.776306168997739e-11]   [5.402535111305191e-10]     7123.742023  \n",
       "...                         ...                       ...             ...  \n",
       "21373    [4.01764186659453e-08]   [2.912667022632127e-10]             NaN  \n",
       "21409   [9.394281499923438e-11]  [3.0329534136724316e-10]             NaN  \n",
       "21412   [4.052669180348156e-08]    [2.91322339024501e-10]             NaN  \n",
       "21416  [2.1455016461625562e-08]  [2.3435204839489227e-10]             NaN  \n",
       "21418   [3.813712960231857e-08]   [2.920694595569872e-10]             NaN  \n",
       "\n",
       "[9414 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W4\n",
      "W3\n",
      "W1\n",
      "W2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/77pj43rx7wbcbp0wx2qjq2140000gp/T/ipykernel_75616/2757696900.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exists['band_id'] = exists['band_id'].apply(lambda x: list(x)[0] if isinstance(x, set) else x)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2672,) (2766,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 27\u001b[0m\n\u001b[1;32m     16\u001b[0m fluxw3 \u001b[38;5;241m=\u001b[39m flux_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m fluxw4 \u001b[38;5;241m=\u001b[39m flux_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 27\u001b[0m color_1_2 \u001b[38;5;241m=\u001b[39m (fluxw1 \u001b[38;5;241m-\u001b[39m fluxw2) \u001b[38;5;241m/\u001b[39m (fluxw1 \u001b[38;5;241m+\u001b[39mfluxw2)\n\u001b[1;32m     28\u001b[0m color_1_3 \u001b[38;5;241m=\u001b[39m(fluxw1 \u001b[38;5;241m-\u001b[39m fluxw3) \u001b[38;5;241m/\u001b[39m (fluxw1 \u001b[38;5;241m+\u001b[39mfluxw3)\n\u001b[1;32m     29\u001b[0m color_1_4 \u001b[38;5;241m=\u001b[39m(fluxw1 \u001b[38;5;241m-\u001b[39m fluxw4) \u001b[38;5;241m/\u001b[39m (fluxw1 \u001b[38;5;241m+\u001b[39mfluxw4)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2672,) (2766,) "
     ]
    }
   ],
   "source": [
    "#exists = pd.read_csv('../Data/Hugefiles/forced_phot_YES.csv')\n",
    "exists =  display_data.loc[display_data['Exists?']== 'Yes!!']\n",
    "display(exists)\n",
    "# Convert the set values in 'band_id' to strings\n",
    "exists['band_id'] = exists['band_id'].apply(lambda x: list(x)[0] if isinstance(x, set) else x)\n",
    "\n",
    "flux_dict = {}\n",
    "\n",
    "for band in exists['band_id'].unique():\n",
    "    flux_dict[band] = exists[exists['band_id'] == band]['Net Flux (Jy)'].values\n",
    "    print(band)\n",
    "\n",
    "# Now you can access the fluxes for any band, for example:\n",
    "fluxw1 = flux_dict['W1']\n",
    "fluxw2 = flux_dict['W2']\n",
    "fluxw3 = flux_dict['W3']\n",
    "fluxw4 = flux_dict['W4']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "color_1_2 = (fluxw1 - fluxw2) / (fluxw1 +fluxw2)\n",
    "color_1_3 =(fluxw1 - fluxw3) / (fluxw1 +fluxw3)\n",
    "color_1_4 =(fluxw1 - fluxw4) / (fluxw1 +fluxw4)\n",
    "color_2_3 =(fluxw2 - fluxw3) / (fluxw2 +fluxw3)\n",
    "color_2_4 =(fluxw2 - fluxw4) / (fluxw2 +fluxw4)\n",
    "color_3_4 = (fluxw3 - fluxw4) / (fluxw3 +fluxw4)\n",
    "# should be 15 color pairs\n",
    "color_pairs = [(color_1_2, color_1_3), (color_1_2,color_1_4),(color_1_2, color_2_3), (color_1_2, color_2_4), (color_1_2, color_3_4), \n",
    "               (color_1_3, color_1_4), (color_1_3, color_2_3), (color_1_3, color_2_4), (color_1_3, color_3_4),\n",
    "                 (color_1_4, color_2_3), (color_1_4,color_2_4 ), (color_1_4, color_3_4),\n",
    "                 (color_2_3, color_2_4), (color_2_3, color_3_4),\n",
    "                  (color_2_4, color_3_4) ]\n",
    "\n",
    "\n",
    "for color_x, color_y in color_pairs:\n",
    "    plt.scatter(color_x, color_y, marker = 'o')\n",
    "    plt.xlabel(f'Color 1 ({color_x})')\n",
    "    plt.ylabel(f'Color 2 ({color_y})')\n",
    "    plt.title('Color-Color Diagram')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
