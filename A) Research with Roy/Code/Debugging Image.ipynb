{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvo as vo\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.io import fits\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "from photutils.utils import calc_total_error\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "import json\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from photutils.detection import DAOStarFinder\n",
    "from astropy.stats import mad_std, sigma_clipped_stats\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going to try debugging this one now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n",
    "#empty data frame to append values of flux to\n",
    "rows=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the image catalog in the WISE database\n",
    "#define coordinates\tmake it possible to run a list over this with all of the ra and decs\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "#print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n",
    "\n",
    "M0instr =  12.98 # found the relative instrumental zero point magnitude in this specific band (W4)\n",
    "flx_conv_fact =  8.363 # the Zero Magnitude Flux Density conversion factor in this band\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "#extract a cutout for plotting and KDTree\n",
    "wcs = WCS(image1[0].header)\n",
    "#cuting out the image of the galaxy apart from the rest of the background.\n",
    "cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "wcs = cutout.wcs\n",
    "\n",
    "#####   constants in every image:\n",
    "\n",
    "#plot the sources with circles\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# convert Ra and dec values to pixel coordinates\n",
    "positions = wcs.world_to_pixel_values(ra, dec)\n",
    "positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "#define the distance threshold for the KDTree grouping (in pixels)\n",
    "distance_threshold = 5\n",
    "\n",
    "#build the KDTree for efficient grouping\n",
    "tree = KDTree(positions)\n",
    "\n",
    "#query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "print(groups)\n",
    "# consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "unique_groups = []\n",
    "seen = set()\n",
    "for group in groups:\n",
    "    group = tuple(sorted(group))\n",
    "    if group not in seen:\n",
    "        seen.add(group)\n",
    "        unique_groups.append(group)\n",
    "print(unique_groups)\n",
    "# for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "#represents the consolidated postion of potentially multiple detections of one source.\n",
    "grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "print(grouped_positions)\n",
    "\n",
    "#define the Region(s) Of Interest (center x, center y, radius)\n",
    "ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "#empty data frame to append values of flux to\n",
    "rows=[]\n",
    "\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "#####  End of constants\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(image_data.shape[0], image_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(image_data.shape[0], image_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = image_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(image_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts<= 0: # \n",
    "                    target_flux # avoid taking the log of zero or negative value\n",
    "                else:\n",
    "                        #counts to flux\n",
    "                    Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                    target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                    #calculate area of annulus\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(image_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts <= 0:\n",
    "                    annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "                else:\n",
    "                    #counts to flux\n",
    "                    Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                    annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': image_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "            #filter only valid sources to conduct the overlapping photometry again. \n",
    "        # so that sources with an acceptable amount of overlap have their overlapping counts subtracted from the nonoverlapping counts.\n",
    "        #valid_sources = display_data[display_data['Flag'] == 'Valid']\n",
    "\n",
    "        for i, valid_row in display_data[display_data['Flag'] == 'Valid'].iterrows():\n",
    "            x, y, r = valid_row['X'], valid_row['Y'], valid_row['Radius']\n",
    "            target_aperture = CircularAperture((x, y), r)\n",
    "            target_photo_table = aperture_photometry(image_data, target_aperture)\n",
    "            target_counts = target_photo_table['aperture_sum'][0]\n",
    "            \n",
    "            if target_counts <= 0:\n",
    "                target_flux = 0\n",
    "            else:\n",
    "                Mcal_trgt = M0instr - 2.5 * (np.log10(target_counts))\n",
    "                target_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5)\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "            non_overlapping_counts = target_counts\n",
    "\n",
    "            for j, valid_row2 in display_data[display_data['Flag'] == 'Valid'].iterrows():\n",
    "                if i != j:\n",
    "                    x2, y2, r2 = valid_row2['X'], valid_row2['Y'], valid_row2['Radius']\n",
    "                    distance = dist((x, y), (x2, y2))\n",
    "                    if distance < r + r2:\n",
    "                        overlap_percent = (r + r2 - distance) / (r + r2)\n",
    "                        if overlap_percent > .01: # i think i will have to fiddle around with this\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(image_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0]\n",
    "                            #Subtract overlapping data from non overlapping and assign the data to the variable of non_overlapping_counts\n",
    "                            non_overlapping_counts -= overlap_counts\n",
    "                            \n",
    "\n",
    "            if non_overlapping_counts <= 0: # if counts are 0 or negative, dont do flux conversion cuz it wont work. assigns the flux to be zero\n",
    "                net_flux = 0\n",
    "            else:\n",
    "                Mcal_trgt = M0instr - 2.5 * (np.log10(non_overlapping_counts))\n",
    "                net_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5) - tot_bg\n",
    "\n",
    "            # for each location of the overlapping source in the pandas dataframe table, assign whether it is still valid or not.\n",
    "            display_data.loc[i, 'Net Flux (Jy)'] = net_flux\n",
    "            display_data.loc[i, 'Flag'] = 'Valid' if net_flux > 0 else 'Low Flux'\n",
    "\n",
    "     \n",
    "        \n",
    "     ## Trying to plot the images now\n",
    "     #extract a cutout and plot it\n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (400,400), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "    \n",
    "        #plotting the image\n",
    "        fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in display_data.itertuples():\n",
    "            if row.Flag == 'Valid':\n",
    "                target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "                annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "                target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "                annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "        ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#rows.append({'band_id': {band_labels[band_id]},\n",
    "    \n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "#visualizing the apertures\n",
    "\n",
    "#for row in display_data.itertuples():\n",
    "    #if row.Flag == 'Valid':\n",
    "       # target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "       # annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "       # target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "       # annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "\n",
    "####if you want to see all of them use the code below:\n",
    "#for ((x, y), r, annulus_inner, annulus_outer) in ROI:\n",
    "    #target_apertureplt = CircularAperture((x,y),r)\n",
    "   # annulus_apertureplt = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "   # target_apertureplt.plot(color='red', lw = 1.5)\n",
    "   # annulus_apertureplt.plot(color='red', lw = 1.5)\n",
    "plt.xlabel('RA')\n",
    "plt.ylabel('Dec')\n",
    "plt.grid(color='white', ls='dotted')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just one band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "#for i in range(len(im_table)):\n",
    "   # print(im_table[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(im_table)):\n",
    "    if im_table[i]['sia_bp_id']:\n",
    "\n",
    "        print(im_table[i].getdataurl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = im_table[0].getdataurl()\n",
    "#Download the image and open it in Astropy\n",
    "fname = download_file(data_url, cache=True)\n",
    "image1= fits.open(fname)\n",
    "image_data= image1[0].data\n",
    "print(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "sources_7793\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "hdr = image1[0].header\n",
    "hdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract a cutout for plotting and KDTree\n",
    "wcs = WCS(image1[0].header)\n",
    "#cuting out the image of the galaxy apart from the rest of the background.\n",
    "cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "print(image_data.shape)\n",
    "print(cutout.data.shape)\n",
    "# THIS IS WHERE THE DISCREPANCY IS HAPPENING.\n",
    "# When i make the image shape the same, the positions of the sources are almost identical to the \n",
    "# image downloaded code.\n",
    "wcs = cutout.wcs\n",
    "cutout_data = cutout.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the KDTree\n",
    "# convert Ra and dec values to pixel coordinates\n",
    "positions = wcs.world_to_pixel_values(ra, dec)\n",
    "positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "#define the distance threshold for the KDTree grouping (in pixels)\n",
    "distance_threshold = 10\n",
    "\n",
    "#build the KDTree for efficient grouping\n",
    "tree = KDTree(positions)\n",
    "\n",
    "#query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "print(groups)\n",
    "# consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "unique_groups = []\n",
    "seen = set()\n",
    "for group in groups:\n",
    "    group = tuple(sorted(group))\n",
    "    if group not in seen:\n",
    "        seen.add(group)\n",
    "        unique_groups.append(group)\n",
    "print(unique_groups)\n",
    "# for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "#represents the consolidated postion of potentially multiple detections of one source.\n",
    "grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "print(grouped_positions)\n",
    "# a problem could be with grouped postions maybe?\n",
    "# here is where the code between downloading the image and using the URL differs!\n",
    "#  the position of sources is slightly altered for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define the Region(s) Of Interest (center x, center y, radius)\n",
    "ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "#empty data frame to append values of flux to\n",
    "rows=[]\n",
    "\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n",
    "\n",
    "M0instr =  12.98 # found the relative instrumental zero point magnitude in this specific band (W4)\n",
    "flx_conv_fact =  8.363 # the Zero Magnitude Flux Density conversion factor in this band\n",
    "cutout_data.shape\n",
    "grouped_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check for overlap and perform aperture photometry\n",
    "for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "    overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "    non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "    for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "        if i != j: # ensures that a source is not compared to itself! wow\n",
    "            distance = dist((x, y) , (x2, y2)) \n",
    "            if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                if overlap_percent > .5:\n",
    "                    overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                    break\n",
    "                else: \n",
    "                    overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                    non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                    # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                    # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                \n",
    "    if overlap:\n",
    "        #flag the sources that overlap\n",
    "        rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                      'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "    else: #perform all the aperture photometry stuff\n",
    "        # For the Target objects in the little aperture circle define their target apertures\n",
    "        target_aperture = CircularAperture((x,y),r,)\n",
    "    \n",
    "        #perform aperture photometry on target\n",
    "        # also now apply the masked data\n",
    "        masked_data = cutout_data * non_overlapping_mask\n",
    "        target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "        target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "        if target_counts<= 0: # \n",
    "            target_flux # avoid taking the log of zero or negative value\n",
    "        else:\n",
    "                #counts to flux\n",
    "            Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "            target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "            #calculate area of annulus\n",
    "        target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "        # For the Background Annuli of outside of the Target\n",
    "        #define the background annulus for the target\n",
    "        annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "        #perform aperture photometry on annuli\n",
    "        annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "        annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "    \n",
    "        if annulus_counts <= 0:\n",
    "            annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "        else:\n",
    "            #counts to flux\n",
    "            Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "            annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "        #calculate area of annulus\n",
    "        annulus_area = annulus_aperture.area\n",
    "\n",
    "        # do the calculations for including a Background aperture\n",
    "    \n",
    "        #Calculating the net flux:\n",
    "        #calculate the mean background per pixel\n",
    "        bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "        #calculate the total background in the target aperture\n",
    "        tot_bg = bg_perpixel * target_area\n",
    "\n",
    "        #Subtract background from the target flux\n",
    "        net_flx = target_flux - tot_bg\n",
    "    \n",
    "        #   Append the result as a dictionary to the list named 'rows'\n",
    "        rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                 'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                   'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                     'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                       'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "    \n",
    "\n",
    "#append the rows to the empty dataframe    \n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#visualizing the apertures that are postive and dont overlap to a detrimental degree. if you want to see all of them take out the (== 'Valid') part of the viz code\n",
    "fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "for row in display_data.itertuples():\n",
    "    if row.Flag == 'Valid':\n",
    "        target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "        annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "        target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "        annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "ax.set_xlabel('Right Ascension')\n",
    "ax.set_ylabel('Declination')\n",
    "#plt.title(f'Band {band_labels[band_id]}')\n",
    "plt.show()\n",
    "\n",
    "display_data.loc[display_data['Flag']== 'Valid']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dont think i need this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#filter only valid sources to conduct the overlapping photometry again. \n",
    "# so that sources with an acceptable amount of overlap have their overlapping counts subtracted from the nonoverlapping counts.\n",
    "valid_sources = display_data[display_data['Flag'] == 'Valid']\n",
    "\n",
    "for i, valid_row in valid_sources.iterrows():\n",
    "    x, y, r = valid_row['X'], valid_row['Y'], valid_row['Radius']\n",
    "    target_aperture = CircularAperture((x, y), r)\n",
    "    target_photo_table = aperture_photometry(cutout_data, target_aperture)\n",
    "    target_counts = target_photo_table['aperture_sum'][0]\n",
    "    \n",
    "    if target_counts <= 0:\n",
    "        target_flux = 0\n",
    "    else:\n",
    "        Mcal_trgt = M0instr - 2.5 * (np.log10(target_counts))\n",
    "        target_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5)\n",
    "        target_area = target_aperture.area\n",
    "\n",
    "    non_overlapping_counts = target_counts\n",
    "\n",
    "    for j, valid_row2 in valid_sources.iterrows():\n",
    "        if i != j:\n",
    "            x2, y2, r2 = valid_row2['X'], valid_row2['Y'], valid_row2['Radius']\n",
    "            distance = dist((x, y), (x2, y2))\n",
    "            if distance < r + r2:\n",
    "                overlap_percent = (r + r2 - distance) / (r + r2)\n",
    "                if overlap_percent > .01: # i think i will have to fiddle around with this\n",
    "                    overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                    overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                    overlap_counts = overlap_photo_table['aperture_sum'][0]\n",
    "                    #Subtract overlapping data from non overlapping and assign the data to the variable of non_overlapping_counts\n",
    "                    non_overlapping_counts -= overlap_counts\n",
    "                    \n",
    "\n",
    "    if non_overlapping_counts <= 0: # if counts are 0 or negative, dont do flux conversion cuz it wont work. assigns the flux to be zero\n",
    "        net_flux = 0\n",
    "    else:\n",
    "        Mcal_trgt = M0instr - 2.5 * (np.log10(non_overlapping_counts))\n",
    "        net_flux = flx_conv_fact * 10**(Mcal_trgt / -2.5) - tot_bg\n",
    "\n",
    "    # for each location of the overlapping source in the pandas dataframe table, assign whether it is still valid or not.\n",
    "    display_data.loc[i, 'Net Flux (Jy)'] = net_flux\n",
    "    display_data.loc[i, 'Flag'] = 'Valid' if net_flux > 0 else 'Low Flux'\n",
    "\n",
    "\n",
    "#visualizing the apertures that are postive and dont overlap to a detrimental degree. if you want to see all of them take out the (== 'Valid') part of the viz code\n",
    "fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "for row in display_data.itertuples():\n",
    "    if row.Flag == 'Valid':\n",
    "        target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "        annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "        target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "        annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "ax.set_xlabel('Right Ascension')\n",
    "ax.set_ylabel('Declination')\n",
    "#plt.title(f'Band {band_labels[band_id]}')\n",
    "plt.show()\n",
    "\n",
    "display_data.loc[display_data['Flag']== 'Valid']\n",
    "#display_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the new code for when i want to apply it to all wavelengths :\n",
    "\n",
    "remember to include the code for different flux conversions for each band!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE THIS WHEN YOU HAVE PUT IN THE CONVERSION Code\n",
    "M0instr =  12.98 # found the relative instrumental zero point magnitude in this specific band (W4)\n",
    "flx_conv_fact =  8.363 # the Zero Magnitude Flux Density conversion factor in this band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dont use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_alldata = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "       # print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data # maybe this needs to be assigned as a dictionary for each of them.\n",
    "        cutout_alldata.append({ 'Band': {band_labels[band_id]}, 'CutoutData' : cutout_data, 'WCS': wcs})\n",
    "cutout_alldata = pd.DataFrame(cutout_alldata)\n",
    "cutout_alldata['ROI'] = np.nan\n",
    "display(cutout_alldata)\n",
    "\n",
    "#cutout_alldata = pd.DataFrame(columns=['Band', 'CutoutData', 'WCS'])  # Initialize with columns\n",
    "#for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "  #  band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "   # if band_id in band_labels:\n",
    "   #    # print(f'Band {band_labels[band_id]}: ')\n",
    "    #    data_url = im_table[i].getdataurl()\n",
    "   #     #Download the image and open it in Astropy\n",
    "   #     fname = download_file(data_url, cache=True)\n",
    "   #     image1= fits.open(fname)\n",
    "    #    image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "     #   wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "     #   cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "      #  wcs = cutout.wcs\n",
    "      #  cutout_data = cutout.data # maybe this needs to be assigned as a dictionary for each of them.\n",
    "      #  cutout_alldata.loc[len(cutout_alldata)] = [band_id, cutout_data, wcs]\n",
    "        #cutout_alldata._append({ 'Band': {band_labels[band_id]}, 'CutoutData' : cutout_data, 'WCS': wcs}, ignore_index= True)\n",
    "\n",
    "display(cutout_alldata)\n",
    "\n",
    "for idx, row in cutout_alldata.iterrows():\n",
    "    wcs = row.WCS\n",
    "    positions = wcs.world_to_pixel_values(ra, dec)\n",
    "    positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "    #define the distance threshold for the KDTree grouping (in pixels)\n",
    "    distance_threshold = 11\n",
    "\n",
    "    #build the KDTree for efficient grouping\n",
    "    tree = KDTree(positions)\n",
    "\n",
    "    #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "    groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "    print(groups)\n",
    "    # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "    unique_groups = []\n",
    "    seen = set()\n",
    "    for group in groups:\n",
    "        group = tuple(sorted(group))\n",
    "        if group not in seen:\n",
    "            seen.add(group)\n",
    "            unique_groups.append(group)\n",
    "    print(unique_groups)\n",
    "    # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "    #represents the consolidated postion of potentially multiple detections of one source.\n",
    "    grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "    print(grouped_positions)\n",
    "\n",
    "    #define the Region(s) Of Interest (center x, center y, radius)\n",
    "    ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "    #empty data frame to append values of flux to\n",
    "    roi_str = json.dumps(ROI) # to revert back : roi_list = json.loads(cutout_alldata.at[idx, 'ROI'])\n",
    "    cutout_alldata.at[idx, 'ROI'] = roi_str\n",
    "display(cutout_alldata)\n",
    "\n",
    "for idx, row in cutout_alldata.iterrows(): \n",
    "    roi_list = json.loads(row['ROI'])\n",
    "    band_id = row['Band']\n",
    "    cutout_data = row['CutoutData']\n",
    "    #now inputting the aperture photometry part\n",
    "    # check for overlap and perform aperture photometry\n",
    "    for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(roi_list):\n",
    "        overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "        non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "        for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(roi_list): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "            if i != j: # ensures that a source is not compared to itself! wow\n",
    "                distance = dist((x, y) , (x2, y2)) \n",
    "                if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                    overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                    if overlap_percent > .5:\n",
    "                        overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                        break\n",
    "                    else: \n",
    "                        overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                        non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                        # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                        # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                    \n",
    "        if overlap:\n",
    "            #flag the sources that overlap\n",
    "            rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "        else: #perform all the aperture photometry stuff\n",
    "            # For the Target objects in the little aperture circle define their target apertures\n",
    "            target_aperture = CircularAperture((x,y),r,)\n",
    "        \n",
    "            #perform aperture photometry on target\n",
    "            # also now apply the masked data\n",
    "            masked_data = cutout_data * non_overlapping_mask\n",
    "            target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "            target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "            if target_counts<= 0: # \n",
    "                target_flux # avoid taking the log of zero or negative value\n",
    "            else:\n",
    "                    #counts to flux\n",
    "                Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                #calculate area of annulus\n",
    "            target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "            # For the Background Annuli of outside of the Target\n",
    "            #define the background annulus for the target\n",
    "            annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "            #perform aperture photometry on annuli\n",
    "            annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "            annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "        \n",
    "            if annulus_counts <= 0:\n",
    "                annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "            else:\n",
    "                #counts to flux\n",
    "                Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "            #calculate area of annulus\n",
    "            annulus_area = annulus_aperture.area\n",
    "\n",
    "            # do the calculations for including a Background aperture\n",
    "        \n",
    "            #Calculating the net flux:\n",
    "            #calculate the mean background per pixel\n",
    "            bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "            #calculate the total background in the target aperture\n",
    "            tot_bg = bg_perpixel * target_area\n",
    "\n",
    "            #Subtract background from the target flux\n",
    "            net_flx = target_flux - tot_bg\n",
    "        \n",
    "            #   Append the result as a dictionary to the list named 'rows'\n",
    "            rows.append({ 'band_id': band_id,'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                    'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                    'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                        'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                        'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "        #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "    \n",
    "display_data = pd.DataFrame(rows)\n",
    "display(display_data)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "for row in display_data.itertuples():\n",
    "    if row.Flag == 'Valid':\n",
    "        target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "        annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "        target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "        annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "ax.set_xlabel('Right Ascension')\n",
    "ax.set_ylabel('Declination')\n",
    "#plt.title(f'Band {band_labels[band_id]}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        print(data_url)\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cutting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 10\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "        print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "        print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        #empty data frame to append values of flux to\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts<= 0: # \n",
    "                    target_flux # avoid taking the log of zero or negative value\n",
    "                else:\n",
    "                        #counts to flux\n",
    "                    Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                    target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                    #calculate area of annulus\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts <= 0:\n",
    "                    annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "                else:\n",
    "                    #counts to flux\n",
    "                    Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                    annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "     \n",
    "    \n",
    "     ## Trying to plot the images now\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in display_data.itertuples():\n",
    "            if row.Flag == 'Valid':\n",
    "                target_aperture = CircularAperture((row.X, row.Y), row.Radius)\n",
    "                annulus_aperture = CircularAnnulus((row.X, row.Y), row.Annulus_Inner_Radius, row.Annulus_Outer_Radius)\n",
    "                target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "                annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "        ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(display_data)\n",
    "#display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best versions of the code so far\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## good but has too many duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "        print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "        print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts<= 0: # \n",
    "                    target_flux # avoid taking the log of zero or negative value\n",
    "                else:\n",
    "                        #counts to flux\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                    Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                    target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                    #calculate area of annulus\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts <= 0:\n",
    "                    annulus_flux = 0  # Avoid taking log of zero or negative value\n",
    "                else:\n",
    "                    #counts to flux\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                    Mcal_annul = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                    annulus_flux = flx_conv_fact * 10**(Mcal_annul/-2.5)      #convert Magnitude to Flux\n",
    "\n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "     \n",
    "    \n",
    "     ## Trying to plot the images now\n",
    "        fig, ax = plt.subplots(subplot_kw = {'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in rows:\n",
    "            if row['Flag'] == 'Valid':\n",
    "                target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "                annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "                target_aperture.plot(color = 'red', lw = 1.5, alpha = .5)\n",
    "                annulus_aperture.plot(color = 'blue', lw = 1.5, alpha = .5)\n",
    "        ax.imshow(cutout.data, cmap= 'gray', norm=norm)\n",
    "\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd best version of code\n",
    "fixed duplicates, does not yet have overlap subtraction in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "        print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "        print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "                        \n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        target_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "\n",
    "                    \n",
    "                    #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                })\n",
    "                \n",
    "            # Append valid_rows to rows (if needed for overall storage)\n",
    "            #rows.extend(valid_rows)\n",
    "        print('valid rows', valid_rows)\n",
    "\n",
    "    # Plotting for current image\n",
    "    # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']),\n",
    "                                            row['Annulus_Inner_Radius'],\n",
    "                                            row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm)\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST VERSION OF THE CODE\n",
    "put the overlapping SUBTRACTION code into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6,'w4':12.98 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "\n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            break\n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0]\n",
    "                            target_counts -= overlap_counts\n",
    "\n",
    "\n",
    "            if overlap:\n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner,\n",
    "                            'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': np.nan, 'Flag': 'Overlap' }) \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                # also now apply the masked data\n",
    "                masked_data = cutout_data * non_overlapping_mask\n",
    "                target_photo_table = aperture_photometry(cutout_data, target_aperture) #replace image_data with \"masked_data\" to incorporate the code for overlapping\n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        target_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "\n",
    "                    \n",
    "                    #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask)})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flag':'Valid' if net_flx > 0 else 'Low Flux',\n",
    "                })\n",
    "                \n",
    "            # Append valid_rows to rows (if needed for overall storage)\n",
    "            #rows.extend(valid_rows)\n",
    "        #print('valid rows', valid_rows)\n",
    "\n",
    "    # Plotting for current image\n",
    "    # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']),\n",
    "                                            row['Annulus_Inner_Radius'],\n",
    "                                            row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm)\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "pd.set_option(\"display.max_rows\", 30)\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including source detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SkyCoord (ICRS): (ra, dec) in deg\n",
      "    (359.457, -32.592)>\n",
      "('W4 Coadd 0000m334_ac51', 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w4-int-3.fits', '{\"aws\": {\"bucket_name\": \"nasa-irsa-wise\", \"key\":\"wise/allwise/images/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w4-int-3.fits\", \"region\": \"us-west-2\"}}', 2, 'image/fits', 0.0, -33.317778, array([4095, 4095], dtype=int32), array([2048., 2048.]), array([  0.      , -33.317778]), 'SIN', array([-0.00038194,  0.00038194]), array([-0.00038194, -0.        , -0.        ,  0.00038194]), 'W4', 2.209e-05, 2.336e-05, 1.984e-05, 'm', 13.0, 0.012, 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w4-unc-3.fits.gz', 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w4-cov-3.fits.gz', '0000m334_ac51')\n",
      "('W1 Coadd 0000m334_ac51', 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w1-int-3.fits', '{\"aws\": {\"bucket_name\": \"nasa-irsa-wise\", \"key\":\"wise/allwise/images/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w1-int-3.fits\", \"region\": \"us-west-2\"}}', 2, 'image/fits', 0.0, -33.317778, array([4095, 4095], dtype=int32), array([2048., 2048.]), array([  0.      , -33.317778]), 'SIN', array([-0.00038194,  0.00038194]), array([-0.00038194, -0.        , -0.        ,  0.00038194]), 'W1', 3.35e-06, 3.78e-06, 3.13e-06, 'm', 20.5, 0.006, 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w1-unc-3.fits.gz', 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w1-cov-3.fits.gz', '0000m334_ac51')\n",
      "('W2 Coadd 0000m334_ac51', 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w2-int-3.fits', '{\"aws\": {\"bucket_name\": \"nasa-irsa-wise\", \"key\":\"wise/allwise/images/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w2-int-3.fits\", \"region\": \"us-west-2\"}}', 2, 'image/fits', 0.0, -33.317778, array([4095, 4095], dtype=int32), array([2048., 2048.]), array([  0.      , -33.317778]), 'SIN', array([-0.00038194,  0.00038194]), array([-0.00038194, -0.        , -0.        ,  0.00038194]), 'W2', 4.6e-06, 5.19e-06, 4.02e-06, 'm', 19.5, 0.007, 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w2-unc-3.fits.gz', 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w2-cov-3.fits.gz', '0000m334_ac51')\n",
      "('W3 Coadd 0000m334_ac51', 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w3-int-3.fits', '{\"aws\": {\"bucket_name\": \"nasa-irsa-wise\", \"key\":\"wise/allwise/images/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w3-int-3.fits\", \"region\": \"us-west-2\"}}', 2, 'image/fits', 0.0, -33.317778, array([4095, 4095], dtype=int32), array([2048., 2048.]), array([  0.      , -33.317778]), 'SIN', array([-0.00038194,  0.00038194]), array([-0.00038194, -0.        , -0.        ,  0.00038194]), 'W3', 1.156e-05, 1.627e-05, 7.6e-06, 'm', 18.0, 0.012, 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w3-unc-3.fits.gz', 'https://irsa.ipac.caltech.edu/ibe/data/wise/allwise/p3am_cdd/00/0000/0000m334_ac51/0000m334_ac51-w3-cov-3.fits.gz', '0000m334_ac51')\n",
      "       ra_x   dec_x               source_id  cntr_01    dist_x      pang_x  \\\n",
      "0   201.365 -43.019                NGC 5128      1.0  0.830776  162.673944   \n",
      "1   184.741  47.303             MESSIER 106      3.0  5.022737  -43.454463   \n",
      "2   202.468  47.198             MESSIER 051      4.0  6.295556  -65.412743   \n",
      "3   148.963  69.679             MESSIER 082      5.0  4.934001   60.594118   \n",
      "4    67.704  64.848                NGC 1569      6.0  8.361842  -51.691199   \n",
      "5    11.888 -25.288                NGC 0253      8.0  0.993958  158.563643   \n",
      "6    35.639  42.349                NGC 0891     10.0  3.895011 -134.133495   \n",
      "7    49.328 -41.106  NGC 1291:[LFF2012] 084     11.0  7.368795 -164.984930   \n",
      "8   190.530  32.542                NGC 4631     12.0  9.053783   69.702218   \n",
      "9   192.721  41.120             MESSIER 094     13.0  1.409980   58.249431   \n",
      "10  196.365 -49.468                NGC 4945     14.0  1.444546  -95.506067   \n",
      "11  172.005  78.993               UGC 06456     16.0  3.261849 -157.154801   \n",
      "12  267.365  70.145                NGC 6503     17.0  5.957336 -101.168740   \n",
      "13  186.454  33.547                NGC 4395     18.0  1.088464 -108.113185   \n",
      "14  184.375  37.809                NGC 4244     20.0  8.423295 -132.064124   \n",
      "15  181.763  43.065                NGC 4111     21.0  2.534106    1.427312   \n",
      "16  187.630  41.650                NGC 4485     22.0  4.796021   37.282045   \n",
      "17  161.958  12.582             MESSIER 105     24.0  4.829860 -107.390842   \n",
      "18  114.216  65.600                NGC 2403     25.0  5.837017  145.062619   \n",
      "19  167.880  55.674             MESSIER 108     26.0  1.511374  -39.873393   \n",
      "\n",
      "      ra_01  dec_01          designation        ra_y      dec_y   sigra  \\\n",
      "0   201.365 -43.019  J132527.62-430109.1  201.365094 -43.019220  0.0263   \n",
      "1   184.741  47.303  J121857.50+471814.4  184.739585  47.304013  0.0301   \n",
      "2   202.468  47.198  J132951.75+471155.4  202.465660  47.198728  0.0304   \n",
      "3   148.963  69.679  J095551.94+694046.8  148.966438  69.679673  0.0014   \n",
      "4    67.704  64.848  J043047.93+645057.9   67.699712  64.849440  0.0427   \n",
      "5    11.888 -25.288  J004733.14-251717.7   11.888112 -25.288257  0.0049   \n",
      "6    35.639  42.349  J022233.10+422053.6   35.637949  42.348247  0.0296   \n",
      "7    49.328 -41.106  J031718.55-410628.7   49.327296 -41.107977  0.0294   \n",
      "8   190.530  32.542  J124207.87+323234.3  190.532798  32.542872  0.0283   \n",
      "9   192.721  41.120  J125053.14+410712.7  192.721442  41.120206  0.0264   \n",
      "10  196.365 -49.468  J130527.45-492804.9  196.364385 -49.468038  0.0270   \n",
      "11  172.005  78.993  J112800.75+785931.7  172.003158  78.992165  0.0712   \n",
      "12  267.365  70.145  J174926.45+700840.8  267.360220  70.144679  0.0340   \n",
      "13  186.454  33.547  J122548.87+333248.8  186.453655  33.546906  0.0374   \n",
      "14  184.375  37.809  J121729.47+374826.7  184.372801  37.807432  0.0389   \n",
      "15  181.763  43.065  J120703.12+430356.5  181.763024  43.065704  0.0298   \n",
      "16  187.630  41.650  J123031.45+413903.8  187.631080  41.651060  0.0314   \n",
      "17  161.958  12.582  J104749.60+123453.7  161.956688  12.581599  0.0318   \n",
      "18  114.216  65.600  J073652.37+653555.2  114.218248  65.598671  0.0731   \n",
      "19  167.880  55.674  J111131.08+554027.5  167.879523  55.674322  0.0275   \n",
      "\n",
      "    sigdec  sigradec  w1mpro  w1sigmpro  w1snr   w1rchi2  w2mpro  w2sigmpro  \\\n",
      "0   0.0252   -0.0031   5.262      0.051   21.1   19.1000   4.757      0.041   \n",
      "1   0.0302   -0.0049   8.530      0.023   47.4   50.1600   8.190      0.020   \n",
      "2   0.0294   -0.0027   9.855      0.023   46.9  123.7000   9.661      0.021   \n",
      "3   0.0014   -0.0003   3.669      0.383    2.8    0.2359   3.286      0.053   \n",
      "4   0.0393   -0.0248   9.450      0.028   38.3  442.4000   9.095      0.026   \n",
      "5   0.0039    0.0010   5.757      0.034   32.3   44.2100   5.028      0.029   \n",
      "6   0.0289   -0.0054   8.741      0.021   52.3  170.3000   8.161      0.019   \n",
      "7   0.0288    0.0050   7.194      0.027   40.4   68.6300   7.720      0.019   \n",
      "8   0.0282   -0.0052   9.175      0.022   50.4  149.4000   8.790      0.020   \n",
      "9   0.0263   -0.0044   5.611      0.048   22.6   31.2000   6.120      0.019   \n",
      "10  0.0254    0.0029   7.768      0.023   48.0   65.9500   6.498      0.020   \n",
      "11  0.0713    0.0160  15.125      0.033   32.7    4.8000  14.647      0.045   \n",
      "12  0.0359    0.0049  10.180      0.023   48.0   94.9500  10.102      0.022   \n",
      "13  0.0374   -0.0053  12.624      0.025   44.0    6.7480  11.839      0.023   \n",
      "14  0.0394   -0.0085  11.795      0.023   48.2   72.2700  11.835      0.024   \n",
      "15  0.0294   -0.0063   8.225      0.023   46.9   45.1200   8.221      0.019   \n",
      "16  0.0315   -0.0045  11.681      0.025   44.1   91.2200  11.381      0.022   \n",
      "17  0.0306   -0.0048   7.513      0.025   43.9   67.3700   7.868      0.020   \n",
      "18  0.0771   -0.0116  11.815      0.038   28.7   36.5100  11.619      0.038   \n",
      "19  0.0262   -0.0024  10.075      0.020   54.7  151.6000   9.602      0.018   \n",
      "\n",
      "    w2snr  w2rchi2  w3mpro  w3sigmpro  w3snr   w3rchi2  w4mpro  w4sigmpro  \\\n",
      "0    26.4   12.230   2.621      0.012   89.4   20.4300   0.279      0.015   \n",
      "1    53.9   27.560   5.482      0.015   70.8    9.1490   3.328      0.020   \n",
      "2    52.7   86.920   5.366      0.013   83.2  114.0000   2.931      0.027   \n",
      "3    20.6   15.660  -1.666      0.321    3.4    0.1714  -4.348      0.001   \n",
      "4    42.3  324.400   5.004      0.017   65.3   75.3800   0.956      0.016   \n",
      "5    37.4   33.400   0.087      0.024   45.5    0.2416  -2.656      0.002   \n",
      "6    56.2  103.700   5.084      0.015   71.8   58.2400   2.955      0.026   \n",
      "7    56.2   56.470   6.691      0.015   72.3   26.1800   5.091      0.031   \n",
      "8    54.7   93.850   4.619      0.015   74.1   55.9200   1.799      0.015   \n",
      "9    56.3  109.100   4.337      0.013   83.0   59.1200   2.036      0.019   \n",
      "10   55.1   36.320   2.622      0.011  102.1   32.9600  -0.189      0.017   \n",
      "11   24.0    1.591  10.965      0.081   13.4    1.3500   6.886      0.068   \n",
      "12   50.4   56.850   7.698      0.022   48.9   33.6900   5.626      0.045   \n",
      "13   47.6    1.676   8.605      0.024   45.2    1.0370   5.519      0.037   \n",
      "14   46.1   19.030   9.271      0.038   28.9    3.7300   7.053      0.114   \n",
      "15   58.0   37.660   7.009      0.015   71.0   10.5800   5.229      0.030   \n",
      "16   49.6   39.960   6.651      0.015   71.1   45.2100   3.807      0.021   \n",
      "17   54.6   52.230   7.327      0.018   62.0   13.8300   6.195      0.047   \n",
      "18   28.5   18.400   8.784      0.070   15.6    4.8450   6.771      0.147   \n",
      "19   60.7   96.640   5.511      0.013   82.0  104.5000   2.512      0.022   \n",
      "\n",
      "     w4snr    w4rchi2   nb   na  w1sat  w2sat  w3sat  w4sat    pmra  sigpmra  \\\n",
      "0     71.3    18.9800  1.0  0.0  0.100  0.097  0.075  0.000   -65.0     22.0   \n",
      "1     53.2     5.9670  1.0  0.0  0.000  0.000  0.000  0.000   218.0     47.0   \n",
      "2     40.0    57.7100  3.0  0.0  0.000  0.000  0.000  0.000   326.0     32.0   \n",
      "3   1253.0  5886.0000  1.0  0.0  0.219  0.161  0.328  0.441   -26.0     31.0   \n",
      "4     69.1    87.6300  3.0  0.0  0.000  0.000  0.000  0.000 -5809.0     42.0   \n",
      "5    515.7   371.4000  1.0  0.0  0.124  0.124  0.308  0.249 -1351.0     37.0   \n",
      "6     41.6    52.9100  2.0  0.0  0.000  0.000  0.000  0.000 -1700.0     27.0   \n",
      "7     35.3     3.1170  1.0  0.0  0.042  0.000  0.000  0.000  -131.0     22.0   \n",
      "8     70.3    81.4200  1.0  0.0  0.000  0.000  0.000  0.000 -4868.0     28.0   \n",
      "9     56.1    27.0900  1.0  0.0  0.097  0.040  0.000  0.000   245.0     26.0   \n",
      "10    65.4    27.8300  1.0  0.0  0.000  0.002  0.042  0.000    27.0     22.0   \n",
      "11    15.9     1.4390  2.0  0.0  0.000  0.000  0.000  0.000  -429.0    721.0   \n",
      "12    24.2    13.6500  2.0  0.0  0.000  0.000  0.000  0.000  -828.0     24.0   \n",
      "13    29.1     0.9281  1.0  0.0  0.000  0.000  0.000  0.000   103.0     46.0   \n",
      "14     9.5     1.1090  1.0  0.0  0.000  0.000  0.000  0.000  -170.0     56.0   \n",
      "15    36.1     1.1850  1.0  0.0  0.000  0.000  0.000  0.000    10.0     32.0   \n",
      "16    52.5    56.3000  1.0  0.0  0.000  0.000  0.000  0.000     0.0     39.0   \n",
      "17    23.0     1.5830  1.0  0.0  0.031  0.000  0.000  0.000  -193.0     37.0   \n",
      "18     7.4     1.3960  3.0  0.0  0.000  0.000  0.000  0.000   276.0     58.0   \n",
      "19    49.8    56.6700  2.0  0.0  0.000  0.000  0.000  0.000 -3041.0     28.0   \n",
      "\n",
      "     pmdec  sigpmdec cc_flags  ext_flg var_flg ph_qual  moon_lev   w1nm  \\\n",
      "0   -305.0      22.0     hhhh      5.0    3344    AAAA       0.0   46.0   \n",
      "1   -347.0      60.0     0000      5.0    2211    AAAA       0.0   34.0   \n",
      "2  -1422.0      33.0     hh00      3.0    n3n4    AAAA       0.0   32.0   \n",
      "3   -107.0      30.0     hhhh      5.0    130n    CABA       0.0   39.0   \n",
      "4   -200.0      37.0     hhdd      3.0    nn23    AAAA       0.0   33.0   \n",
      "5    539.0      33.0     HHHH      5.0    nnnn    AAAA       0.0   27.0   \n",
      "6  -2463.0      26.0     hhhd      5.0    nn11    AAAA       0.0   27.0   \n",
      "7    -45.0      22.0     0000      5.0    3331    AAAA       0.0   65.0   \n",
      "8     95.0      29.0     hhhh      3.0    n333    AAAA      11.0   27.0   \n",
      "9   -494.0      25.0     hhh0      5.0    4n43    AAAA       0.0   33.0   \n",
      "10    -4.0      22.0     0hhh      5.0    2444    AAAA       0.0   50.0   \n",
      "11  -789.0     882.0     0000      1.0    0011    AAAA       0.0   51.0   \n",
      "12  -388.0      24.0     hhd0      5.0    3331    AAAA       0.0  151.0   \n",
      "13    93.0      47.0     0000      5.0    4500    AAAA       0.0   28.0   \n",
      "14  -468.0      63.0     0000      5.0    1000    AAAB       0.0   28.0   \n",
      "15   221.0      32.0     0000      5.0    3200    AAAA       0.0   29.0   \n",
      "16     0.0      39.0     000h      3.0    2124    AAAA       0.0   27.0   \n",
      "17  -362.0      34.0     0000      5.0    1100    AAAA    1100.0   24.0   \n",
      "18   538.0      61.0     ddPP      3.0    11nn    AAAB       0.0   32.0   \n",
      "19   -25.0      28.0     hhhd      5.0    n3n4    AAAA       0.0   33.0   \n",
      "\n",
      "      w1m   w2nm    w2m  w3nm   w3m  w4nm   w4m _merge  \n",
      "0    46.0   46.0   46.0  24.0  24.0  24.0  24.0   both  \n",
      "1    34.0   34.0   34.0  19.0  19.0  19.0  19.0   both  \n",
      "2    32.0   32.0   32.0  18.0  18.0  18.0  18.0   both  \n",
      "3    39.0   39.0   39.0  19.0  19.0  19.0  19.0   both  \n",
      "4    33.0   33.0   33.0  17.0  17.0  17.0  17.0   both  \n",
      "5    27.0   27.0   27.0  14.0  14.0  14.0  14.0   both  \n",
      "6    27.0   27.0   27.0  12.0  12.0  12.0  12.0   both  \n",
      "7    65.0   65.0   65.0  33.0  33.0  33.0  33.0   both  \n",
      "8    27.0   27.0   27.0  14.0  14.0  14.0  14.0   both  \n",
      "9    33.0   33.0   33.0  18.0  18.0  18.0  18.0   both  \n",
      "10   50.0   50.0   50.0  27.0  27.0  27.0  27.0   both  \n",
      "11   51.0   50.0   51.0  16.0  25.0  24.0  25.0   both  \n",
      "12  151.0  151.0  151.0  77.0  77.0  77.0  77.0   both  \n",
      "13   28.0   28.0   28.0  15.0  15.0  15.0  15.0   both  \n",
      "14   28.0   27.0   27.0  14.0  14.0  13.0  14.0   both  \n",
      "15   29.0   29.0   29.0  16.0  16.0  16.0  16.0   both  \n",
      "16   27.0   27.0   27.0  15.0  15.0  15.0  15.0   both  \n",
      "17   24.0   24.0   24.0  13.0  13.0  13.0  13.0   both  \n",
      "18   32.0   32.0   32.0  17.0  17.0  11.0  17.0   both  \n",
      "19   33.0   33.0   33.0  20.0  20.0  20.0  20.0   both  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nd/77pj43rx7wbcbp0wx2qjq2140000gp/T/ipykernel_2853/3377927322.py:34: DtypeWarning: Columns (533,534) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band W4: \n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n",
      "Total error in flux for band w4: 0.039923301252416464\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "error was calculated by determining the error from the annuli and overlapping areas,\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####Defining the constants\n",
    "\n",
    "#define coordinates\t\n",
    "ra= 359.45700000000016\n",
    "dec= -32.592000000000013\n",
    "pos = SkyCoord(ra=ra, dec=dec, unit= 'deg')\n",
    "print(pos)\n",
    "\n",
    "# Lookup and define a service for ALLWISE Atlas images\n",
    "# the website gave me the URL\n",
    "allwise_service = vo.dal.SIAService(\"https://irsa.ipac.caltech.edu/ibe/sia/wise/allwise/p3am_cdd?\")\n",
    "\n",
    "#search the service for images covering within 1 arcsecond of the star. make this bigger if needed\n",
    "im_table = allwise_service.search(pos=pos, size= 1*u.arcsec)\n",
    "#im_table\n",
    "im_table.to_table().colnames\n",
    "for i in range(len(im_table)):\n",
    "    print(im_table[i])\n",
    "\n",
    "\n",
    "   #grab the x-ray sources for this galaxy\n",
    "#import huge csv and grab the name and ra and dec needed for each source.\n",
    "targetgals = pd.read_csv('../Data/inWISE.csv') # this should not be the one for all 120 and should rather be for the 74 of them.\n",
    "print(targetgals[0:20])\n",
    "huge = pd.read_csv('../Data/Hugefiles/Source_Flux_All_Modified_5.csv')\n",
    "columns = ['RA','Dec', 'Gname_Modified','Gname_Homogenized']\n",
    "g_huge = huge[columns]\n",
    "g_huge[0:100]\n",
    "\n",
    "#locate through merging\n",
    "df1 = targetgals\n",
    "df2 = g_huge\n",
    "\n",
    "merged_data = pd.merge(df1, df2, left_on='source_id', right_on = 'Gname_Homogenized', how='inner')\n",
    "columns = ['RA','Dec','Gname_Homogenized']\n",
    "Xray_sources = merged_data[columns]\n",
    "Xray_sources\n",
    "\n",
    "# just want NGC 7793s sources\n",
    "sources_7793 = Xray_sources.loc[Xray_sources['Gname_Homogenized'] == 'NGC 7793']\n",
    "#sources_7793\n",
    "#define the X-ray sources of NGC 7793\n",
    "ra = sources_7793['RA'].values\n",
    "dec = sources_7793['Dec'].values\n",
    "\n",
    "# defining a function to calculate the distances between two sources.\n",
    "def dist(p1, p2):\n",
    "    return np.sqrt( (p2[0] - p1[0])**2 + (p2[1] - p1[1])**2 )\n",
    "\n",
    "#defining a function that creates a circular mask around each source so that if something overlaps with it, that overlapping part is not included in the aperture photometry\n",
    "def create_circular_mask(h,w,center,radius):\n",
    "    Y, X = np.ogrid[:h, :w] # creating an open (more memory efficient) coordinate grid of the image\n",
    "    dist_from_center = np.sqrt((X-center[0])**2+ (Y-center[1])**2)\n",
    "    mask = dist_from_center <= radius # so that everything inside the radius receives a mask\n",
    "    return mask\n",
    "\n",
    "# define a mapping of the bands into labels to make it easier\n",
    "band_labels = {'w1': 'W1', 'w2': 'W2', 'w3': 'W3', 'w4': 'W4'}\n",
    "flux_zmfd = {'w1': 309.54 ,'w2': 171.787,'w3': 31.674,'w4': 8.363} # check if these worked by looking at the band 4 code above\n",
    "instr_zpmag = {'w1': 20.73,'w2': 19.56,'w3': 17.6 ,'w4':12.98 }\n",
    "\n",
    "'''REMEMBER TO\n",
    "Convert the sensitivities from jy to dn and then back to jy after running it through aperture photometry\n",
    "'''\n",
    "#noise_level =  {'w1': 0.0000136,'w2': 0.0000196,'w3': 0.000172 ,'w4': 0.00108 } THIS IS IN Jy. convert it to DN:\n",
    "noise_level =  {'w1': 8.6, 'w2': 7.607, 'w3': 59.54229 , 'w4': 20.093 }\n",
    "\n",
    "\n",
    "#flux uncertainty\n",
    "#bkg_error = annulus_error_var\n",
    "#overlap_error = overlap_error_var\n",
    "\n",
    "#error = calculate_total_error(data, bkg_error, overlapping counts? yes easy)\n",
    "#_error_var = _photo_table['aperture_sum_err'][0]\n",
    "tot_err= []\n",
    "def calc_tot_err(target_error_var, annulus_error_var, overlap_error_var):\n",
    "     tot_err = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "     return tot_err\n",
    "     \n",
    "def create_error_array(shape, noise_level):\n",
    "     #creates an error array with a constant noise level, although this makes me wonder about what to do for areas of brightness or if that doesnt matter.\n",
    "     return np.full(shape, noise_level)\n",
    "\n",
    "     \n",
    "# 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##running the for loop over every image and doing aperture photometry on each one\n",
    "#currently outputs as w4,w1,w2,w3 when querying the images. so index is 0.1.2.3 i want the index to be 0.3.2.1\n",
    "rows = []\n",
    "for i in [0, 3, 2, 1]:  # Reverse order index\n",
    "    band_id = im_table[i][\"sia_bp_id\"].lower()  # Get band ID in lowercase\n",
    "    if band_id in band_labels:\n",
    "        print(f'Band {band_labels[band_id]}: ')\n",
    "        data_url = im_table[i].getdataurl()\n",
    "        #Download the image and open it in Astropy\n",
    "        fname = download_file(data_url, cache=True)\n",
    "        image1= fits.open(fname)\n",
    "        image_data= image1[0].data\n",
    "        #print(data)\n",
    "        \n",
    "        wcs = WCS(image1[0].header)\n",
    "        #cuting out the image of the galaxy apart from the rest of the background.\n",
    "        cutout = Cutout2D(image_data, pos, (437,437), wcs=wcs)\n",
    "        wcs = cutout.wcs\n",
    "        cutout_data = cutout.data\n",
    "        #print(cutout_data)\n",
    "        positions = wcs.world_to_pixel_values(ra, dec)\n",
    "        positions = np.array(list(zip(positions[0], positions[1])))\n",
    "\n",
    "        #define the distance threshold for the KDTree grouping (in pixels)\n",
    "        distance_threshold = 5\n",
    "\n",
    "        #build the KDTree for efficient grouping\n",
    "        tree = KDTree(positions)\n",
    "\n",
    "        #query the KDTree to find points within the defined radius of dist threshold and group them together\n",
    "        groups = tree.query_ball_tree(tree, r=distance_threshold)\n",
    "       # print(groups)\n",
    "        # consolidating the groups. 'unique_groups' and 'seen': These are used to ensure that each group is processed only once.\n",
    "        unique_groups = []\n",
    "        seen = set()\n",
    "        for group in groups:\n",
    "            group = tuple(sorted(group))\n",
    "            if group not in seen:\n",
    "                seen.add(group)\n",
    "                unique_groups.append(group)\n",
    "       # print(unique_groups)\n",
    "        # for each unique group, the average postion of the detections is calulated so that only one source detection is used for aperture photometry instead of a bunch of the same sources being used.\n",
    "        #represents the consolidated postion of potentially multiple detections of one source.\n",
    "        grouped_positions = [positions[list(group)].mean(axis=0) for group in unique_groups]\n",
    "        #print(grouped_positions)\n",
    "\n",
    "        #define the Region(s) Of Interest (center x, center y, radius)\n",
    "        ROI = [ ((x, y) , 9, 16, 23) for x,y in grouped_positions ] # (x, y, radius around target, inner r, outer r)   36.3636, 50.90909) may need to mke the radius bigger when goruping? \n",
    "        \n",
    "\n",
    "        # initialize valid rows plotting for the current image iteration\n",
    "        valid_rows = []\n",
    "\n",
    "        \n",
    "        #now inputting the aperture photometry part\n",
    "        # check for overlap and perform aperture photometry\n",
    "        for i, ((x, y), r, annulus_inner, annulus_outer) in  enumerate(ROI):\n",
    "            overlap = False# initialize overlap flag (A boolean flag overlap is set to False for each source to track if it overlaps with any other source.)\n",
    "            non_overlapping_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x,y), r)\n",
    "\n",
    "            for j, ((x2, y2), r2, annulus_inner2, annulus_outer2) in  enumerate(ROI): # apparently you can run a for loop over 2 objects by putting the second one inside the first. it iterates over every source again to then see if it overlaps at all with another source.\n",
    "                if i != j: # ensures that a source is not compared to itself! wow\n",
    "                    distance = dist((x, y) , (x2, y2)) \n",
    "                    if distance < r + r2:  # if the distance is less than the size of the two radii added together, then they are overlapping.\n",
    "                        overlap_percent = (r + r2 - distance)/(r+r2)  # the amount they are overlapping divided by the total size of radii distance\n",
    "                        if overlap_percent > .5:\n",
    "                            overlap = True # this way, if they overlap by more than 50% then they will not be usable because less than 50% of the flux extractable area can be seen.\n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            if band_id in noise_level:\n",
    "                                 band_noise_level = noise_level[band_id]\n",
    "                                 error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                                 overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture, error=error)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error_var = overlap_photo_table['aperture_sum_err'][0]\n",
    "                            if target_counts > 0:\n",
    "                                target_counts -= overlap_counts\n",
    "                            \n",
    "                        else: \n",
    "                            overlap_mask = create_circular_mask(cutout_data.shape[0], cutout_data.shape[1], (x2,y2), r2)\n",
    "                            non_overlapping_mask = np.logical_and(non_overlapping_mask, np.logical_not(overlap_mask)) # so that the overlapping part is read as false and thus excluded from calculation of flux.\n",
    "                            # \"logical and and not\" are used to exclude certain regions such as the overlapping part! the logical not makes it so that \n",
    "                            # values that were once true in the overlap mask are not false, and the logical_and is there so that only the true values are accepted. effectively rejecting the part the overlapping mask covers.\n",
    "\n",
    "                            #Handle overlaps that are acceptable (less than the threshold, but still overlapping by a small percent)\n",
    "                            overlap_aperture = CircularAperture((x2, y2), r2)\n",
    "                            if band_id in noise_level:\n",
    "                                band_noise_level = noise_level[band_id]\n",
    "                                error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                                overlap_photo_table = aperture_photometry(cutout_data, overlap_aperture, error=error)\n",
    "                            overlap_counts = overlap_photo_table['aperture_sum'][0] \n",
    "                            overlap_error_var = overlap_photo_table['aperture_sum_err'][0]\n",
    "                            if target_counts > 0:\n",
    "                                target_counts -= overlap_counts\n",
    "                            \n",
    "\n",
    "\n",
    "            if overlap:\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                if band_id in noise_level:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    target_photo_table = aperture_photometry(cutout_data, target_aperture, error=error) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_error_var = target_photo_table['aperture_sum_err'][0]\n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [], 'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [],  'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var})\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                if band_id in noise_level:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture, error=error)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                annulus_error_var = annulus_photo_table['aperture_sum_err'][0]\n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #flag the sources that overlap\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [], 'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var })\n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [],'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, \n",
    "                    'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [] })\n",
    "                \n",
    "            else: #perform all the aperture photometry stuff\n",
    "                # For the Target objects in the little aperture circle define their target apertures\n",
    "                target_aperture = CircularAperture((x,y),r,)\n",
    "            \n",
    "                #perform aperture photometry on target\n",
    "                if band_id in noise_level:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    target_photo_table = aperture_photometry(cutout_data, target_aperture, error=error) \n",
    "                target_counts = target_photo_table['aperture_sum'][0]\n",
    "                target_error_var = target_photo_table['aperture_sum_err'][0]\n",
    "                \n",
    "\n",
    "                if target_counts > 0: # \n",
    "                    # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(target_counts))     #converting counts to magnitude\n",
    "                         target_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                         # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx,'Flux Uncertainty': [],'Flag':'Negative Target Counts',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Overlap Counts': overlap_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                            'Offset in Arcseconds': [], 'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': overlap_error_var})\n",
    "\n",
    "                    \n",
    "                #calculate area of target aperutue\n",
    "                target_area = target_aperture.area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # For the Background Annuli of outside of the Target\n",
    "                #define the background annulus for the target\n",
    "                annulus_aperture = CircularAnnulus((x, y), annulus_inner, annulus_outer)\n",
    "\n",
    "                #perform aperture photometry on annuli\n",
    "                if band_id in noise_level:\n",
    "                    band_noise_level = noise_level[band_id]\n",
    "                    error = create_error_array(cutout_data.shape, band_noise_level)\n",
    "                    annulus_photo_table = aperture_photometry(cutout_data, annulus_aperture, error=error)\n",
    "                annulus_counts = annulus_photo_table['aperture_sum'][0]\n",
    "                annulus_error_var = annulus_photo_table['aperture_sum_err'][0]\n",
    "                \n",
    "            \n",
    "                if annulus_counts > 0:\n",
    "                     # avoid taking the log of zero or negative value\n",
    "                    if band_id in flux_zmfd and instr_zpmag: \n",
    "                         #print(f'Band {flux_zmfd[band_id]}: ')\n",
    "                         flx_conv_fact = flux_zmfd[band_id]\n",
    "                         M0instr = instr_zpmag[band_id]\n",
    "                         Mcal_trgt = M0instr - 2.5*(np.log10(annulus_counts))     #converting counts to magnitude\n",
    "                         annulus_flux = flx_conv_fact * 10**(Mcal_trgt/-2.5)      #convert Magnitude to Flux\n",
    "                else:\n",
    "                        annulus_flux = np.nan # to handle the cases where the counts are not more than 0 and if the conversion factors are missing.\n",
    "                        \n",
    "                #calculate area of annulus\n",
    "                annulus_area = annulus_aperture.area\n",
    "\n",
    "                # do the calculations for including a Background aperture\n",
    "            \n",
    "                #Calculating the net flux:\n",
    "                #calculate the mean background per pixel\n",
    "                bg_perpixel = annulus_flux/annulus_area\n",
    "\n",
    "                #calculate the total background in the target aperture\n",
    "                tot_bg = bg_perpixel * target_area\n",
    "\n",
    "                #Subtract background from the target flux\n",
    "                net_flx = target_flux - tot_bg\n",
    "            \n",
    "                #   Append the result as a dictionary to the list named 'rows'\n",
    "                rows.append({ 'band_id': {band_labels[band_id]},'Region': i+1, 'X': x, 'Y': y, 'Radius': r, 'Annulus_Inner_Radius': annulus_inner, \n",
    "                        'Annulus_Outer_Radius': annulus_outer, 'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [],  'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux',\n",
    "                        'aperture_sum': target_photo_table['aperture_sum'][0] ,'tot_bg': tot_bg, 'Target Counts': target_counts, 'Target Flux': target_flux,\n",
    "                            'Annulus Counts': annulus_counts, 'Annulus Flux': annulus_flux,'Image Data Shape': cutout_data.shape, 'Mask Shape': non_overlapping_mask.shape,\n",
    "                            'Mask Type': non_overlapping_mask.dtype, 'Non-zero mask elements': np.count_nonzero(non_overlapping_mask), 'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr,\n",
    "                              'Offset in Arcseconds': [],   'Exists?': 'No', 'Point Source Position' : [], 'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': []})  #will prolly have to change the name of the Flux here!!!\n",
    "            #\"Low Flux\" means that they either have zero flux or negative flux and so they are excluded from the plotting\n",
    "               \n",
    "                # Append valid results to valid_rows\n",
    "                valid_rows.append({\n",
    "                    'band_id': {band_labels[band_id]},\n",
    "                    'Region': i+1, 'X': x, 'Y': y, 'Radius': r,\n",
    "                    'Annulus_Inner_Radius': annulus_inner,\n",
    "                    'Annulus_Outer_Radius': annulus_outer,\n",
    "                    'Net Flux (Jy)': net_flx, 'Flux Uncertainty': [],\n",
    "                    'Flag':'Valid' if not math.isnan(target_counts) and target_counts > 0 and net_flx > 0 else 'Low Flux', \n",
    "                    'Flux Conv':flx_conv_fact, 'MzpInstr':M0instr, 'Exists?': 'No', 'Point Source Position' : [], 'Offset in Arcseconds': [],\n",
    "                     'Target Error': target_error_var, 'Annulus Error': annulus_error_var, 'Overlap Error': [] })\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "\n",
    "        #Source detection code\n",
    "        mean, median, std = sigma_clipped_stats(cutout_data, sigma=3.0)  \n",
    "       #print((mean, median, std))\n",
    "\n",
    "        # subtract the background and find FWHM of sources at a certain threshold\n",
    "        #started at fwhm= 3 and threshold = 5\n",
    "        daofind = DAOStarFinder(fwhm=8, threshold=1*std) # find the stars in the image that have FWHMs of around 3 pixels and have peaks approximately 5-sigma above the background. \n",
    "        sources = daofind(cutout_data - median)  \n",
    "        #print(type(sources))\n",
    "        # will likely run into iissues in the code below\n",
    "        for col in sources.colnames:  \n",
    "            if col not in ('id', 'npix'):\n",
    "                sources[col].info.format = '%.2f'  # for consistent table output\n",
    "       # sources.pprint(max_width=3000)  \n",
    "\n",
    "        #likely the flux labeled in this is not converted!\n",
    "        \n",
    "        # plot the image with marked locations of all the sources it detected.\n",
    "        detected_positions = np.transpose((sources['xcentroid'], sources['ycentroid']))\n",
    "        apertures = CircularAperture(detected_positions, r=2)\n",
    "\n",
    "\n",
    "        # Plotting for current image\n",
    "        # Filter valid rows\n",
    "        valid_rows_filtered = [row for row in valid_rows if row['Flag'] == 'Valid']\n",
    "        \n",
    "        #calculate error, convert it back to flux and append the total error\n",
    "        #total_error = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "        for  row in valid_rows_filtered:\n",
    "            total_error = np.sqrt(target_error_var**2 + annulus_error_var**2 + overlap_error_var**2)\n",
    "            if band_id in flux_zmfd and instr_zpmag: \n",
    "                flx_conv_fact = flux_zmfd[band_id]\n",
    "                M0instr = instr_zpmag[band_id]\n",
    "                Mcal_error = M0instr - 2.5*(np.log10(total_error))     #converting counts to magnitude\n",
    "                total_error_flx= flx_conv_fact * 10**(Mcal_error/-2.5)#convert Magnitude to Flux\n",
    "                flux_uncertainty_value=total_error_flx      #may need to index the variable here.\n",
    "                print(f'Total error in flux for band {band_id}: {flux_uncertainty_value}')\n",
    "                row['Flux Uncertainty'].append(flux_uncertainty_value)\n",
    "            else:\n",
    "                 print(f'Missing data for band {band_id}. Skipping...')\n",
    "\n",
    "        # Was there a point source there?\n",
    "        pixelsinarc = 0.0003819444391411 * 3600 ## 0.0003819444391411 is the number found in the header of the image for the scale of pixels in degrees for the fits image.\n",
    "        detectedpos_all = []\n",
    "        #rows = [row for row in rows if row['Flag'] == 'Valid']\n",
    "        for row in valid_rows_filtered:\n",
    "            apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "            for detected_position in detected_positions:\n",
    "                detected_x, detected_y = detected_position\n",
    "                distance = dist((row['X'], row['Y']), (detected_x, detected_y) ) #distance from the center of the xray source to the center of the detected source\n",
    "                if distance <= row['Radius']: \n",
    "                    row['Exists?'] = 'Point Source Detected'\n",
    "                    row['Point Source Position'].append((detected_x, detected_y))\n",
    "                    dist_in_arc = distance * pixelsinarc\n",
    "                    row['Offset in Arcseconds'].append((dist_in_arc))\n",
    "                    detectedpos_all.append(detected_position) \n",
    "                    #print(f\"Number of detected positions within forced apertures: {len(detectedpos_all)}\")\n",
    "\n",
    "\n",
    "        Yes = []\n",
    "        YesRadius= 5\n",
    "        for row in valid_rows_filtered:\n",
    "                    apertures_forced = CircularAperture((row['X'], row['Y']), r=row['Radius'])\n",
    "                    for detected_position in detected_positions:\n",
    "                        detected_x, detected_y = detected_position\n",
    "                        distance = dist((row['X'], row['Y']), (detected_x, detected_y) )\n",
    "\n",
    "                        if distance <= YesRadius:\n",
    "                            row['Exists?'] = 'Yes!!'\n",
    "                            Yes.append((row['X'], row['Y']))\n",
    "                                              \n",
    "\n",
    "        # Update rows with valid_rows_filtered information\n",
    "        for valid_row in valid_rows_filtered:\n",
    "            for row in rows:\n",
    "                if row['band_id'] == valid_row['band_id'] and row['Region'] == valid_row['Region']:\n",
    "                    row.update(valid_row)\n",
    "\n",
    "        #print('valid sources', valid_rows_filtered)\n",
    "\n",
    "        #print( len(detectedpos_all))\n",
    "        if len(detectedpos_all) > 0:\n",
    "            apertures_detected = CircularAperture(detectedpos_all, r=2)\n",
    "        if len(Yes) > 0:\n",
    "            apertures_Yes = CircularAperture(Yes, r=YesRadius)\n",
    "\n",
    "\n",
    "\n",
    "         # Plotting for current image\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': wcs})\n",
    "        norm = ImageNormalize(cutout.data, stretch=SqrtStretch())\n",
    "        for row in valid_rows_filtered:\n",
    "            target_aperture = CircularAperture((row['X'], row['Y']), row['Radius'])\n",
    "            annulus_aperture = CircularAnnulus((row['X'], row['Y']), row['Annulus_Inner_Radius'], row['Annulus_Outer_Radius'])\n",
    "            target_aperture.plot(color='red', lw=1.5, alpha=.5, ax=ax)\n",
    "            annulus_aperture.plot(color='blue', lw=1.5, alpha=.5, ax=ax)\n",
    "            \n",
    "            apertures.plot(color='#98ff98', lw=.5, alpha=0.5) \n",
    "            apertures_detected.plot(color='#FF4500', lw=.5, alpha=0.5)  #  #FF69B4 for hot pink\n",
    "            apertures_Yes.plot(color='green', lw=.5, alpha=0.5) \n",
    "        ax.imshow(cutout.data, cmap='gray', norm=norm, interpolation='nearest')\n",
    "        ax.set_xlabel('Right Ascension')\n",
    "        ax.set_ylabel('Declination')\n",
    "        plt.title(f'Band {band_labels[band_id]}')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "display_data = pd.DataFrame(rows)\n",
    "display_data\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "print(len(display_data))\n",
    "display(display_data.loc[display_data['Flag']== 'Valid'])\n",
    "display(display_data)\n",
    "print(len(display_data.loc[display_data['Flag']== 'Valid']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
