{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0dc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "from astroquery.ipac.irsa import Irsa\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astroquery.simbad import Simbad\n",
    "from astropy.table import Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data frames. rewrote some of the columns to make them the way i wanted.\n",
    "#testing\n",
    "gsample = pd.read_csv('../Data/galaxy_names_reduced_homogeneous_resolved_unique_with_10ks_exposure_cut.csv')\n",
    "#print(gsample)\n",
    "gsample = pd.DataFrame(gsample['Galaxy_Name_Reduced'][:])\n",
    "\n",
    "gsample = gsample.rename(columns={'Galaxy_Name_Reduced': 'source_id'})\n",
    "gsample['source_id']\n",
    "#print(gsample)\n",
    "#gsample.to_csv('output1.csv', index=True)\n",
    "\n",
    "oldsample = pd.read_csv('../Data/ocatResult_Modified.csv')\n",
    "#oldsample\n",
    "#gsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want only a specific few columns just to make it simpler\n",
    "\n",
    "columns = ['RA','Dec','Gname']\n",
    "name_and_coords = oldsample[columns]\n",
    "name_and_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05053f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsample['source_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca179f",
   "metadata": {},
   "source": [
    "# Querying data bases\n",
    "    Simbad and ALLWISE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9851b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this block is useful for doing simbad queries but does not really help. some interesting functions like \"to list\"\n",
    "\n",
    "sample_list = gsample['source_id'].tolist()\n",
    "#print(sample_list)\n",
    "#Set simbad settings to retrieve Ra and Dec\n",
    "simbad_settings = Simbad()\n",
    "#simbad_settings.add_votable_feilds(\"coordinates\")\n",
    "#testing to make sure querying simbad works\n",
    "test= Simbad.query_object(\"M1\")\n",
    "\n",
    "#querying simbad using the list running over each name in the list and pulling out all the information on it.\n",
    "#i specifically wanted to see the RA and DEC but i'll get many other things from it and that's ok\n",
    "myresult= []\n",
    "\n",
    "for galaxy in sample_list:\n",
    "    result = Simbad.query_object(galaxy)\n",
    "    myresult.append(result)\n",
    "\n",
    "#myresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af74d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#querying the ALLWISE database\n",
    "\n",
    "#trying to figure out the names of columns so i know what to \n",
    "#catalogs = Irsa.list_catalogs()\n",
    "\n",
    "#print(\"All catalogs\", catalogs)\n",
    "#table = Irsa.query_region(\"HIP 12\", catalog=\"allwise_p3as_psd\", spatial=\"Cone\")\n",
    "#print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1cef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3c3c82e",
   "metadata": {},
   "source": [
    "# Creating table to upload to ALLWISE catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22261487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code that Katie helped me with. Not something that i should be practicing since apparently you should not\n",
    "# should not use for loops with pandas since the reason it exists is to eliminate the need for them\n",
    "# nonetheless, this uses names from the list of samples above and goes into \"name_and_coords\"(which is a variable for\n",
    "# a column reduced csv file that Anthony gave us with all the galaxies in the sample and had way too many duplicates)\n",
    "# and finds the location (.loc) for any name that matches what is in the small csv file with the big csv file and appends it\n",
    "# as you can see it reduces the number somewhat cuz of the 10ks cut, but there are a lot of duplicates\n",
    "\n",
    "targets = sample_list\n",
    "columns = name_and_coords.columns\n",
    "#create empty data frame\n",
    "target_data = pd.DataFrame(columns=columns)\n",
    "for target in targets:\n",
    "    row = name_and_coords.loc[name_and_coords['Gname']==target]\n",
    "    target_data = target_data._append(row)\n",
    "\n",
    "\n",
    "target_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c01bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes the duplicates\n",
    "target_data.drop_duplicates(subset = ['Gname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa041334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wanted to rename the columns again cuz i was fighting with the document upload feature on WISE telescope\n",
    "\n",
    "target_data = target_data.rename(columns={'Gname': 'source_id'})\n",
    "target_data = target_data.rename(columns={'RA': 'ra'})\n",
    "target_data = target_data.rename(columns={'Dec': 'dec'})\n",
    "\n",
    "target_data = target_data.drop_duplicates(subset = ['source_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a40437",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7813cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetnames = target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write each row as separated by |\n",
    "#with open('../Data/file_ascii.txt', 'w', encoding = 'ascii', errors = 'ignore') as f:\n",
    "   # for index, row in target_data:\n",
    "     #   row_string = '|'.join(map(str, row.values)) + '\\n'\n",
    "       # f.write(row_string)\n",
    "\n",
    "# still fighting but i'll leave it here just in case   \n",
    "    \n",
    "columns1 = ['ra','dec']\n",
    "target_data = target_data[columns1]\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_data.to_csv('final1.csv', index=False, sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#a nice thing i found on stack overflow for creating a .tbl file! writing it into one of the formats that WISE only accepts\n",
    "\n",
    "data_out = Table.from_pandas(target_data)\n",
    "output_path = '../Data/data_out.tbl'\n",
    "\n",
    "# Write the table in IPAC format\n",
    "data_out.write(output_path, format='ipac')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447490b",
   "metadata": {},
   "source": [
    "# Reading in results from the ALLWISE Catalog table\n",
    "    Also figuring out the fraction of galaxies present and which ones are not present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed57893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.genfromtxt('../Data/table_irsa_catalog_search_results.tbl')\n",
    "\n",
    "# found out that you can change the type of document you can download from WISE which helped a lot (csv files are goated)\n",
    "data = pd.read_csv('table_irsa_catalog_search_results.csv')\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "data\n",
    "\n",
    "#THE DESCRIPTIONS FOR EACH COLUMN IN THE DATA TABLE CAN BE SEEN IN THE DOWNLOADED FILE!! i think you have a version of it as a tbl which is a little more legible.\n",
    "# I'm not sure why, but for some reason there are some repeats. if you look closely at the Ra_01 and Dec_01 returned\n",
    "# i think it duplicates the values almost exactly as many times as there are missing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for some reason the \"merge\" function wants the columns in both dataframes to be named the exact same\n",
    "# so this makes things simpler\n",
    "gcolumns= ['ra_01','dec_01', 'cntr_01']\n",
    "simple_data = data[gcolumns]\n",
    "simple_data = simple_data.rename(columns={'ra_01': 'ra'})\n",
    "simple_data = simple_data.rename(columns={'dec_01': 'dec'})\n",
    "simple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ddf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful code from katie. not sure what \"inner\" means, maybe that it doesnt prioritize one dataframe over another.\n",
    "merged_data = pd.merge(df1, df2, on='the column you want to match', how='inner')\n",
    "merged_data = merged_data.drop_duplicates()\n",
    "#merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using merge to find which of the 114 galaxies found in the WISE telescope are in the list that Anthony gave us. Used a \"left merge\"\n",
    "df_all = targetnames.merge(simple_data.drop_duplicates(subset=['cntr_01']), on=['ra', 'dec'], \n",
    "                   how='left', indicator=True)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "df_all[0:122]\n",
    "#this ra and dec (11.888\t-25.288\t)is number 6 in this one and 7 in the other?? not good, that's why i'm seeing way too many 'left_only'\n",
    "# when i put in some of the one's that are left only into the catalogue it comes up with really crappy empty images, but others are also very good (ngc 0404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = targetnames.merge(data.drop_duplicates(subset=['cntr_01']), left_on=['ra', 'dec'], right_on =['ra_01', 'dec_01'], \n",
    "                  how='left', indicator=True)\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "df_all[0:122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = df_all.dropna()\n",
    "clean_data\n",
    "print(len(clean_data))\n",
    "print(len(targetnames))\n",
    "74/120\n",
    "#61.6 percent of the galaxies are in the WISE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9b75c6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxies not in the ALLWISE catalog ['MESSIER 086', 'NGC 4697', 'NGC 0404', 'MESSIER 101', 'MESSIER 104', 'NGC 4214', 'NGC 4449', 'NGC 3628', 'NGC 3115', 'NGC 3077', 'NGC 4051', 'NGC 0055', 'NGC 6822', 'NGC 3377', 'NGC 1313', 'NGC 1808', 'NGC 5204', 'NGC 1427A', 'NGC 4565', 'IC 0010', 'MESSIER 095', 'NGC 2841', 'NGC 3998', 'NGC 3621', 'UGC 05423', 'Holmberg I', 'Holmberg IX', 'MESSIER 064', 'NGC 3198', 'NGC 7814', 'NGC 2683', 'NGC 0300', 'Sextans A', 'MESSIER 049', 'NGC 1559', 'NGC 3287']\n"
     ]
    }
   ],
   "source": [
    "#the galaxies that are missing\n",
    "#Missing = clean_data.loc[clean_data['cntr_01']['Nan']] # the galaxies that are only in the file that anthony gave us\n",
    "nan_df = df_all[df_all['cntr_01'].isna()]\n",
    "obj_nan = nan_df['source_id'].tolist()\n",
    "print(\"Galaxies not in the ALLWISE catalog\", obj_nan)\n",
    "#for elem in nan_df['cntr_01']:\n",
    "    #if elem == True:\n",
    "        #print(nan_df['source_id'])\n",
    "\n",
    "#Missing = clean_data.loc[clean_data['cntr_01']['Nan']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82462f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3f76408",
   "metadata": {},
   "source": [
    "# **Everything below here does not seem to work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33acea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden code\n",
    "  #merge_list = df_all['_merge'].tolist()\n",
    "  #don't remember how to do pull out just the one's that are left_only.\n",
    "  #for i in merge_list:\n",
    "    #  if merge_list['_merge'] == True:\n",
    "        #  print(\"The galaxy exists in the catalog\")\n",
    "\n",
    "  Target_namesonly = df_all.loc[df_all['_merge'] == 'left_only'] # the galaxies that are only in the file that anthony gave us\n",
    "  both_dfs = df_all.loc[df_all['_merge'] == 'both']\n",
    "  #Fraction of galaxies present in the WISE telescope \n",
    "  Frac_present = len(Target_namesonly)/len(both_dfs)\n",
    "  print(Frac_present)\n",
    "  print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a04dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below here I tried to use the OG method Katie and i found but i couldnt get it to work\n",
    "114/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcolumns= ['ra','dec']\n",
    "simple_data = data[gcolumns]\n",
    "simple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = simple_data\n",
    "gcolumns = targetnames.columns\n",
    "#create empty data frame\n",
    "missing = pd.DataFrame(columns=gcolumns)\n",
    "for target in targets:\n",
    "    row = targetnames.loc[targetnames['ra']==target]\n",
    "    missing = missing._append(row)\n",
    "\n",
    "missing\n",
    "#nothing is showing up because it is not the exact value. you need a partial match, that is something that this does not seem to be able to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/1to1_irsa_catalog_search_results.csv')\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "#data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd04b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all = targetnames.merge(data.drop_duplicates(), left_on=['ra', 'dec'], right_on =['ra_01', 'dec_01'], \n",
    "                   how='left', indicator=True)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "df_all[0:122]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09aee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Missing = df_all.loc[df_all['_merge'] == 'left_only'] # the galaxies that are only in the file that anthony gave us\n",
    "both_dfs = df_all.loc[df_all['_merge'] == 'both']\n",
    "#Fraction of galaxies present in the WISE telescope \n",
    "Frac_present = len(Missing)/len(both_dfs)\n",
    "print(Frac_present)\n",
    "print(len(Missing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b271ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nan_df = data.isna()\n",
    "#print(nan_df)\n",
    "#nan_rows = nan_df.isna().any(axis=1)\n",
    "#nan_df\n",
    "#print(df_all)\n",
    "#df_all.drop_duplicates(subset = ['cntr_01', 'source_id'])\n",
    "#print(df_all)\n",
    "#clean_data = df_all.dropna()\n",
    "\n",
    "#clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f65a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
